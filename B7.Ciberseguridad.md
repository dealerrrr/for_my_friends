---
title: Ciberseguridad | Bloque 7
URL: https://app.web3mba.io/courses/take/bloque-7-ciberseguridad/lessons/35071668-u1-1-introduccion-a-la-ciberseguridad-washington-gomez
lang: es-AR
---
# B7. Ciberseguridad
## Introducción a la Criptografía
### Introducción a la Ciberseguridad (Video)
![[376.B7_Introducción_a_la_Ciberseguridad.mp4]]
[Introduccion a la Ciberseguridad](https://app.web3mba.io?wvideo=5u2lg8mcj7)

La ciberseguridad, una definición tal vez un poco más académica, se refiere a aquellas prácticas que nos permiten proteger los sistemas y la información de los ataques informáticos. Esa sería una definición tradicional que uno podría encontrar en Wikipedia o en Internet. Sin embargo, creo que será mucho más productivo que les cuente desde mis años de experiencia cómo interpreto la definición de ciberseguridad y, con los años que llevo trabajando en este ámbito, qué es realmente la ciberseguridad y cuáles son los esfuerzos que realizan todos los equipos de ciberseguridad en las distintas organizaciones para lograr proteger la información y los sistemas.

La ciberseguridad, en mi opinión personal, se puede entender en trece dimensiones. Por un lado, tenemos la tecnología; por otro, la gobernanza o gestión; y como tercer pilar importante, tenemos a las personas. En lo que respecta a las tecnologías, es fundamental contar con hardware, software y diversas tecnologías que hoy en día están surgiendo, como el Machine Learning y la Inteligencia Artificial, aplicadas a la gestión y correlación de eventos de seguridad. Estas tecnologías nos permiten ser mucho más rápidos, tener un tiempo de respuesta menor, identificar posibles ataques y correlacionar eventos que, si lo hiciéramos de forma manual, un analista encontraría realmente complejo. Además, no tendríamos la eficacia que tienen estos algoritmos y tecnologías. Por eso, hoy en día es muy importante estar al tanto de los últimos avances tecnológicos para poder defendernos frente a temas relacionados con la ciberseguridad, como son los ataques, por ejemplo.

Hoy en día, también es cierto que solo con la tecnología no podemos defender nuestras organizaciones. Ya no es suficiente únicamente la tecnología; debemos tener también las otras dos dimensiones. Por ejemplo, una de las tecnologías que ha evolucionado en estos años son los antivirus. Estos han pasado de tener bases de datos con definiciones de virus, donde si un virus estaba registrado, sabíamos que era un virus, a contar con avances que nos permiten detectar comportamientos. Estos comportamientos nos permiten entender cómo funcionan los malware y los virus, y sin tenerlos aún registrados, podemos suponer que se trata de un ataque. Esto nos hace ser mucho más eficientes y la tecnología nos permite ser más ágiles al momento de reaccionar frente a un incidente o incluso a un ataque de ciberseguridad.

¿Es suficiente tener el mejor firewall, comprar la marca más cara y tener el mejor producto en el mercado? Sinceramente, no. Hoy en día, solo con la tecnología no podemos afirmar que estamos seguros. ¿Qué más se necesita? Se requiere gobernanza. ¿Qué es la gobernanza? Bueno, la gobernanza tiene varios aspectos. Uno de ellos es la gestión de todo lo relacionado con la ciberseguridad. Son políticas, procedimientos y planes que ayudan a estar preparados, previniendo situaciones y posibles incidentes que puedan suceder, y nos ayudan a poder responder y tener un marco de seguridad de la información establecido. De esta forma, todos los esfuerzos que hagamos en base a ese marco de ciberseguridad serán estándares y podremos ayudar a nuestra organización a resolver problemas y llevar la ciberseguridad a todos los ámbitos.

Bajando un poco más en detalle sobre qué es la gobernanza, por ejemplo, puedo tener el mejor firewall, el más caro, de la marca más reconocida del mercado, pero si no tengo una correcta gestión del acceso a ese equipo, si no tengo un procedimiento que me permita revisar las reglas que existen en ese firewall de forma periódica, y si no tengo un procedimiento de alta y baja del personal técnico que gestiona ese firewall, seguramente terminaré teniendo un incidente de seguridad. Entonces, ¿es suficiente con la tecnología? No. ¿Es suficiente con la gobernanza? No. Y veremos más adelante por qué.

Dentro de la gobernanza también se encuentra la gestión de riesgos, que es algo muy importante para poder definir qué controles implementaremos en nuestra organización. Por ejemplo, un firewall es un control que busca reducir o mitigar el riesgo de una posible intrusión desde el exterior de nuestra organización. Ahora, como todos los controles, deben tener una gestión. Tenemos que validar que esos controles sean efectivos y que, con el paso del tiempo, esos mismos controles que hoy definimos como efectivos sigan siéndolo. Lo que nos permite la gobernanza, a través de uno de sus pilares que es la gestión de riesgos, es poder gestionar si nuestros controles son efectivos.

Un caso práctico para ilustrar esto podría ser el siguiente: puedo definir que un antivirus es un control efectivo para que los equipos de la organización no se infecten a través de un virus. Sin embargo, si no tengo una correcta gobernanza de ese control, por ejemplo, asegurando que se descarguen actualizaciones de forma periódica y que todos nuestros equipos estén integrados a ese antivirus, lo que sucederá es que tendré un control que me dará una falsa sensación de seguridad y que será ineficiente. Por lo tanto, es importante que, al gobernar la ciberseguridad, también sepa que debo gobernar los controles que implemento, ya sean firewalls, antivirus o soluciones de DLP. Todos los controles que solemos implementar, ya sean tecnológicos o no, para mitigar los riesgos, deben ser medidos y evaluados para saber si son eficientes y si cumplen con la función para la cual fueron contratados o implantados.

También es sumamente importante, al implantar un control, valorar el costo-beneficio de ese control. Muchas veces estamos tentados a gastar mucho dinero en seguridad y no hacemos un análisis real de costo-beneficio. ¿Qué sería un análisis de costo-beneficio? Intentaré poner un ejemplo más cotidiano para que se entienda. Si en mi casa quiero proteger el acceso a mis activos, es decir, todo lo que tengo dentro de mi hogar, seguramente instalaré una alarma que tenga un determinado costo para salvaguardar todas las cosas de valor que tengo dentro. Sin embargo, si también quiero resguardar lo que tengo en el trastero, que probablemente contenga cosas viejas y prescindibles, cosas que si mañana les sucediera algo no me impactarían tanto como si fueran activos valiosos, seguramente implantaré un control que sea mucho más económico y que se ajuste a las necesidades de lo que realmente quiero proteger.

Siguiendo con este ejemplo cotidiano, lo mismo sucede en seguridad. Siempre que implantemos controles, debemos hacer un análisis de costo-beneficio para asegurarnos de que el beneficio que nos brinda la implantación de este control y su costo estén alineados con lo que nuestra organización necesita. Después de haber adquirido e implantado tecnología de última generación para la detección de intrusos, así como para la gestión de reglas, tengo toda la gobernanza de la seguridad: políticas, procedimientos y planes que me indican cómo proceder en caso de un incidente, dónde reportarlo, a quién y de qué forma. También tengo toda la gobernanza de los riesgos, que me indica qué controles me ayudan a mitigar esos riesgos y qué planes de acción seguir.

¿Es suficiente para estar seguro? Realmente no. ¿Por qué? Porque falta otro pilar importante: las personas. Se ha escuchado que, en toda la cadena de la seguridad de la información, las personas suelen ser el eslabón más débil. Esta definición es correcta, pero en mi opinión personal tiene un pequeño matiz: las personas no capacitadas son el eslabón más débil de la cadena de seguridad de la información. ¿Qué quiere decir esto? Que esa definición se aplica cuando no hacemos nada por capacitar a nuestro personal en temas de seguridad de la información y ciberseguridad.

Si logramos implementar el concepto que ya se ha mencionado en el ámbito de la tecnología y la ciberseguridad, conocido como el "firewall humano" o "cortafuego humano", que es un concepto bastante interesante, se trata de capacitar a las personas para que puedan estar vigilantes, alertas y con los conocimientos necesarios de seguridad de la información para poder responder frente a intentos de ataques, como los ataques de ingeniería social. Hoy en día, dentro de estos ataques, el que más destaca es el phishing o el fraude de CEO, que es otro ataque bastante conocido en el cual se hacen pasar por el CIO de la compañía e intentan que, generalmente, el foco esté en el personal de finanzas, solicitando de forma urgente que realicen una transferencia de dinero hacia una cuenta, creyendo que es una solicitud legítima, cuando en realidad se trata de un ataque de ingeniería social.

Si logramos tener a las personas capacitadas, si logramos que tengan los recursos y las posibilidades de reportar cuando detectan algo que les genera dudas, que podría ser un posible intento de ingeniería social, alcanzaremos lo que se conoce como el "firewall humano". Esto nos brindará una increíble posibilidad de contar con personas comprometidas con la seguridad en cada uno de los distintos departamentos de nuestras organizaciones. Estas personas estarán vigilantes, con los conocimientos necesarios, realizando tareas diarias con esa capacitación, lo que les permitirá detectar posibles ataques y vulnerabilidades en sus procesos y en su trabajo diario. Ninguna tecnología nos permitirá alcanzar ese nivel de seguridad y resiliencia para toda la organización como lo hará tener distribuido en cada departamento a muchas personas capacitadas, logrando así una red, una cadena de "firewalls humanos" que nos permitirá superar con creces cualquier ataque de ingeniería social o intento de un atacante externo de vulnerar nuestros activos principales, que son las personas.

Por otro lado, tenemos el concepto de seguridad de la información, que busca proteger la información en un triángulo de tres pilares importantes. Por un lado, tenemos la integridad; por otro, la confidencialidad; y el tercero es la disponibilidad. Siempre que se hable de seguridad de la información, se tratará de proteger la información en esas tres dimensiones, logrando así que la información esté siempre disponible, siempre íntegra y siempre accesible para quienes realmente necesitan acceder a ella.

En temas de confidencialidad, podemos destacar dos buenas prácticas que se suelen utilizar, que son principios. Uno es el principio de "privilegios mínimos", que significa que siempre se deben otorgar los mínimos privilegios de acceso a la información posible. Un caso práctico podría ser que, si necesitamos darle acceso a una persona a un documento, deberíamos darle acceso solo a ese documento y no a toda la carpeta o directorio donde se encuentra, ya que la persona no necesita acceder a toda la información en ese directorio, sino únicamente a un documento en particular. Ese es un ejemplo práctico del principio de "privilegios mínimos".

Luego tenemos otro principio que se llama "need to know", que es el principio de la necesidad de saber. Esto significa que las personas dentro de la organización que no necesiten saber o conocer determinada información no deberían tener acceso a la misma. Como verán, lo que se busca siempre es proteger la confidencialidad y otorgar acceso solo a quienes realmente lo necesiten para realizar su trabajo diario o llevar a cabo sus tareas.

Un concepto muy importante dentro de la seguridad es que la información debe ser íntegra. Debemos proteger la información para que, cuando la necesitemos recuperar o utilizar, mantenga el mismo nivel de integridad que tenía cuando la guardamos, por ejemplo, en una base de datos o cuando la respaldamos. Debemos asegurarnos de que la integridad de la información siempre se mantenga de esa forma.

Por último, a veces se suele olvidar un aspecto fundamental en el mundo de la seguridad: la disponibilidad. Generalmente, en la práctica, la disponibilidad está más relacionada con los departamentos de sistemas, que se encargan de armar una arquitectura resiliente para que siempre funcione. Suele no tenerse en cuenta en los departamentos de ciberseguridad, pero es uno de los principios y pilares fundamentales de la seguridad de la información. La información debe estar disponible cuando sea necesario utilizarla. En base a esto, desde los departamentos de ciberseguridad, tenemos mecanismos que veremos más adelante para garantizar la disponibilidad de la información.

Dentro de la correcta gestión de riesgos, uno de los métodos más utilizados para valorar y gestionar riesgos es el "Risk Assessment" o análisis de riesgos. ¿Qué es un análisis de riesgos? Un análisis de riesgos nos permite evaluar las distintas amenazas para nuestros activos de información y asignar un puntaje de riesgo a dichas amenazas. Básicamente, para generar este puntaje o nivel de riesgo se toman en cuenta dos variables muy importantes. La primera es la probabilidad de que esa amenaza suceda, es decir, que se concrete y se materialice. Y, por otro lado, en caso de que esa vulnerabilidad o amenaza realmente suceda, ¿cuál sería el nivel de impacto que tendría en nuestro negocio? Por ejemplo, ¿cuál sería el impacto si se materializa una amenaza como una fuga de información? Seguramente la probabilidad sea baja, pero el impacto es muy alto, por lo que tendríamos un nivel de riesgo que sería alto.

A partir de esto, se implementan controles para mitigar o minimizar ese nivel de riesgo. Entonces, al implantar distintos controles, lo que buscamos es reducir ese nivel de riesgo a niveles aceptables para la organización. Este nivel de riesgo aceptable se conoce generalmente como el "apetito de riesgo" de la misma. Por lo tanto, el apetito de riesgo de la organización debe estar por debajo del nivel esperado.

¿Cómo se logra esto? Una vez que se identifica el riesgo, se evalúan las amenazas que afectan nuestros activos, se determina la probabilidad de ocurrencia y también se evalúa el impacto. Una vez que tenemos este nivel, se intentan implantar controles que disminuyan el riesgo. Por último, el riesgo residual, que sería el riesgo inicial menos el riesgo de aplicar los controles que mitigan ese riesgo, debe estar dentro o por debajo del apetito de riesgo de la organización. En caso de estar por debajo del apetito de riesgo, estaríamos dentro de los parámetros establecidos por el negocio. Si estamos por encima, debemos plantearnos distintas acciones a seguir.

¿Qué se hace con los riesgos que están por encima del apetito de riesgo? Existen distintas formas de gestionarlos. Una opción es mitigar ese riesgo, es decir, implantar más controles para disminuir el nivel de riesgo. Otra posibilidad es transferir el riesgo. A veces, esto se traslada a una empresa a través de un ciberseguro o mediante la implementación de ciertos sistemas en un proveedor de nube. De esta forma, estoy trasladando el riesgo de tener algún problema en mi centro de cómputos a un proveedor que me ofrece servicios de hosting para mis servidores. O, como mencioné anteriormente, puede ser que traslade el riesgo mediante la contratación de un ciberseguro.

Otra posibilidad, otra acción que se puede realizar, es aceptar el riesgo, que suele ser la opción menos utilizada. Aceptar el riesgo significa reconocer que el riesgo existe, que lo tengo identificado, pero no voy a tomar ninguna acción. Ni voy a implantar controles para disminuir el nivel de riesgo, ni tampoco voy a intentar trasladarlo. Simplemente aceptaré que ese riesgo existe y, en caso de que realmente se materialice, asumiré los costos y el impacto que me genere.

### ¿Qué es la criptografía?
La criptografía es una de las técnicas más antiguas utilizadas para proteger información. Esta técnica es tan antigua como la propia escritura.

Uno de los ejemplos más conocidos es el caso de máquina [Enigma](https://es.wikipedia.org/wiki/Enigma_(m%C3%A1quina)), usada por los Nazis durante la Segunda Guerra Mundial para cifrar los mensajes en el frente.

**La palabra criptografía proviene del griego κριπτός (kryptós = recubierto, oculto), γραφειν (grafein = escribir), y el sufijo -ia (usada para crear sustantivos abstractos).** 

El mensaje cifrado en sí está a la vista. Se puede leer, pero su significado está oculto. Así, podemos decir que mediante la criptografía una persona puede ocultar un texto o una información para que solo el emisor y el receptor puedan interpretarlo.

Con el creciente auge y desarrollo de la informática, esta fue ampliamente divulgada y modificada para su uso. Ahora se basa en complejos algoritmos matemáticos que se encargan de cifrar los mensajes.

- Tienen la tarea de garantizar confidencialidad entre las partes y la integridad de la información. 
- Ofrece la autenticación, tanto del emisor como del receptor, garantizando ambos puedan rechazar el mensaje en el caso de no cumplirla. 
- También garantiza que el mensaje es nuevo y que no es repetido.

> Las bases de la criptografía informática se establecen en los artículos “_A Mathematical Theory of Communication_” de 1948 y “_Communication Theory of Secrecy Systems_” de 1949. Ambos publicados por Claude Shannon y establecen las bases de la teoría de la información y de la criptografía moderna.

“_New directions of Cryptography_”, desarrollado por Whitfiled Diffie y Martin Hellman en 1976, establece el concepto de criptografía de clave pública. La consolidación de la criptografía llega en 1977 con la publicación del algoritmo RSA, desarrollado por los matemáticos Ron Rivest, Adi Shamir y Len Adleman.

#### Criptografía y seguridad
La criptografía es uno de los pilares fundamentales en los que se basa la tecnología Blockchain: Hace posible el funcionamiento de la red, garantiza los mecanismos de consenso entre los usuarios y la integridad de la propia Blockchain.

Para garantizar que nadie externo puede acceder a los datos se utiliza la criptografía de clave pública (criptografía asimétrica) y la criptografía de clave secreta (criptografía simétrica) que desarrollaremos más adelante. 

- El cifrado de clave pública genera un hash que hace más sencilla la distribución de la información.
- La clave privada cifra y descifra la información entre el emisor y el receptor.

**En Bitcoin, la clave pública se obtiene mediante la clave privada, pero el proceso inverso es imposible de realizar. Es decir, no se puede obtener la clave privada a raíz de la clave pública. La clave pública, tras unas modificaciones posteriores, es la dirección que podemos compartir con todos los miembros de la comunidad para que nos envíen dinero. O en su caso, la que usaremos de otros usuarios de la comunidad para realizarles algún pago. No existe ningún riesgo de robo, ya que los fondos solo son accesibles mediante la clave privada.**

La clave privada es similar a un PIN o contraseña que utilizamos para acceder a diferentes páginas web, pero que en este caso está cifrada añadiendo muchísima más seguridad. Esto quiere decir que nosotros introduciremos una serie de términos o palabras y estas se cifrarán protegiendo el wallet o monedero. 

> Solo nosotros poseemos estas palabras, por lo que debemos guardarlas con seguridad y no compartirlas con nadie. Así podremos acceder a nuestros fondos en cualquier momento.

#### Tipos de criptografía
1. Simétrica
2. Asimétrica
3. Híbrida

##### 1 | Simétrica
Se ha utilizado desde los inicios de la historia y durante mucho tiempo. También es conocida como criptografía de clave privada o criptografía de una clave.

Para llevarla a cabo y poder cifrar y descifrar un mensaje, se emplea una única clave que tanto el emisor como el receptor deben conocer previamente. Este es el punto débil de este método, ya que hay más probabilidad de que un tercero intercepte la clave cuando el emisor se la transmita al receptor.

En la criptografía simétrica se debe emplear una clave muy difícil de adivinar, debido a que los ordenadores actuales pueden adivinar claves muy rápidamente. Por ello, debemos considerar que como los algoritmos criptográficos son públicos, se debe garantizar que su fortaleza depende de su complejidad interna y de la longitud de la clave empleada, para evitar los ataques de fuerza bruta.

![[377.B7_cifrado.png]]

##### 2 | Asimétrica
Conocida como criptografía de clave pública. Este método hace uso de dos claves, una pública y una privada; por lo que no es necesario conocer una clave previamente.

La clave pública puede ser enviada y dada a conocer a cualquier persona, mientras que la clave privada es la que no se debe compartir con nadie. Cuando un emisor desea enviar un mensaje, este usa la clave pública para cifrar el mensaje y lo envía. Y solo el receptor con su clave privada puede descifrar el mensaje.

La criptografía asimétrica brinda un nivel de seguridad extraordinario, al punto de que ni siquiera la persona que cifró el mensaje, puede descifrarlo sin la clave privada. Este es el método utilizado en las criptomonedas y es una pieza fundamental en la Blockchain para poder realizar operaciones e intercambios de información entre iguales, con total seguridad y sin necesidad de confiar entre sí.

##### 3 | Híbrida
Es un método que usa tanto un cifrado simétrico como un asimétrico. Empleando el cifrado de clave pública para compartir una clave para el cifrado simétrico.

Conociendo los conceptos básicos de la criptografía simétrica y la criptografía asimétrica, podemos darnos cuenta de cuál es su mayor diferencia. 

La seguridad que aporta la Criptografía Simétrica es de un nivel muy bajo si lo comparamos con la seguridad que aporta la Asimétrica. En cambio, la rapidez con que la criptografía simétrica cifra y descifra un mensaje es superior a la de la criptografía asimétrica. De aquí surge la criptografía híbrida.

### Introducción a la Criptografía (Video)
![[378.B7_Introducción_a_la_Criptografía.mp4]]
[Introduccion a la Criptografia](https://app.web3mba.io?wvideo=9l86rcl2gb)

Una de las técnicas más antiguas utilizadas para proteger la información es la criptografía. Esta técnica es tan antigua como la escritura, y uno de los muchos ejemplos que encontramos sobre su uso es el interesante caso de la historia de la máquina Enigma, utilizada por los nazis durante la Segunda Guerra Mundial para cifrar los mensajes en el frente de batalla. La palabra criptografía proviene del griego "kryptos", que significa oculto, "grafén", que significa escribir, y el sufijo "ia", que se utiliza para crear sustantivos abstractos. El mensaje cifrado sí está a la vista, se puede leer, pero su significado es oculto. Así podemos decir que, mediante la criptografía, una persona puede ocultar un texto o una información para que solo el emisor y el receptor puedan interpretarlo.

Con el creciente auge y desarrollo de la informática, esta técnica fue ampliamente divulgada y modificada para su uso. Ahora se basa en complejos algoritmos matemáticos que se encargan de cifrar los mensajes. Tiene la tarea de garantizar la confidencialidad entre las partes y la integridad de la información, a su vez que ofrece la autenticación tanto del emisor como del receptor. Esto garantiza que el emisor o el receptor pueda repudiar el mensaje y, por último, asegura que el mensaje es nuevo, es decir, que no es repetido. Las bases de la criptografía informática se establecen en los artículos "A Mathematical Theory of Communication" y "Communication Theory of Secrecy Systems" de 1949, ambos publicados por Claude Shannon, que establecen las bases de la teoría de la información y de la criptografía moderna. Más adelante, Whitfield Diffie y Martin Hellman, en 1976, establecieron el concepto de la criptografía de clave pública. La consolidación de la criptografía llegó en 1977 con la publicación del algoritmo RSA, desarrollado por los matemáticos Rivest, Shamir y Adleman.

Hoy en día, la criptografía es uno de los pilares fundamentales en los que se basa la tecnología blockchain. Esta permite el funcionamiento de la red, garantiza los mecanismos de consenso entre los usuarios y la integridad del blockchain. Para garantizar que nadie externo pueda acceder a los datos, se utiliza la criptografía de clave pública, la criptografía simétrica y la criptografía de clave secreta, que es la simétrica, que desarrollaremos más adelante. El cifrado de clave pública genera un hash, que hace más sencilla la distribución de información, mientras que la clave privada cifra y descifra la información entre el emisor y el receptor. En Bitcoin, la clave pública se obtiene mediante la clave privada, pero el proceso inverso es imposible de realizar. Es decir, no se puede obtener la clave privada a partir de la clave pública. La clave pública, tras unas modificaciones posteriores, es la dirección que podemos compartir con todos los miembros de la comunidad para que nos envíen su dinero, o en su caso, la que usaremos de otros usuarios de la comunidad para realizarles algún pago. No existe ningún riesgo de robo, ya que los fondos solo son accesibles mediante la clave privada.

La clave privada es similar a un PIN o una contraseña que utilizamos para acceder a diferentes páginas web, pero en este caso está cifrada, añadiendo muchísima más seguridad. Esto quiere decir que nosotros introduciremos una serie de términos o palabras, llamadas semillas, y estas se cifrarán y protegerán la seguridad del wallet o el monedero. Solo nosotros poseeremos esas palabras, por lo que debemos guardarlas con seguridad y no compartirlas con nadie. Así podemos acceder a nuestros fondos en cualquier momento y con total seguridad.

La historia de la criptografía la podemos rastrear hacia miles de años atrás en nuestra historia. De hecho, el uso más antiguo conocido de la criptografía puede verse en los jeroglíficos no estándares tallados en monumentos del Antiguo Egipto, hace más de 4,500 años. Sin embargo, los eruditos siempre han usado medios escritos o simbólicos para ocultar información. Quizás uno de los mayores ejemplos de criptografía antigua lo podemos ver en los romanos. Durante el imperio, se hizo amplio uso del conocido cifrado César para enviar y recibir información delicada, de tal forma que, incluso en manos enemigas, esta no pudiera servir de nada sin saber cómo descifrarla de forma correcta. Se trata de un tipo de descifrado alfabético bastante sencillo que consiste en rotar las letras del alfabeto un número determinado para escribir mensajes, creando así algo que no tenía sentido a menos que se descifrara el mensaje realizando la operación contraria. Para tener éxito en este sistema, quien enviaba y recibía la información debía saber el número que se había escogido para realizar la operación de cifrado. Es un ejemplo básico de criptografía simétrica.

La criptografía moderna, tal como la conocemos, comenzó sus primeros pasos con la creación del manuscrito sobre el desciframiento de mensajes criptográficos realizado por Al-Kindi y el Instituto de Ciencia que trabajaba en la Casa de la Sabiduría de Bagdad, alrededor del año 820 d.C. Este documento es considerado el primer texto de criptoanálisis del mundo, ya que relata el método para romper cualquier tipo de criptografía alfabética, que era lo que se conocía hasta entonces. Básicamente, con este documento, la criptografía quedó inutilizada y ninguno de los medios usados hasta entonces era seguro. No fue hasta la creación de la criptografía polialfabética por parte de Alberti en 1465 que la criptografía volvió a tener un medio seguro para su uso. Sin embargo, la creación de Alberti no fue la única que abrió el nuevo camino hacia la criptografía segura y moderna, sino que también en esas mismas fechas, religiosos, alquimistas y ocultistas habían creado otros sistemas criptográficos completamente ajenos, más que todo impulsados por símbolos y letras que no tenían ningún sentido para el ojo o mente no entrenada.

En medio de estas operaciones, se pueden destacar documentos como el manuscrito Borinx, el libro Soiga y el códice P. Ale... Algunos de estos escritos son tan enrevesados que, incluso hoy en día, no hay traducción posible de los mismos. Pero en medio del oscurantismo y del Renacimiento, la criptografía jugó un papel fundamental tanto a nivel político, científico como religioso. Por un lado, algunos querían ocultar sus conocimientos y, por otro, darlos a conocer al resto de sus compañeros de investigación, sin correr el riesgo de que asociaciones religiosas o cualquier persona maliciosa pudiera poner en riesgo tales descubrimientos o información. Por otro lado, los religiosos siguieron desarrollando sus propios sistemas para ocultar mensajes al poder político y militar de los reyes, y los reyes, a su vez, hicieron lo mismo por su parte. Podríamos decir que era una sociedad que usaba la criptografía para cuidar de su privacidad, algo que en la actualidad está perfectamente representado.

Sea como sea, después de la creación de Alberti en 1465, la criptografía floreció y mejoró rápidamente, pero al mismo tiempo mejoraban los sistemas de criptoanálisis y las herramientas para romper dichos secretos. No fue hasta el siglo XX cuando la criptografía comenzaría una nueva revolución. La Primera y Segunda Guerra Mundial fueron momentos en los que la criptografía avanzó a pasos agigantados, haciendo de la necesidad virtud. El objetivo era llevar la información del frente y del enemigo hasta los comandantes y las tropas de campo de forma segura. Para esto, la mayoría de los sistemas criptográficos terminaron abandonando los sistemas polialfabéticos y pasaron a convertirse en funciones matemáticas complejas. Los primeros fueron usados durante la Primera Guerra Mundial, y romperlos muchas veces no suponía ningún gran esfuerzo, incluso aunque se erraran los códigos de forma continua. Pero los segundos se convirtieron en todo un reto, especialmente cuando la máquina para hacerlas posibles era mecánico-eléctrica, como el caso de la máquina Enigma del ejército alemán. El principal problema es que estos equipos tenían una enorme cantidad de combinaciones posibles, siendo solo una la correcta. De allí que los criptoanálisis aplicados muchas veces no sirviesen de nada, porque día tras día la combinación cambiaba y todo lo descubierto ya no funcionaba.

No fue hasta que los avances de la inteligencia polaca, en manos del matemático Ryzynski, ofrecieron algunas luces para romper Enigma. Pero aún faltaba algo: procesar rápidamente los datos para descubrir la combinación y romper el cifrado. En este punto es donde entran Welchman y Turing, quienes hicieron su entrada creando lo que sería considerada la primera computadora del mundo, todo ello con el fin de romper Enigma, y lo lograron. Con esto se iniciaba una revolución. La criptografía pasaba a ser parte del mundo computacional y puramente matemático. La era de la criptografía moderna comienza realmente con Shannon, que podría considerarse el padre de la criptografía matemática. En 1949, publicó un artículo sobre sistemas de secreto y, poco después, un libro sobre teoría matemática de la comunicación, junto con Warren Weaver. Estos trabajos, junto con otros que publicó sobre la teoría de la información y la comunicación, establecieron una sólida base teórica para la criptografía y el criptoanálisis moderno.

Aunque irónico, el pilar fundamental de la criptografía moderna nació en el seno de la Agencia Nacional de Seguridad de Estados Unidos, la famosa NSA. En un primer momento, esta acaparó y bloqueó casi totalmente la publicación de cualquier avance en el campo de la criptografía desde principios de la década de los 50 hasta mediados de los 70. Este periodo de tiempo fue conocido como el oscurantismo criptográfico, y su principal aliciente era evitar que la criptografía avanzada cayera en manos del bloque soviético. Estábamos en plena Guerra Fría y con los peligros de una guerra nuclear sobre el mundo. Por esta razón, casi toda la información disponible sobre el tema era muy básica y totalmente anticuada. Sus estrategias para conseguirlo fueron las siguientes: la NSA disponía de un importante presupuesto, lo que permitía pagar bien a sus empleados y disponer de una plantilla de colaboradores amplia, así como conseguir equipamiento de difícil acceso por su precio. Esto conseguía atraer a los mejores investigadores en criptografía.

En segundo lugar, para trabajar o colaborar y recibir cursos o recursos de la NSA, a los investigadores se les obligaba a mantener secreta la información y someter sus futuros trabajos al control de la NSA. Esto provocaba que, para acceder a cierto tipo de información, era necesario permanecer en ese grupo de colaboradores de la NSA. Se presionaba para que no se publicaran artículos o libros sobre criptografía o sobre la propia NSA. Por ley, revelar información sobre criptografía de la Segunda Guerra Mundial era un acto de traición. La ley se empleó para incluir a la criptografía como una forma de arma, quedando vetada para su exportación en los Estados Unidos, una ley que aún está activa. En quinto lugar, la NSA supervisaba todas las solicitudes de patentes relacionadas con la criptografía y estaba autorizada por ley para clasificar como secreto cualquier idea que considerara peligrosa fuera de dominio público. Y, por último, en sexto lugar, la NSA presionaba para cerrar, incluso antes de que se llegaran a abrir, proyectos de investigación que consideraran amenazantes. Por ejemplo, consiguió cerrar el proyecto de investigación criptográfica del Centro de Investigación de la Fuerza Aérea de Cambridge, en el que trabajaba Feistel. Posteriormente, él mismo achacó a la NSA el no conseguir organizar un proyecto de investigación sobre criptografía en el ámbito de las organizaciones sin ánimo de lucro norteamericanas, que todos conocemos como MITRE.

Todos estos puntos provocaban que muchos investigadores acabaran colaborando con la NSA, ya que llegaban a la idea de que, renunciando a colaborar con ella, jamás descubrirían nada que valiese la pena ni tendrían una carrera profesional satisfactoria. A mediados de los 70, se vivieron dos importantes avances públicos, es decir, no secretos. El primero fue la publicación del borrador del Data Encryption Standard en el Registro Federal estadounidense en 1975. La propuesta fue enviada por IBM por invitación de la Oficina Nacional de Estándares, ahora lo que denominamos NIST. Es un esfuerzo por desarrollar sistemas de comunicación electrónica segura para las empresas, como los bancos y otras grandes organizaciones financieras. Ahora ya se tenía esa necesidad por parte de las empresas de cara a tener unas transmisiones seguras. Tras el asesoramiento y ciertas modificaciones por parte de la NSA, fue adoptado y publicado como un proyecto de desarrollo, el Federal Information Processing Standard en 1977. El DES, que es como lo conocemos, fue el primer cifrado accesible públicamente que fue bendecido por la Agencia Nacional de Seguridad. La publicación de sus especificaciones por la NBS estimuló una explosión de interés público y académico por la criptografía.

Este no fue el único gran avance de esa época. En 1976 se hizo pública la creación de la criptografía simétrica, la cual fue inventada por Merkle, Diffie y Hellman. Este esquema de claves privadas y públicas garantiza el establecimiento de comunicaciones completamente seguras, incluso por canales inseguros, razón por la cual la actualización de este sistema criptográfico es el más usado. Un claro ejemplo son las estructuras públicas y privadas que permiten la comunicación por Internet, donde se hace uso de la criptografía simétrica para garantizar la privacidad de las comunicaciones. Este fue el mayor avance en el mundo de la criptografía desde la antigüedad y las bases para la criptografía que usamos diariamente en Internet y en el mundo de las criptomonedas.

Uno de los principales casos de uso de la criptografía lo podemos ver aplicado en Internet. En la red de redes, la mayor parte del tráfico está cifrado usando criptografía asimétrica, con el fin de que nuestros datos y la interacción que mantenemos con los distintos sitios no puedan ser espiados ni manipulados por terceros. Por ejemplo, esto lo puedes ver en la página de Twitter. Verás que, cada vez que accedes a la web principal de B2Me, tu navegador web realiza una llamada que inicia un proceso de comunicación cifrado usando criptografía simétrica, utilizando el estándar TLS 1.3 y el protocolo QUIC. Como resultado de esto, no solo la velocidad de la conexión entre tu navegador y el servidor web de B2Me es muy rápida, sino que el sistema de comunicación cifrado de B2Me es seguro, evitando que terceros puedan escuchar y espiar la conexión. Para lograr esto, se usa un certificado de seguridad que utiliza una criptografía simétrica denominada ECDSA P256 de curva elíptica, que es una variante del algoritmo DSA que emplea operaciones sobre puntos de las curvas elípticas en lugar de las exponenciaciones que usa la DSA, que se basa en el problema de logaritmo discreto, el cual se encarga de todo este proceso de cifrado de manera totalmente transparente para el usuario. Por supuesto, este ejemplo se repite en la gran mayoría de sitios web que hay en Internet, algunos con mayor o menor seguridad dependiendo de sus configuraciones, pero todos buscando el mismo objetivo: proteger la información de ojos indiscretos.

También los teléfonos móviles son otro ejemplo donde la criptografía tiene un gran uso. Con el lanzamiento de las redes GSM, se estableció la necesidad de un sistema de cifrado que protegiera las conexiones de nuestros teléfonos que tuvieran cola central inalámbrica. En un principio, este sistema estaba relacionado con los algoritmos A3, que eran los encargados de la autenticación y que permitían que cada teléfono móvil fuera único dentro de la red y pudiera identificar a su propietario. Después teníamos A5, el cual era el algoritmo de cifrado de la voz. Gracias a él, la conversación va encriptada. Se trata de un algoritmo de flujo con una clave de 64 bits. Hay dos versiones, la A51 y la A52. Esta última es para la nueva versión autorizada para exportación y, en consecuencia, resulta más fácil de atacar. Esto es consecuencia de la segunda, CryptoWall, que en los años 90, cuando el estándar GSM estaba siendo definido, se pidió crear estándares débiles para poder espiarnos si era necesario. Y tercero, el A8, finalmente es el algoritmo que genera claves tanto para la autenticación en el A3 como para la encriptación en el A5. Básicamente, se trata de una función unidireccional parecida a las funciones hash de tipo MD5 o SHA1, que permite la firma digital en documentos electrónicos. Después también tenemos el COM128, que es un algoritmo que permite funcionar a los A3 y A8. Las especificaciones de GSM permiten el uso de varios tipos de algoritmos como corrección de estos A3 y A8. COM128 es uno de ellos, no es el único posible, pero es de los más utilizados. Estos algoritmos los vimos aplicados en los conocidos protocolos 2G y, con la llegada del 3G, el sistema mejoró especialmente con la llegada de un nuevo modelo de A53 conocido como KASUM, con una mejor criptografía que cuesta más romper, pero que no se aplica por defecto y depende de la operadora. Finalmente, con la llegada del 4G y 5G, llegan los sistemas de criptografía completa aplicada en ambas partes para proteger mejor la seguridad, pero eso se puede romper a nivel de radio básica.

La tecnología blockchain es otro espacio donde podemos ver aplicada la criptografía en todo su esplendor. El funcionamiento de esta tecnología depende de la misma para la práctica totalidad de todas sus tareas. La creación de un nodo utiliza la criptografía y funciones hash para generar claves públicas y privadas que le permitan controlar sus criptomonedas y, al mismo tiempo, le permiten identificarse como un nodo válido dentro de la red P2P. Se usa la criptografía a la hora de generar transacciones, firmarlas y emitirlas para que un tercero pueda usar dicha información tras lograr completar el puzzle criptográfico que les da acceso a esos recursos. Incluso se puede usar criptografía para añadir funciones de privacidad y anonimato para los usuarios de la red, entre otras funciones que puedan ser generadas usando la red de blockchain.

### Historia de la criptografía
El uso más antiguo conocido de criptografía se puede ver en jeroglíficos no estándares tallados en monumentos del Antiguo Egipto (hace más de 4500 años).

Sin embargo, los eruditos siempre han usado medios escritos o simbólicos para ocultar información.

Quizás uno de los mayores ejemplos de criptografía antigua la podemos ver en la civilización Romana. 

- Durante el Imperio, se hizo amplio uso del conocido [Cifrado César](https://es.wikipedia.org/wiki/Cifrado_C%C3%A9sar) para enviar y recibir información delicada de tal forma, que incluso en manos enemigas, esta no sirviera de nada sin saber cómo descifrar la misma de forma correcta. 
- Un tipo de cifrado alfabético bastante sencillo que consistía en rotar las letras del abecedario, un número determinado, para escribir el mensaje y de esta forma crear algo que no tenía sentido, a menos que se descifrará el mensaje realizando la operación contraria. 
- Para tener éxito en este sistema, quien enviaba y recibía la información sabía qué número era el escogido para realizar la operación de cifrado. Un ejemplo claro de criptografía simétrica. 

#### Los primeros pasos hacia la criptografía moderna
La criptografía moderna, tal como la conocemos, comienza con la creación del "Manuscrito sobre el desciframiento de mensajes criptográficos", por _Abu Yusuf Yaqub ibn Ishaq al-Sabbah Al-Kindi_ que trabajaba en "Casa de la Sabiduría de Bagdad", en el año de 820 d.C.

Este documento es considerado el primer documento de criptoanálisis del mundo, ya que se relata un método para romper cualquier tipo de criptografía alfabética conocida hasta entonces. Básicamente, con este documento la criptografía quedo inutilizada y ninguno de los métodos usados para entonces era seguro. No fue hasta la creación de la criptografía poli alfabética por parte de Leon Battista Alberti (1465), que la criptografía volvió a tener un medio seguro para su uso. 

Sin embargo, la creación de Leon Battista Alberti no fue la única que abrió de nuevo el camino a la criptografía segura (y moderna). En esas mismas fechas, religiosos, alquimistas y ocultista, habían creado sistemas criptográficos completamente fuera de sí, más que todo impulsados por símbolos y “letras” que no tienen ningún sentido para el ojo y mente no entrenada. En medio de esas creaciones, se pueden destacar documentos cómo el Manuscrito Voynich, el Libro de Soyga, el Codex Rohonczi o el Codex de Copiale. Algunos de estos escritos son tan enrevesados que incluso hoy en día no hay traducción posible de los mismos. 

> En medio del Oscurantismo y el Renacimiento, la criptografía jugó un papel fundamental tanto a nivel político, científico y religioso.

Por un lado, algunos querían ocultar sus conocimientos, dándolos a conocer al resto de sus compañeros de investigación sin correr el riesgo de que la Inquisición o cualquier persona maliciosa pudiera poner en riesgo tal información. 

Por el otro, los religiosos siguieron desarrollando sus propios sistemas para ocultar mensajes del poder político y militar de los Reyes, y los Reyes hicieron lo mismo por su parte. Podríamos decir que era una “sociedad que usaba la criptografía para cuidar de su privacidad” algo que en la actualidad está perfectamente representada. 

Sea como sea, después de la creación de Alberti, la criptografía floreció y mejoró rápidamente. Pero al mismo tiempo, mejoraban los sistemas de criptoanálisis y las herramientas para romper dichos secretos. No fue hasta el siglo XX, cuando la criptografía comenzaría una nueva revolución.

#### Criptografía y las Guerras Mundiales
La Primera y Segunda Guerra Mundial fueron momentos en los que la criptografía avanzó a pasos agigantados. 

El objetivo era claro: Llevar la información del frente y del enemigo hasta los comandantes y las tropas del campo de forma segura. 

**Para hacer eso, la mayoría de los sistemas criptográficos terminaron abandonando los sistemas poli alfabéticos y pasaron a convertirse en funciones matemáticas complejas.** 

Los primeros fueron usados durante la Primera Guerra y romperlos muchas veces no suponía gran esfuerzo, incluso aunque se rotaran los códigos de forma continua. Pero los segundos se convirtieron en todo un reto, especialmente cuando la maquinaría para hacerlas posible era mecánico-eléctrica, como el caso de la máquina Enigma del Ejército Alemán. El principal problema es que estos equipos tenían una enorme cantidad de combinaciones posibles, siendo una sola correcta. De ahí que los criptoanálisis aplicados muchas veces no sirvieran de nada, porque día tras día la combinación cambiaba, y todo lo descubierto ya no funcionaba. 

No fue hasta que los avances de la inteligencia polaca, en manos del matemático Marian Rejewski, arrojaron algunas luces para romper Enigma. Pero aún faltaba algo: procesar rápidamente los datos para descubrir la combinación y romper el cifrado. Fue en este punto donde Gordon Welchman y Alan Turing hicieron su entrada, creando la que sería considerada la primera “computadora” del mundo, todo ello con el fin de romper a Enigma. Y lo lograron. Con esto, se iniciaba una revolución: la criptografía pasaba a ser parte del mundo computacional y puramente matemático.

#### Criptografía moderna
La era de la criptografía moderna comienza realmente con Claude Shannon, que podría decirse que es el padre de la criptografía matemática.

**En 1949 publicó el artículo Communication Theory of Secrecy Systems en la Bell System Technical Journal, y poco después el libro Mathematical Theory of Communication, con Warren Weaver.** Estos trabajos, junto con los otros que publicó sobre la teoría de la información y la comunicación, establecieron una sólida base teórica para la criptografía y el criptoanálisis moderno hasta ahora.

Aunque irónico, el pilar fundamental de la criptografía moderna nació en el seno de la NSA de Estados Unidos. En un primer momento, la NSA acaparó y bloqueó casi totalmente la publicación de cualquier avance en el campo de la criptografía desde principios de la década de 1950 hasta mediados de los 70.

Este periodo de tiempo fue conocido como el “Oscurantismo Criptográfico” y su principal aliciente era evitar que la criptografía avanzada cayera en manos del bloque soviético, en plena Guerra Fría y con los peligros de una guerra nuclear sobre el mundo. 

Por esta razón, casi toda la información disponible sobre el tema era la básica y estaba totalmente anticuada. Sus estrategias para conseguir esto fueron las siguientes:
1. **La NSA disponía de un importante presupuesto, lo que le permitía pagar bien a sus empleados, disponer de una plantilla de colaboradores amplia y de conseguir equipamiento de difícil acceso por su precio.** Esto conseguía atraer a los mejores investigadores en criptografía.
2. **Para trabajar, colaborar o recibir cursos y/o recursos de la NSA, a los investigadores se les obligaba a mantener secreta la información y someter sus futuros trabajos al control de la NSA.** Esto provocaba que para acceder a cierto tipo de información era necesario pertenecer al grupo de “colaboradores de la NSA”.
3. **Se presionaba para que no se publicaran artículos o libros sobre criptografía y sobre la propia NSA.** Por ejemplo, se presionó a David Kahn para evitar la publicación de su libro _Codebreakers_. Finalmente, la NSA consiguió quitar tres fragmentos específicos del libro.
4. **Por ley, revelar información sobre criptografía de la II Guerra Mundial era un acto de traición.** La Ley se amplió para incluir a la criptografía como una forma de arma, quedando vetada para su exportación en los Estados Unidos (una ley que aún está activa). 
5. **La NSA supervisaba todas las solicitudes de patentes relacionadas con la criptografía y estaba autorizada por ley para clasificar como secreto cualquier idea que considerara peligrosa que fuera de dominio público.**
6. **La NSA presionaba para cerrar o incluso que no se llegaran a abrir proyectos de investigación que considerar amenazantes.** Por ejemplo, consiguió cerrar el proyecto de investigación criptográfica del Centro de Investigación de la Fuerza Aérea de Cambridge, en el que trabajaba Horst Feistel. Posteriormente, el mismo Horst Feistel achacó a la NSA el no conseguir organizar un proyecto de investigación sobre criptografía en el MITRE.

Todos estos puntos provocaban que muchos investigadores aceptaran colaborar con la NSA, ya que llegaban a la idea de que renunciado a colaborar con ella jamás descubrirían nada que valiese la pena ni tendrían una carrera profesional satisfactoria.

#### Los primeros estándares y la llegada de la criptografía asimétrica
A mediados de los 70 se vivieron dos importantes avances públicos (es decir: no secretos). 

El primero fue la publicación del borrador del _Data Encryption Standard_ en el Registro Federal estadounidense el 17 de marzo de 1975. La propuesta fue enviada por IBM, por invitación de la Oficina Nacional de Estándares (ahora NIST), en un esfuerzo por desarrollar sistemas de comunicación electrónica segura para las empresas como los bancos y otras organizaciones financieras grandes.

Tras el asesoramiento y ciertas modificaciones por parte de la NSA, fue adoptado y publicado como un _Federal Information Processing Standard_ en 1977 (actualmente el FIPS 46-3). El DES fue el primer cifrado accesible públicamente que fue «bendecido» por una agencia nacional como la NSA. La publicación de sus especificaciones por la NBS estimuló una explosión del interés público y académico por la criptografía. 

Sin embargo, este no fue el único gran avance en esa época. En 1976, se hizo pública la creación de la criptografía asimétrica, la cual fue inventada por Ralph Merkle, Whitfield Diffie y Martin Helman. Este esquema de claves privadas y públicas garantiza el establecimiento de comunicaciones completamente seguras, incluso sobre canales inseguros. Razón por la que en la actualidad este sistema criptográfico es el más usado. Un claro ejemplo son las estructuras públicas y privadas que permiten la comunicación por internet, donde se hace uso de criptografía asimétrica para garantizar la privacidad de las comunicaciones. Este fue el mayor avance en el mundo de la criptografía desde la antigüedad y la base para la criptografía que usamos diariamente en Internet y el mundo de las criptomonedas. 

#### The Imitation Game
Biopic sobre el matemático británico Alan Turing, famoso por haber descifrado los códigos secretos nazis contenidos en la máquina Enigma.

Su invento determinó el devenir de la Segunda Guerra Mundial (1939-1945) en favor de los Aliados. Lejos de ser admirado como un héroe, Turing fue acusado y juzgado por su condición de homosexual en 1952.

### Casos de uso de la criptografía
#### Internet
Uno de los principales casos de uso de la criptografía lo podemos ver aplicado en Internet. La mayor parte del tráfico está cifrado usando criptografía asimétrica, esto con el fin de que nuestros datos y la interacción que mantenemos con los distintos sitios no puedan ser espiados o manipulados por terceros maliciosos.

**Un ejemplo de esto lo puedes ver cuando entras a Bit2Me.** 

- Cada vez que accedes a la web principal, tu navegador Web realiza una llamada que inicia un proceso de comunicación cifrada con criptografía asimétrica usando el estándar TLS v1.3 y el protocolo QUIC. 
- Como resultado de esto, no solo la velocidad de conexión entre tu navegador y el servidor Web de Bit2Me es rápida, sino que está protegida para evitar que terceros puedan escuchar y espiar la conexión. 
- Para lograr esto, se usa un certificado de seguridad que usa criptografía asimétrica ECDSA_P256, el cual se encarga de todo este proceso de cifrado de manera totalmente transparente para ti. 

Por supuesto, este ejemplo se repite en la gran mayoría de sitios webs que hay en Internet. Algunos con mayor o menos seguridad, dependiendo de su configuración, pero todos buscando un mismo objetivo: proteger tu información de ojos indiscretos.

![[380.B7_wannacry.png]]
![[380.B7_oooops.png]]

WannaCry es un ejemplo de _ransomware_ de cifrado, un tipo de software malicioso (_malware_) que los cibercriminales utilizan a fin de extorsionar a un usuario para que pague.

#### Teléfonos móviles
Con el lanzamiento de las redes GSM, se estableció la necesidad de un sistema de cifrado que protegiera las conexiones que nuestros teléfonos tuvieran con la central inalámbrica. En un principio, ese sistema estaba relacionado con los algoritmos:
1. **A3, el cual estaba encargado de la autenticación y que permitía que cada teléfono móvil sea único dentro de la red,** así se puede identificar al móvil y con la base de datos de la operadora se puede asociar al usuario propietario, permitiendo, entre otras cosas, saber a quién hay que cobrar la llamada.
2. **A5, el cual era el algoritmo de cifrado de voz. Gracias a él, la conversación va encriptada. Se trata de un algoritmo de flujo con una clave de 64 bits.** Hay dos versiones, denominadas A5/1, y A5/2. Esta última es la versión autorizada para la exportación, y en consecuencia resulta más fácil de atacar. Esto es consecuencia de la Segunda Crypto Wars, en los años 90, cuando el estándar GSM estaba siendo definido y se pidió crear estándares débiles para poder espiarlos si era necesario.
3. **A8, finalmente, es el algoritmo que genera claves tanto para autenticación (el A3) como para encriptación (el A5).** Básicamente, se trata de una función undireccional parecida a las funciones hash, del tipo MD5 o SHA-1, que permiten la firma digital en los documentos electrónicos.
4. **COMP128, es un algoritmo que permite funcionar a los A3 y A8. Las especificaciones GSM permiten el uso de varios tipos de algoritmos como “corazón” del A3 y A8. COMP128 es uno de ellos.** No es el único posible, pero sí uno de los más usados.

**Estos algoritmos los vimos aplicados en los conocidos protocolos 2G GSM.** Con la llegada de 3G GSM, el sistema mejoró (especialmente con la llegada de un nuevo modelo A5/3 conocido como KASUMI, con una mejor criptografía que cuesta más romper, pero que no se aplica por defecto y depende de la operadora), y finalmente con la llegada de 4G y 5G GSM, llegan los sistemas de criptografía completa aplicada en ambas partes para obtener una mejor seguridad (pero que pueden romperse en cuanto a radiobases). 

#### Blockchain
La tecnología Blockchain es otro espacio donde podemos ver aplicada la criptografía en todo su esplendor. El funcionamiento de esta tecnología depende de la misma para la práctica totalidad de sus tareas.

**La creación de un nodo uso criptografía y funciones hash para generar las claves públicas y privadas que le permiten controlar sus criptomonedas, y al mismo tiempo, le permiten identificarse como un nodo válido dentro de una red P2P.** 

Se usa criptografía a la hora de generar transacciones, firmarlas y emitirlas, para que un tercero pueda usar dicha información tras lograr completar el puzzle criptográfico que les da acceso a esos recursos. Incluso, se puede usar criptografía para añadir funciones de privacidad y anonimato para los usuarios de la red, entre otras funciones que puedan ser generadas usando la red Blockchain.


## U2. Sistemas Criptográficos
### Sistemas Criptográficos (Video)
![[381.B7_Sistemas_Criptográficos.mp4]]
[Sistemas Criptograficos](https://app.web3mba.io?wvideo=2j5lzoueg1)

Casi tan antigua como la escritura misma, la criptografía ha sido utilizada durante años para proteger los mensajes. Podemos remontarnos a muchos años atrás, en épocas donde había batallas en las cuales se enviaba un mensajero, que en su momento podía ser incluso a pie, para hacer llegar un mensaje al ejército que estaba desplegado en otra ubicación. Muchas veces, ese mensaje era interceptado por fuerzas enemigas y, durante la batalla, lo que se hacía era enviar ese mensaje de una forma que, cuando era interceptado por el enemigo, intentaban leerlo, pero era prácticamente imposible. Cuando intentaban leer el mensaje, lo que veían eran letras unas al lado de otras, sin un sentido aparente de qué era lo que se estaba enviando.

Este tipo de mensajes que se usó a la hora de lanzar el misil, hace muchos años, principalmente en batallas, lograba que, una vez que el mensaje llegara al otro ejército, se utilizara una plantilla que se colocaba encima de ese papel, de esa hoja con el mensaje. La plantilla ocultaba ciertas letras y dejaba ver otras, con el fin de que, al colocarla sobre la hoja de papel, se pudiera leer el mensaje. Esto es lo que se conoció como tecnología de cifrado y es uno de los principales usos que se le daba hace muchos años para poder enviar mensajes en épocas de guerra y batallas.

Recientemente, en la Segunda Guerra Mundial, también podemos destacar, durante la Alemania nazi, la creación de la máquina Enigma, que, a través de mecanismos un poco más sofisticados que los anteriores, lograba cifrar los mensajes que se enviaban en aquella época y, de esta forma, comunicar las órdenes sin que el enemigo pudiera detectar cuál era el mensaje que se estaba enviando. El uso de la criptografía siempre ha sido proteger la información para que solo aquellas personas a quienes estaba destinada pudieran leerla.

Veremos tres conceptos importantes respecto al uso de la criptografía. Por un lado, veremos lo que son claves simétricas; luego, lo que son claves asimétricas; y, por último, lo que son funciones hash. ¿Qué es una clave simétrica? Es un tipo de cifrado en el cual se utiliza una única clave para cifrar y descifrar la información. Para poner un caso práctico, si quiero enviar un archivo a una persona y lo cifro, tendría que enviarle la clave con la cual lo he cifrado para que la persona, utilizando dicha clave, pueda descifrar el mensaje que le estoy enviando.

Si bien el uso de este tipo de claves simétricas es mucho más rápido en cuanto a procesamiento, tanto para cifrar como para descifrar, que lo que son las claves asimétricas, que veremos más adelante, tiene un problema muy importante a nivel de seguridad: siempre tenemos que compartir, de una forma u otra, la clave con la cual hemos cifrado el mensaje con nuestro destinatario, para que él pueda utilizar la misma clave para poder descifrarlo. Esto hace que la utilización de claves simétricas no sea tan segura como utilizar las que veremos a continuación, que son las claves asimétricas.

Las claves asimétricas son un tipo de cifrado que permite tener un par de claves: una pública y otra privada. ¿Cuál sería el uso práctico de esto? A diferencia del caso anterior, si quiero enviar un documento o un texto cifrado, lo que haré es generar un par de claves, una pública y una privada. Compartiré con la persona que quiero que me envíe esa información cifrada la clave pública. La persona cifrará la información con mi clave pública y, cuando yo reciba el archivo, podré descifrarlo con mi clave privada para acceder a la información. Esto, como se puede observar, es mucho más sencillo, porque nunca comparto la clave que me permite acceder a la información, que en este caso sería la clave privada; lo único que hago es compartir mi clave pública.

Hoy en día, esto tiene muchos usos. Podemos decir que las claves asimétricas son las más utilizadas frente a las claves simétricas. También tenemos funciones de hash, que son algoritmos matemáticos que transforman un bloque de texto, por ejemplo, en una serie de caracteres con una longitud determinada. Un caso práctico en el cual se puede utilizar una función de hash es cuando vamos a descargar un archivo. Generalmente, anexo al archivo que vamos a descargar, tenemos algo que dice MD5, dos puntos y una cantidad de caracteres. El archivo que se subió pasó por una función hash y se generó esa serie de caracteres que vemos utilizando MD5.

¿Cuál es la función de esto? La función de esta función de hash es que puedo, a través de ella, saber si ese documento o archivo que estoy descargando fue modificado en algún momento. Si descargo ese archivo y vuelvo a ejecutar la función de hash, me debería dar la misma serie de caracteres que fueron creados cuando la persona subió ese archivo a la web. ¿Qué sucede si tengo una serie de caracteres distintos? Seguramente, ese archivo fue modificado mientras se descargaba o después de que la persona había subido ese archivo a internet. Esto que me permiten las funciones de hash es tener la inmutabilidad de la información. Cualquier cambio, por más que sea un solo carácter en un archivo, generará directamente una serie de caracteres distintos en la función de hash. De esta forma, lo que nos permite es tener la garantía y la seguridad de que ese archivo no fue modificado.

¿Cómo se relacionan todos estos conceptos de clave simétrica, asimétrica y funciones de hash con el mundo cripto y con la blockchain? El cifrado asimétrico se utiliza en la blockchain para permitir, por ejemplo, las transacciones seguras entre los nodos. También se utiliza cuando hacemos un envío o recibimos criptomonedas, por ejemplo, desde o hacia un monedero en la red; estamos utilizando lo que es el cifrado asimétrico. Luego, las funciones de hash también son utilizadas, como sabrán, en la blockchain, que es una cadena de bloques y cada bloque tiene el hash del bloque anterior. Esto nos permite verificar que, si quiero colocar un bloque en el medio de dos bloques de la cadena, la cadena se rompa, y esto nos permitirá identificar cualquier alteración que se quiera hacer a la misma. Esto garantiza que los bloques sean inmutables y que nos den seguridad de que cada bloque que está en la cadena es único y no ha sido modificado una vez que pertenece a la cadena o al blockchain.

También estas funciones y el cifrado asimétrico se usan en la creación de direcciones. Cuando uno crea su propia dirección de Bitcoin, por ejemplo, se siguen una serie de pasos, cerca de diez, que utilizan estas tecnologías para generar lo que hoy conocemos como una dirección pública de Bitcoin. A grandes rasgos y sin entrar en muchos detalles técnicos, lo que se hace es crear una clave privada utilizando un algoritmo llamado DSA, que es un algoritmo de curva elíptica. A partir de esa clave privada, se genera la clave pública, que pasa por ciertas funciones. Primero, una función de hash que utiliza el algoritmo SHA-256 y luego por otra función de hash que utiliza RIPEMD-160, que es otro algoritmo. A partir de pasar por estas distintas conversiones y funciones, logramos una cadena, una serie de caracteres que luego se utiliza en base 58 para tener una dirección pública de Bitcoin, que es la que hoy en día conocemos.

La importancia de la criptografía, como podrán ver a lo largo de la historia, ha sido bastante significativa. Siempre el objetivo es proteger la información y que solo sea leída por las personas que deben hacerlo. El uso de esta tecnología es muy importante en todo lo que es el mundo cripto y la blockchain. Básicamente, la blockchain se basa en esta tecnología y, de esta forma, a través de la misma, podemos resguardar y salvaguardar todo lo que es la cadena y la inmutabilidad de los bloques que la conforman.

### ¿Qué es la Criptografía Simétrica?
Es uno de los primeros métodos empleados para el cifrado de información. También conocida como _criptografía de clave secreta_ o _criptografía de una clave_.

Su nombre se debe a que este método emplea la misma clave tanto para el cifrado como el descifrado de un mensaje. Por lo que el emisor y el receptor deben estar previamente de acuerdo y en conocimiento de la clave a utilizar.

Un buen ejemplo de este tipo de sistema criptográfico sería el siguiente:
> Supongamos que María quiere enviar un mensaje cifrado a José. Ambos deben comunicarse previamente, y acordar cuál es la clave que van a emplear. Una vez hecho esto, María puede cifrar el mensaje y enviarlo a José, donde este con la misma clave que usó María, puede descifrar el mensaje.

**En la criptografía simétrica, toda la seguridad está centrada en la clave. Por lo que debe ser secreta y que no sea fácil de adivinar por una tercera persona. Sin embargo, con la tecnología que disponemos hoy en día, el proceso de comunicación o distribución de la clave se volvió el punto débil de este método. Esta debilidad se debe a que al comunicarse (el emisor y el receptor) para definir y acordar la clave, un tercero puede interceptar dicha comunicación, hacerse con la clave y acceder a la información contenida en el mensaje.**

Pero antes de seguir indagando en estos detalles, conozcamos un poco sobre la historia de la criptografía simétrica.

#### ¿Quiénes la desarrollaron?
Se estima que desde los tiempos del Antiguo Egipto y el Imperio Romano se empleaba la criptografía simétrica de manera muy básica, sin embargo, esta se desarrolló y fue ampliamente utilizada durante la Segunda Guerra Mundial.

Fue durante este conflicto bélico que los ejércitos emplearon y desarrollaron poderosos sistemas criptográficos simétricos. Todo con el fin de codificar los mensajes y protegerlos de los enemigos.

Luego de estos sucesos, la era de la criptografía simétrica moderna sufrió toda una revolución hasta llegar a lo que conocemos hoy en día. Todo gracias al trabajo de investigadores y científicos dedicados a este campo. Sin embargo, un nombre destaca sobre todos los demás, el de Claude Shannon. Shannon es conocido como el padre de la criptografía matemática.

Los trabajos de Shannon se desarrollaron a partir de 1949, cuando publicó un artículo llamado _Communication Theory of Secrecy Systems_. En este artículo se describe la modernización de las técnicas de encriptado conocidas hasta entonces, con procesos matemáticos avanzados que le brindaban un mayor nivel de complejidad y seguridad. Más tarde escribió un libro con el informatólogo Warren Weaver. Todo este conjunto de trabajos realizados se convirtieron en las bases de la criptografía simétrica moderna.

#### Breve historia de su desarrollo y evolución
El primer avance notable en la criptografía simétrica fue descrito por el tercer presidente de Estados Unidos, Thomas Jefferson, entre 1790 y 1780. Este fue llamado _rueda de cifrado_ o [_cilindro de Jefferson_](https://es.wikipedia.org/wiki/Discos_de_Jefferson). Consistía en un eje que poseía 26 cilindros giratorios que tenían grabados las 26 letras del abecedario de forma aleatoria.

Usando este curioso artefacto, el emisor podía escribir el mensaje en una línea y luego escoger cualquier otra para enviarlo al receptor. Luego, el receptor, con otro cilindro con la misma secuencia de discos, transfería el orden y buscaba la línea que tuviera sentido, descifrando el mensaje. Sin embargo, este método nunca llegó a utilizarse en el momento de su creación. Pero su concepto era tan avanzado que sirvió como base para la criptografía militar de Estados Unidos durante la Primera Guerra Mundial.

> Durante la Segunda Guerra Mundial, Alemania también logró otro avance de la criptografía simétrica: La creación de la máquina Enigma.

Era muy similar en funcionamiento al cilindro de Jefferson, ya que utilizaba ruedas giratorias para encriptar un mensaje. Por lo que eran virtualmente imposibles de leer si no se empleaba otra máquina Enigma. Aunque posteriormente los Aliados pudieron desentrañar y romper el cifrado de la máquina utilizando los primeros computadores del mundo. Este hecho terminó dándoles a los Aliados una ventaja definitiva sobre el Nazismo.

#### Llega la era de la computación
Luego, con el avance y desarrollo de las tecnologías en computación, los ordenadores se convirtieron en instrumentos claves dentro de la criptografía. Pero el cifrado y descifrado de mensajes comenzó a considerarse como algo secreto y relacionado con el espionaje.

Por lo que la Agencia de Seguridad Nacional (NSA) de Estados Unidos acaparó, ocultó y bloqueó todo tipo de investigaciones y estudios sobre criptografía. Era el inicio de lo que muchos conocen como las CryptoWars.

Este evento ocurrió en varios países, por lo que el desarrollo de la criptografía fue censurado durante la década de los 50 hasta la década de los 70. El mundo cambió nuevamente cuando IBM desarrolló el algoritmo de cifrado Data Encryption Standard (DES) en 1975. Este significó el primer avance público en criptografía que no dependía de la NSA, y motivó el concepto e investigación de criptoanálisis y de cifrado por bloque.

Posteriormente, fue sustituido por el algoritmo Advanced Encryption Standard (AES) que, tras 5 años de revisión y análisis, se convirtió en un estándar. **De hecho, AES es tan seguro que los datos encriptados con este algoritmo tardarían miles de millones de años en romperse sin la clave apropiada.**

Todas estas referencias de sistemas criptográficos se basan en la criptografía simétrica. Es decir, que tanto el emisor como el receptor manejaban una misma clave para el cifrado y descifrado de la información. Así podemos darnos cuenta del papel importante que ha jugado la criptografía en la historia de la humanidad, y su evolución más significativa estuvo íntimamente relacionada con los ordenadores y la nueva era digital. Hoy en día el avance y desarrollo que ha tenido la criptografía nos permite, muchísimas veces sin saberlo o de manera inconsciente, hacer uso de ella diariamente conforme crece el volumen de información que generamos e intercambiamos.

#### Métodos, algoritmos de cifrado simétrico
Desde el nacimiento de los ordenadores, la criptografía sufrió grandes cambios. En los que pasó de realizarse de forma clásica y manual, para integrar complejos problemas matemáticos. 

Hoy en día existen muchos algoritmos de cifrado que son empleados en los correos, en las bases de datos e incluso en los discos duros. Veamos algunos de los más conocidos y ampliamente utilizados.

1. Data Encryption Standard (DES)
2. Triple Data Encryption Standard (3DES)
3. Advanced Encryption Standard (AES)

##### 1 | Data Encryption Standard (DES)
Fue el primer método de cifrado informático desarrollado por la compañía IBM en 1975. Este algoritmo trabaja en bloques y emplea una clave simétrica de 64 bits de longitud que es sometida a 16 interacciones.

De los 64 bits, 56 bits son utilizados para el encriptado. Y los 8 bits restantes son usados para paridad y para la detección de errores, y luego son descartados. Por lo que la longitud real de la clave es de 56 bits.

Para realizar el encriptado, este algoritmo aplica una serie de permutaciones y sustituciones. Tras esto, modifica inicialmente la secuencia de los bits y escribe el resultado en bloques diferentes de un tamaño determinado, siendo cifrados de forma independiente. El proceso consta de 16 rondas de cifrado y una vez realizadas, se agrupan los resultados en un bloque de tamaño de 64 bits que también es sometido a otra permutación. El texto final que resulta de todo este proceso es el mensaje cifrado.

DES posee 4 modos de operación: 
- **El Electronic Codebook Mode (ECB)** que se emplea para mensajes cortos de longitud menor a 64 bits. 
- **El Cipher Block Chaining Mode (CBC)** empleado para mensajes largos. 
- **El Cipher Block Feedback (CFB)** utilizado para cifrar bit por bit, o byte por byte. 
- **El Output Feedback Mode (OFB)** que tiene el mismo uso, pero además evita la propagación de errores.

Sin embargo, aunque este algoritmo al momento de su creación fue un gran avance y sentó las bases para la criptografía moderna que conocemos actualmente, hoy en día ya no es utilizado debido a que su clave es demasiado corta y ya no es segura a los ataques de fuerza bruta. Tal como se demostró en 1999 cuando fue roto.

##### 2 | Triple Data Encryption Standard (3DES)
El algoritmo 3DES es el mismo que el algoritmo DES, solo que como su nombre indica, se aplica 3 veces. 

Dependiendo de las claves que se utilicen, se puede generar un sistema más robusto. Por ejemplo, si se emplean 3 claves se puede generar una de 168 bits; si se emplean solo 2 claves se puede generar una de 112 bits.

##### 3 | Advanced Encryption Standard (AES)
Este nuevo algoritmo fue el sustituto de DES y es el empleado actualmente debido a que su método de cifrado se adapta mejor a las necesidades del siglo XXI. 

El cifrado de AES puede ser empleado tanto en software como en hardware y el tamaño fijo del bloque es de 128 bits. Mientras que las claves pueden ser elegidas a voluntad entre 128, 192 y 256 bits. Siendo la longitud de 128 bits un estándar. E igual que su antecesor, aplica el cifrado por bloques.

El resultado de cifrar con este método genera una matriz de 4 filas por 4 columnas, a la que luego se le aplica una serie de rondas de cifrado que están basadas en operaciones matemáticas, según la longitud de sus claves. Para una clave de 128 bits se aplican 10 rondas de cifrado, para una clave de 192 bits se aplican 12 rondas, y para una clave de 256 bits son necesarias 14 rondas.

Y aunque es un algoritmo ampliamente usado en la actualidad, muchos criptógrafos comienzan a dudar de su seguridad. Esto es debido a que se ha registrado la posibilidad de ataques en un número de rondas de cifrado muy cercanas al número de rondas necesarias para el cifrado.

#### ¿Cómo es de segura la criptografía simétrica?
En términos de seguridad, el cifrado simétrico no es tan confiable por el hecho de que se debe compartir la clave privada para descifrarlo. 

En este tipo de cifrado toda la seguridad está reflejada en la clave, por lo que compartirla representa una gran vulnerabilidad si no se emplean los sistemas de comunicación adecuados. Sin embargo, cuando se emplea este método, se deben cumplir unos parámetros esenciales para que se considere seguro. Estos son:

Después de encriptar una información, no se puede obtener la clave usada para el cifrado y descifrado. Ni la información contenida en el mensaje cifrado. El costo de descifrar una información debe ser más alto que la misma información contenida en el mensaje cifrado.

#### Importancia en la actualidad
La criptografía simétrica ha sido ampliamente usada desde los inicios de la civilización. Sin embargo, con el desarrollo tecnológico actual, los algoritmos de encriptado son programables en cualquier ordenador. 

Por lo que están presentes en nuestro día a día, y así podemos emplear la criptografía de forma más amplia y eficiente en distintos dispositivos.

Como ya mencionamos, debido a una mayor velocidad, la criptografía simétrica permite su uso para la protección de información en varios sistemas de computación actuales. Como por ejemplo: los mensajes de correo electrónico, los archivos de disco duro, los registros de bases de datos y toda cantidad de información que podemos generar. Esto mediante la aplicación de algoritmos de cifrado simétrico como el AES, que es el de mayor uso en la actualidad para cifrar y proteger información clasificada.

Muchas veces, al emplear sistemas de comunicación e información como Gmail o los teléfonos móviles, hacemos uso, de manera inconsciente, de la criptografía simétrica. Esta nos garantiza que una persona no autorizada no pueda interceptar o acceder a nuestras conversaciones.

De la misma forma, la criptografía simétrica se emplea combinada junto a la criptografía asimétrica en casos que lo requieran. Esto como forma de sacar máximo provecho de las ventajas que poseen ambas.

#### Ventajas y desventajas
##### Ventajas
1. **La rapidez.**  
    Ya que requiere de menor poder computacional debido a la longitud de sus claves (de 64 bits), mientras que en el algoritmo AES van desde 128 a 256 bits. Además, posee una infraestructura sencilla y solo requiere de una clave, por lo que es muy fácil de emplear para el cifrado de archivos que contengan datos personales.
2. **El cifrado simétrico.**  
    Garantiza la privacidad y la integridad en las comunicaciones vía telefónica o por internet, como el caso del correo electrónico.

##### Desventajas
1. **Intercambio o distribución de la clave.**   
    Debido a que esta debe distribuirse a todo aquel que necesite acceder a la información encriptada. Y en ese intercambio, un tercero puede interceptar la clave en un medio de comunicación no seguro y hacerse con la información contenida en el mensaje.
2. **La criptografía simétrica es vulnerable a los ataques de fuerza bruta.**  
    En teoría, la ruptura de este cifrado es posible mediante el criptoanálisis lineal y el criptoanálisis diferencial, pero en la práctica estos ataques no han tenido éxito. Sin embargo, si es posible romperlo con un ataque de fuerza bruta que pruebe todas las combinaciones posibles hasta hallar la clave correcta.
3. **Este tipo de cifrado no permite autenticar la identidad del emisor.**  
    Como sí ocurre en la criptografía asimétrica, ya que el emisor firma digitalmente el mensaje.
    
### ¿Qué es la Criptografía Asimétrica?
Una de las técnicas criptográficas más potentes diseñadas por el hombre es la criptografía asimétrica o criptografía de clave pública.

Este sistema consiste en la utilización de una fórmula matemática muy compleja para crear un par de claves. 

- **La primera es la clave privada,** de uso exclusivo para el creador del par de claves y sirve para cifrar y descifrar mensajes de forma completamente segura.
- **La segunda es la llamada clave pública,** que el creador puede entregar a terceras personas. 
- **La clave pública se crea a partir de la clave privada, pero el proceso inverso es imposible.** De esta forma, el creador de las claves puede compartir esta clave pública con terceras personas, y gracias a ella estas personas puedan enviarle información cifrada que solo será accesible usando la clave privada del creador.

La tecnología de cifrado asimétrica fue inventada por Ralph Merkle, Whitfield Diffie y Martin Hellman en el año 1976. Este esquema de claves privadas y públicas garantiza el establecimiento de comunicaciones completamente seguras, incluso sobre canales inseguros. Razón por la que en la actualidad este sistema criptográfico es el más usado. Un claro ejemplo son las estructuras públicas y privadas que permiten la comunicación por internet, donde se hace uso de criptografía asimétrica para garantizar la privacidad de las comunicaciones.

#### ¿Cómo funciona la criptografía asimétrica?
El funcionamiento del sistema de criptografía pública consta de una serie de etapas bien definidas. Todas y cada una de ellas garantizan que el sistema funcione correctamente. 

Vamos a explicar, con bastante detalle, cada una de ellas:

##### Algoritmo y curva de cifrado
En primer lugar, se ha de definir qué algoritmo de cifrado asimétrico se usará. 

- Cada algoritmo tiene propiedades únicas. 
- Estas propiedades están relacionadas con la curva elíptica que usa el algoritmo para su funcionamiento. 
- En este punto, las curvas elípticas consideradas para el cifrado asimétrico son numerosas. 
- Existen, al menos de forma registrada y bien estudiadas, 22 curvas en total.

Por ejemplo, la Curve25519 de Daniel Bernsteins es muy utilizada en algoritmos de cifrado compactos y muy eficientes. Sin embargo, en las redes Blockchain de criptomonedas como Bitcoin la curva más usada es la secp256k1. Esta curva es el estándar de facto de la seguridad de las criptodivisas.

##### Generación de claves
El siguiente paso es la generación de las claves privada y pública. La primera en generarse es la clave privada. Para su creación segura se ha de usar un generador de números aleatorio muy seguro y un pool de entropía. 

Estos dos garantizarán que el número aleatorio aplicado a la fórmula matemática elegida sea realmente aleatorio. Con ello garantizaremos la seguridad de la clave desde su inicio.

Una vez que el generador de números aleatorios ha dado un número, este se aplica a la fórmula elegida. El sistema comienza a resolver la fórmula y de ella obtenemos un número que será nuestra clave privada. Generada nuestra clave privada, se inicia el ciclo de generación de la clave pública. 

Este ciclo utilizará el número de la clave privada para enlazar de forma unidireccional la clave privada con la pública. De esta forma, la clave pública podrá generar contenido cifrado que podremos resolver con nuestra clave privada. Sin embargo, nada ni nadie bajo ninguna circunstancia podrá develar nuestra clave privada utilizando un proceso contrario.

Una vez ha culminado este proceso de generación, tendremos a la mano nuestras dos claves listas para el siguiente paso de uso.

##### Propagación de confianza
El tercer elemento del funcionamiento de los sistemas de criptografía asimétrica es la propagación segura de las claves. Con esto se busca generar espacios que garanticen la seguridad de los canales de comunicación. 

Entre estos métodos podemos encontrar:
1. **Infraestructura de clave pública o PKI.** Esta es una infraestructura en la que existe una o varias entidades emisoras de certificados. Cada entidad se relaciona con un nivel de confianza y dicho nivel sirve para asegurar la autenticidad de las claves públicas. Este esquema es el que se usa en Internet para asegurar la autenticidad de los certificados SSL/TLS de las páginas webs.
2. **Establecimiento de una red de confianza.** Este es el esquema de propagación de claves más sencillo y personal que existe. Establece que cada usuario tiene una serie de contactos con los que comparte su clave pública de forma abierta o privada. Este esquema de propagación es muy utilizado por sistemas como PGP para el envío de correos privados y cifrados.
3. **Uso de criptografía basada en identidad.** Este es un sencillo sistema de propagación que utiliza un sistema centralizado que gestiona nuestras claves. Las claves generadas están relacionadas con la identidad real o virtual que proporcionamos al sistema.
4. **Uso de criptografía basada en certificados.** En este modelo el usuario posee una clave privada y otra pública. La clave pública la envía a una Autoridad de certificación. Esta se asegura utilizando criptografía basada en identidad de generar un certificado que asegura la validez de los datos.
5. **Uso de criptografía sin certificados.** Este modelo es parecido al anterior con la salvedad de que la clave privada generada por la autoridad es parcial. La clave privada final depende de la clave privada parcial y un número aleatorio calculado por el usuario. Esto garantiza un mayor nivel de seguridad.

##### Envío y recepción de mensajes
Una vez que hemos propagado las claves públicas con seguridad, podemos empezar a utilizar el sistema para enviar y recibir mensajes de forma segura. Este esquema de envío y recepción funciona generalmente de la siguiente forma:
- Juan genera un mensaje que es cifrado usando la clave pública de María, y es firmado con la clave privada de Juan. Esto garantiza que el mensaje solo pueda ser visto por María y ella puede corroborar que inequívocamente proviene de Juan.
- El mensaje viaja firmado y cifrado por el canal de comunicación. Si es interceptado, el esfuerzo será fútil porque no se podrá leer información alguna del mismo.
- Una vez que el mensaje llega a su destinatario, María, ella usará su clave privada para descifrarlo. Al mismo tiempo, podrá usar la clave pública de Juan para validar que realmente el mensaje ha sido enviado por él.
- Se repite el proceso para realizar la respuesta correspondiente.

Este proceso de comunicación resuelve de forma efectiva las comunicaciones seguras en canales abiertos. Corromper o manipular un mensaje enviado usando criptografía asimétrica no es fácil, de hecho, un sistema de cifrado asimétrico bien construido, lo haría prácticamente imposible. 

De ahí su uso tan extendido en Internet y en Blockchain, todo ello con el fin de ofrecer el máximo de seguridad a los usuarios.

#### Uso de la criptografía asimétrica en la Blockchain
Desde su nacimiento, la tecnología Blockchain ha buscado la forma de brindar la mayor seguridad posible. En la búsqueda de tales niveles de seguridad, la criptografía asimétrica ha jugado un papel muy importante. 

Su uso permitió la generación de claves públicas (direcciones) y privadas que permiten asegurar, enviar y recibir criptomonedas de forma segura.

De hecho, la tecnología Blockchain ha sido una perfecta herramienta para probar y desarrollar nuevas técnicas criptográficas. Avances que no solo tienen un impacto positivo en el ecosistema Blockchain, sino en la informática en general. Ejemplo de esto son, por ejemplo, los esquemas como las _Pruebas de Conocimiento Cero_ (ZKP) o las firmas _Schnorr_.

#### Ventajas y Desventajas de la criptografía asimétrica
##### Ventajas
1. **Este sistema ofrece una alta tasa de seguridad,** pues el esquema de cifrado es altamente complejo. El criptoanálisis de estos sistemas es complicado y los ataques de fuerza bruta para romperlo son ineficientes y nada prácticos.
2. **Permite asegurar canales de comunicación abiertos y públicos** gracias al esquema de claves privada y pública. Esto permite que emisor y receptor puedan compartir información de forma segura.
3. **El sistema también permite la autentificación de la información cifrada** gracias a un proceso de firmado digital.
4. **Ofrece un alto nivel de confidencialidad, integridad y garantiza el no-repudio de la información.**

##### Desventajas
1. **E****s computacionalmente más costoso** en comparación con sistema de cifrado simétrico.
2. **El sistema de cifrado es susceptible a elementos ajenos a la programación del sistema de cifrado.** Por ejemplo, un generador de números aleatorios defectuoso comprometería el sistema de cifrado completamente.
3. **La complejidad de los algoritmos resulta en unas dificultades** en el análisis de funcionamiento y seguridad de los mismos. Esto hace que detectar fallos o _bugs_ sea más complejo y difícil en estos sistemas.
4. **Algunos esquemas de propagación de confianza son centralizados.** Esto es un importante punto de fallo que puede traducirse en manipulación de certificados si la estructura es comprometida.

### Funciones Hash
El nombre de Hash se usa para identificar una función criptográfica muy importante en el mundo informático. 

Estas funciones tienen como objetivo primordial codificar datos para formar una cadena de caracteres única. Todo ello sin importar la cantidad de datos introducidos inicialmente en la función. 

Estas funciones sirven para asegurar la autenticidad de datos, almacenar de forma segura contraseñas y la firma de documento electrónico. 

Las funciones  son ampliamente utilizadas en la tecnología Blockchain con el fin de agregar seguridad a las mismas. El Bitcoin es un claro ejemplo de cómo los _Hashes_ pueden usarse para hacer posible la tecnología de las criptomonedas.

![[384.B7_funcion_hash.png]]

#### Historia de las funciones Hash
La aparición de la primera función Hash data del año 1961. En ese entonces, Wesley Peterson creó la función _Cyclic Redundancy Check_ (Comprobación de Redundancia Cíclica). 

Fue creada para comprobar cómo de correctos eran los datos transmitidos en redes (como Internet) y en el sistema de almacenamiento digital. Fácil de implementar y muy rápida, ganó aceptación y es hoy un estándar industrial. Con la evolución de la informática y los computadores, estos sistemas se fueron especializando cada vez más.

Esto permitió crear nuevas y mejores funciones Hash entre las que se pueden destacar:
1. **MD2:** es una de las primeras funciones Hash criptográficas. Creada por Ronald Rivest, en el año de 1989. Con un alto nivel de eficiencia y seguridad para el momento, era fundamental en la seguridad de Internet. Su consecuente evolución llevó a la creación de la función Hash MD5, siendo aún usada en ambientes donde la seguridad no es una alta prioridad.
2. **RIPEMD:** es una función Hash criptográfica creada por el proyecto europeo RIPE en el año de 1992. Su principal función era la de sustituir al estándar del momento, la función Hash MD4. En la actualidad aún se considera muy seguro, especialmente en sus versiones RIPEMD-160,  RIPEMD-256 y RIPEMD-320.
3. **SHA:** el estándar actual de Hashes criptográficos. Creada por la NSA en 1993, como parte de su proyecto interno para autentificar documentos electrónicos. SHA y sus derivadas son consideradas las funciones Hash más seguras hasta el momento. Es de especial interés SHA-256, por ser fundamental en la tecnología que hizo posible el Bitcoin.

#### Funciones Hash | ¿Cómo funcionan?
Las funciones Hash funcionan gracias a una serie de complejos procesos matemáticos y lógicos. Estos procesos son trasladados a un software con el fin de usarlos desde el propio ordenador. 

Desde allí, podemos tomar cualquier serie de datos, introducirlos en la función y procesarlos. Con esto se busca obtener una cadena de caracteres de longitud fija y única para los datos introducidos, a la vez que se hace prácticamente imposible realizar el proceso contrario. Es decir, es prácticamente imposible obtener los datos originales desde un Hash ya formado. Esto es gracias a que el proceso de creación de Hashes es un proceso de un solo sentido.

Un ejemplo sencillo y de la vida diaria de este proceso sería la realización de un pastel. Cada uno de los ingredientes del pastel sería el equivalente a la entrada de datos. El proceso de preparación y cocción del pastel sería el proceso de codificación de dichos datos (ingredientes) por la función. Al finalizar, obtenemos un pastel con características únicas e irrepetibles dadas por los ingredientes del mismo. Mientras que el proceso contrario (llevar al pastel a su estado de ingredientes inicial), es prácticamente imposible de realizar.

Un ejemplo visual del proceso se puede mostrar usando las funciones MD5 y SHA-256, en dos casos de uso distintos. Observando ambos casos de uso podemos notar lo siguiente:
1. **La primera entrada de datos da como resultado un Hash único, para los casos de MD5 y SHA-256. Resultados que están ajustados a la realidad de cada una de esas funciones.** En la segunda entrada se ha realizado una pequeña modificación en el texto. Esta, aunque es mínima, alteró completamente el resultado de los Hashes para MD5 y SHA-256.
2. **Esto prueba que los Hashes serán únicos en todo caso.** Lo que nos permite estar seguros de que ningún actor malicioso podrá forzar Hashes de forma sencilla. Aunque lograr esto no sea imposible, un hacker podría pasar cientos de años procesando datos para lograr su cometido.
  
Son estas dos observaciones las que nos dan la seguridad de usar este método en distintas áreas sensibles. Certificados digitales, firmas únicas de documentos sensibles o secretos, identificación digital y almacenamiento de claves son algunos casos de uso. Pero no se detiene allí, puesto que la flexibilidad y seguridad de esta tecnología la hace idónea en muchas áreas.

#### Características de las funciones de Hash
Entre las principales características de las funciones Hash, se pueden mencionar las siguientes:
1. **Son fáciles de calcular.** Los algoritmos de Hash son muy eficientes y no requieren de gran potencia de cálculo para ejecutarse.
2. **Es compresible.** Esto quiere decir que, sin importar el tamaño de la entrada de datos, el resultado siempre será una cadena de longitud fija. En el  caso de SHA-256, la cadena tendrá una longitud de 64 caracteres.
3. **Funcionamiento tipo avalancha.** Cualquier mínimo cambio en la entrada de datos origina un Hash distinto a la entrada de datos original.
4. **Resistencia débil y fuerte a colisiones.** Hace referencia a que es imposible calcular un Hash que permita encontrar otro Hash igual. Más conocidos como _pre-imagen_ y _segunda preimagen_, es el concepto base de la seguridad de los Hashes.
5. **Son irreversibles.** Tomar un Hash y obtener los datos que dieron origen al mismo, en la práctica no puede ser posible. Esto es uno de los principios que hacen a los Hashes seguros.

#### Nivel de seguridad de las funciones Hash
Las actuales funciones Hash tienen un alto nivel de seguridad, aunque esto no significa que sean infalibles. 

Un buen ejemplo de esto es la función Hash MD5. En principio, las especificaciones de la misma prometían una seguridad muy alta. Su uso se extendió en Internet por la necesidad de un sistema de Hash para mantener su seguridad. Pero en el año 1996, se pudo romper la seguridad de la función. Con ello quedó obsoleta y se recomendó abandonar su uso.

Por otro lado, funciones como RIPEMD-160 y SHA-256 son tan complejas que su seguridad aún está garantizada. Por ejemplo, para SHA-256 se calcula que para romper su seguridad harían falta miles de años usando supercomputadores actuales. Lo mismo aplica en el caso de RIPEMD-160 y sus consecuentes evoluciones. Esto significa que ambas funciones aún brindan un alto nivel de seguridad y pueden utilizarse sin problemas.  
Pero pese a que estas funciones son muy seguras, no significa que no se investiguen y se desarrollen más opciones diferentes. Esta constante evolución nos dice que siempre tendremos a disposición herramientas seguras para usar, en cualquier caso.

#### Las funciones Hash en el mundo Blockchain
Gracias a que son rápidas, eficientes, computacionalmente económicas y únicas, las funciones de Hash son muy usadas en la tecnología Blockchain.

Cuando Satoshi Nakamoto publicó su _whitepaper_ de Bitcoin, explicó el por qué de su uso y cómo ea la aplicación de SHA-256 y RIPEMD-160 en Bitcoin. Desde entonces, la tecnología Blockchain ha evolucionado mucho, pero las bases siguen siendo las mismas. Hacer uso de criptografía fuerte y Hashes para que la tecnología sea muy segura, privada e incluso anónima.

De todos los usos de las funciones de Hash en Blockchain se pueden destacar los siguientes casos:

##### Creación de la dirección (Address Wallet)
Las direcciones de los monederos de criptomonedas son una representación segura de las claves públicas de la cartera. 

Las claves públicas, por lo general, son muy largas y complejas. Es por esta razón que las Blockchain utilizan funciones de Hash para derivar una dirección más corta.

Este proceso se usa en varias ocasiones para acortar la dirección y agregar una capa extra de seguridad.  
En Bitcoin, el proceso de crear una dirección de monedero, usa las funciones Hash RIPEMD-160 y SHA-256. Ambas son usadas para mejorar la seguridad del proceso y hacer que las mismas sean únicas e irrepetibles.

##### Proceso de Minería
El proceso de minería es otra etapa importante de la tecnología Blockchain donde se usan las funciones Hash. 

En Bitcoin, la minería hace un uso intensivo de cálculo de Hashes SHA-256 de forma distribuida en cada uno de sus nodos.

Los mineros son los responsables de calcular millones de Hashes para crear nuevos bloques Bitcoin. El proceso también se usa para verificar las transacciones que se hacen en la red.  
Si bien el proceso de calcular Hashes es muy rápido, su uso intensivo dificulta el proceso drásticamente. Esto lleva a los mineros a usar un alto poder de cómputo para resolver los acertijos Bitcoin. Al resolverlos, los mineros son recompensados con 6,25 BTC por bloque. Esto es un valor cercano a los $ 96.875 (noviembre 2020). Este incentivo económico es el que mantiene el funcionamiento y la seguridad de toda la red Bitcoin.

##### Contratos Inteligentes (Smart Contracts)
Esta es otra área donde se usan mucho las funciones de Hashes. Las Blockchain como Bitcoin, Ethereum, NEO o TRON hacen uso de contratos inteligentes para potenciar distintas aplicaciones. 

Estas aplicaciones son manejadas por un contrato público entre partes.

Sin embargo, muchos de estos datos son muy sensibles o simplemente es demasiada información para ser almacenada en una Blockchain, por lo que la mejor forma de solventar estos escenarios es a través de funciones de Hash. De esta manera todo el contrato es público, pero la información enlazada o que se quiere mantener privada no es publicada. Estos datos pueden incluir nombres, direcciones, direcciones de monederos, datos de terceros participantes... Es decir, información privilegiada y solo de interés entre partes.  
Los Hashes también son usados para versionar los contratos. Es decir, un contrato público tiene un Hash único que viene dado por lo que dice el contrato. 

Si el contrato es modificado, el contrato anterior es terminado y se genera uno nuevo con un nuevo Hash. De esta manera, el Hash determina el contrato correcto a usar dentro de aplicación descentralizado facilitando su control. Otro uso del Hash en contratos inteligentes es para marcar la validez y autenticidad del mismo. Un ejemplo puede ser un contrato hecho para la venta de una casa con un pago hecho en criptomonedas. La realización del contrato y su Hash serán testigos inalterables de venta realizada entre las partes.

### Checksum
La suma de verificación o CheckSum, es una sencilla función que se utiliza para detectar que una serie de datos o archivos no han sido modificados.

![[385.B7_funcion_checksum.png]]

Una función muy útil para garantizar la integridad y la protección de la información cuando es almacenada o compartida con otros usuarios en la red.

- **Su funcionalidad está basada en un sencillo algoritmo de verificación** que permite crear pequeños _Hash_ o cadenas de caracteres que luego pueden ser usados para verificar, antes o después de una transmisión de datos, la validez de los datos transmitidos. 
- **Dicho Hash, generalmente, está ubicado en la parte final del archivo o cadena verificado.** De esta forma, actúa como una firma que ayuda a verificar la integridad de la información.
- **Es muy útil cuando, por ejemplo, queremos incluir una verificación automática** que nos permita saber si lo que escribimos o los datos que nos han llegado realmente representan la información deseada.
- **El uso de la función _Checksum_ está muy extendido, tanto en Bitcoin como en otras criptomonedas.** 

Vamos a conocer más sobre esta pequeña, pero potente función y cómo nos ayuda a hacer de Bitcoin un desarrollo mucho más seguro para todos.

#### Origen de los CheckSum
La aparición de las primeras funciones CheckSum datan de los trabajos iniciales de [William Wesley Peterson](https://en.wikipedia.org/wiki/W._Wesley_Peterson), un científico computacional y matemático que dedicó varios años a la investigación, diseño e implementación de CheckSum del mundo. 

Más específicamente, Peterson diseño la primera función _Checksum_ o de suma de verificación, en el año de 196, la conocida CRC (Verificación por redundancia cíclica), que luego daría vida a estándares industriales como CRC8 o CRC32C, entre otras derivadas de muy amplio uso.

Desde entonces, las funciones CheckSum o de suma de verificación han sido parte esencial de nuestras vidas. Desde un simple reproductor de CD, pasando por los televisores, los sistemas de conversión digital-analógico y viceversa, las transmisiones de datos por cable (como la Ethernet de nuestros computadores) o por radio (como las que realizan nuestros celulares). En fin, la utilidad de _Checksum_ es gigantesca y seguramente está presente en cosas que ni remotamente pensarías que la tienen aplicadas.

Por otro lado, William W. Peterson fue un grandioso desarrollador de tecnologías y mejora de lenguajes de programación, hasta su muerte el 6 de mayo de 2009. En su honor, las empresas Intel y AMD, agregaron a sus respectivos procesadores la función CRC32c. Esta es la función Checksum más ampliamente conocida de Peterson, y que todavía es ampliamente utilizada en la industria.

#### ¿Cómo funciona CheckSum?
La función CheckSum fue creada a partir de la aplicación de un algoritmo sencillo. Este tiene como objetivo utilizar una serie de operaciones matemáticas y lógicas complejas para convertir una secuencia de datos en una cadena de números fija conocida como Hash de suma de verificación.

Este pequeño Hash se utiliza luego para verificar de forma muy rápida si una determinada data ha sufrido daños. Bien sea por almacenamiento (datos escritos o leídos de forma incorrecta) o por transmisión de los mismos (las redes de transmisión siempre tienen una pérdida relacionada con distintos factores). O inclusive si algún actor malicioso la ha modificado de forma premeditada.

Entonces, cómo esta función permite verificar la integridad de una información, es ampliamente utilizada al momento de compartir o almacenar datos en la red. Puesto que los datos, al estar acompañados de los valores Hash generados a partir de ellos mismos mediante una función Hash, adquieren algunas propiedades extras que les permiten ser verificados y validados por sí mismos cuando son compartidos o almacenados.  
Por ejemplo, si un usuario desea compartir un archivo en la red con otro usuario, debe suministrar un valor Hash del archivo de manera que este mismo valor pueda ser obtenido al momento de aplicar la función Hash sobre ese archivo. Garantizando entonces que el archivo compartido sí llegó de forma correcta y sin alteraciones a su destinatario.

En el momento de archivar y almacenar una información, esta puede ser verificada posteriormente calculando y guardando el resultado del valor Hash obtenido. Así, cuando se necesite hacer una comprobación, puede usarse el valor Hash guardado para saber si la información ha sido alterada o no, por cualquier motivo.

#### Casos de uso de la función CheckSum
Los casos de uso de las funciones _CheckSum_ son ampliamente variados. Es una parte muy fundamental tanto de aparatos electrónicos como de la informática en general.

Con el fin de que puedas comprender con mayor claridad el alcance de las mismas, veremos a continuación algunos casos de uso reales y muy cotidianos de estas funciones:

##### Tecnología GSM
La tecnología GSM que hace posible que podamos usar la mayoría de nuestros celulares en la actualidad hace un amplio uso de las funciones Checksum en sus sistemas de transmisión digital de voz y datos.

Recordemos que la información digital que se envía a la red celular va codificada, comprimida y modulada de tal forma que la misma pueda llegar de un punto a otro en la red celular con la menor pérdida de información y calidad.

Pero al ser una red de datos del tipo inalámbrica, existen diversos factores que alteran la calidad de la información enviada. Cualquier tipo de interferencia puede causar pérdidas de información y con ello, perderemos calidad en los servicios. Para hacer frente a esta situación se utilizan las funciones _Checksum_. 

Gracias a estas funciones, la red puede verificar de forma rápida que la información enviada y recibida esté en perfectas condiciones. Y de no estarlo, si se detecta un error, la misma red es capaz de tratar de corregirlo (la mayor parte del tiempo con éxito).  
Así que sí: gracias a las funciones _Checksum_ tienes llamadas de voz, mensajería y datos de alta calidad en nuestras redes celulares actuales.

##### Cuentas bancarias
Otro uso muy común de las funciones de _Checksum_ es el de verificar que la información de una cuenta bancaria es correcta. Cada vez que ves un número de cuenta bancaria, no solo ves un grupo de números que te identifican dentro de ese banco.

Si no que también hay un dato que les permite verificar que esos números que has entregado son los correctos. Por ejemplo, en las cuentas bancarias del tipo IBAN, estos números de control o _Checksum_ son los primeros cuatro dígitos. Los primeros dos indican el país de origen de la cuenta, y los otros dos indican el número de control. Este número de control está relacionado con los últimos 10 números que identifican la cuenta bancaria. Y esto nos garantiza que no nos equivocaremos al introducir un número de cuenta bancaria.

##### Direcciones de criptomonedas
A través de _CheckSum_ o suma de verificación puedes comprobar rápida y fácilmente que la dirección que estás utilizando es la correcta o si, por el contrario, está alterada de alguna manera, evitando así enviar sus criptomonedas a una dirección falsa, incorrecta o inexistente.

Aunque, en teoría, sería imposible enviar bitcoins a una dirección que no existe o que esté escrita de forma incorrecta. Debido a que estas direcciones, cuando son generadas, incorporan un código de suma de control. Este dato representa el valor Hash de la dirección y los datos de la suma conforman un esquema alfanumérico propio conocido como _Base58Check_. Este guarda la suma de verificación de forma directa dentro de la dirección, y con ello (si se introduce una dirección de forma incorrecta) las sumas de verificación de ambas direcciones no coinciden. De esta forma, el monedero impide realizar una transacción cuando las direcciones se introduzcan de forma errónea.

En Bitcoin, la función Hash SHA-256 se aplica dos veces para generar un Hash de 32 bytes, donde los primeros 4 bytes (32 bits) son tomados como el _Checksum_ para detectar los errores de tipografía en las direcciones. Y, aunque a través de esta suma de verificación no se podrán obtener las claves asociadas a la dirección, sí permite la verificación de dichas claves. Con esto se logra evitar que se cometa un error al realizar una transacción.  
Este sencillo procedimiento garantiza que no puedas equivocarte al introducir una dirección de Bitcoin. De hecho, la probabilidad de que te equivoques es de 1 en 4.294.967.295.

### Optimizaciones de la Criptografía: Firmas Schnorr
Las Schnorr Signatures o firmas Schnorr son una solución planteada en la red Bitcoin que busca mejorar la privacidad y escalabilidad del sistema. 

![[386.B7_Schnorr.png]]

Esto se debe a que permiten que un conjunto de firmas de transacciones con una misma entrada pueda ser sustituida por una única firma. Reduciendo el espacio de almacenamiento ocupado dentro de un bloque.

Esto, a su vez, permite que las transacciones puedan ser confirmadas de forma mucho más rápida, mejorando el rendimiento de la red. La propuesta de mejora fue presentada por Pieter Wuille en julio de 2019.

Este nuevo esquema de firmas también permite mejorar la seguridad de la red frente a ataques de spammers. Esto se debe a que, con esta implementación, un atacante tendría que enviar mucha más cantidad de transacciones para ocupar el mismo espacio dentro de un bloque. De este modo, el ataque se vuelve más costoso y menos factible para el atacante.

#### ¿Cómo funcionan las firmas Schnorr?
La principal función de las firmas Schnorr es permitir a varios usuarios crear una firma única para todas las partes involucradas. Esto permite reducir el tamaño de las transacciones y la cantidad de firmas necesarias para realizar una transacción.

El sistema Bitcoin utiliza el algoritmo ECDSA de firma digital de curva elíptica para que los usuarios puedan demostrar su propiedad sobre las salidas no gastadas (UTXO) de bitcoins. Entonces, cada vez que un usuario desee efectuar una transacción, debe proporcionar una firma que valide su propiedad. A su vez, dicha transacción también tiene un script P2SH que determinará la forma en cómo se gastarán las entradas de una transacción.

Estos scripts pueden modificarse para condicionar o programar el gasto de los bitcoins. Por ejemplo, se pueden establecer condiciones de _time lock_ o _multisig_. En este último, es necesaria la configuración de varias firmas para autorizar una transacción. Las multisig emplean un esquema M-of-N, donde cualquier combinación de firmas válidas dentro de N podrá desbloquear las salidas no gastadas, al solicitar un umbral con M número de firmas válidas. Entonces, para autorizar una transacción y gastar una salida, deben proporcionarse M número de firmas entre los participantes, donde cada una de estas firmas posee un tamaño en bytes de longitud.

- María, Juan y Pedro poseen una wallet con multisig.
- Para realizar una transacción, deben firmar 2 de los 3 participantes.
- Cualquier combinación de firmas (N) podrán autorizar la transacción, ya sea que firme María junto a Juan, o María junto a Pedro, o Pedro junto a Juan.

En este ejemplo, cualquier combinación de firmas (N) podrán autorizar la transacción, ya sea que firme María junto a Juan, o María junto a Pedro, o Pedro junto a Juan. O en su caso, exista otra condición que determine quiénes deberán ser los firmantes principales. 

> En general, el cumplimiento de 2 firmas (M) autorizará la transacción. No obstante, el tamaño en bytes de una transacción con multi-sig será mayor a una transacción convencional que solo requiere de una firma.

En este punto es donde radica el problema. Pues las multi-sig al tener que proporcionar una cierta cantidad de firmas para autorizar una transacción, el tamaño de la transacción crecerá de forma proporcional a la cantidad de firmas que sean requeridas. Por lo que la implementación de las firmas Schnorr representa una verdadera solución a esta problemática. Esta solución combina todas las firmas individuales dentro de una misma firma, reduciendo, a su vez, el tamaño de las transacciones y los costos generados por las comisiones de la transacción.

#### Ventajas e inconvenientes de las firmas Schnorr
##### Pros
1. La implementación de este esquema de firmas puede mejorar la privacidad de la red al permitir que las transacciones con la firma Schnorr se vean idénticas a las transacciones convencionales de una sola firma. Es por esto que son indistinguibles unas de otras.
2. Las firmas Schnorr reducen la necesidad de espacio de almacenamiento de las transacciones realizadas con multifirmas hasta en un 25 %. Esto disminuye el tamaño de la transacción dentro del bloque, ahorrando su espacio y reduciendo las comisiones por dichas transacciones.
3. Al reducir el espacio de almacenamiento de las transacciones dentro del bloque, las firmas Schnorr pueden contribuir a una mejor escalabilidad de la red.
4. Esta implementación permitirá que las transacciones sean validadas y confirmadas de forma mucho más rápida. De esta forma se reduce significativamente el tiempo de espera de las confirmaciones en la red.
5. Las firmas Schnorr no tienen problemas de maleabilidad, por lo que ninguna parte puede modificar o alterar una firma para generar doble gasto.
6. Son parte esencial para la aplicación de Taproot, una de las mejoras más esperadas de Bitcoin para mejorar su escalabilidad, privacidad y capacidad para Smart Contracts.

##### Contras
1. En la implementación de las firmas Schnorr cada participante debe demostrar que su clave pública es válida a través de una firma producida con su clave privada correspondiente.
2. La implementación de las firmas Schnorr expone un vector de ataque donde un participante puede reclamar una clave pública falsa y controlar el multi-sig.

#### Esquema de firmas múltiples MuSig
El esquema de firmas Schnorr fue creado en 1980 por el criptógrafo alemán Claus-Peter Schnorr, quien patentó su invención, impidiendo el uso público y directo de este esquema. En 2008, la patente de esta creación venció dando paso a que pueda ser usada libremente.

Posteriormente, en 2018, varios desarrolladores y programadores diseñaron un nuevo esquema de firma múltiple denominado MuSig, que está basado en las firmas Schnorr. Este nuevo esquema permite a los participantes de una multi-sig la creación de Smart Contracts privados fuera de la Blockchain.

Con la implementación de MuSig se pueden agregar las firmas y claves públicas de cada participante del multi-sig y generar una sola clave pública que verifique las demás, en lugar de tener que hacerlo con cada clave pública individual por separado.

#### Firmas Schnorr y Bitcoin Cash
Aprovechando el enorme parecido que existe entre Bitcoin y Bitcoin Cash, los desarrolladores de Bitcoin Cash han decidido aplicar las firmas Schnorr a la variación de su protocolo. 

El desarrollador Mark Lundeberg fue quien llevó a cabo todo este trabajo para hacer que Bitcoin Cash pudiera aprovechar este nuevo esquema de firmado, que sería opcional al sistema ECDSA.

La red Bitcoin Cash se actualizó para hacer uso de este tipo de firmas el día 15 de mayo de 2019. Como resultado de esta actualización, Bitcoin Cash logró reducir en un 4 % el tamaño de las firmas digitales de las transacciones. Al mismo tiempo, consiguió reducir en un 20 % el tamaño de las transacciones con el consiguiente aumento en la capacidad de procesamiento de transacciones de la red.

### Optimizaciones de la Criptografía: MuSig
Un monedero multifirma o MuSig es una cartera virtual que puede gestionar direcciones multifirma de Bitcoin y, por lo tanto, puede permitir la gestión de un mismo monedero por dos o más personas mediante sus claves criptográficas privadas para firmar las transacciones.

![[387.B7_MuSig.png]]

Es el equivalente en Blockchain de las cuentas bancarias mancomunadas, donde la extracción de dinero solo es posible con la aprobación de las partes que han abierto la cuenta. 

¿Lo mejor? Es que con un monedero MuSig no debes ir a un banco. Y mucho menos, confiar en terceros para lograr tener la misma funcionalidad con una mayor seguridad y confianza.

Y si a esto sumamos que actualmente se cuenta con una gran cantidad de opciones para crear monederos virtuales, las ventajas aumentan. 

Sin embargo, para entender el punto de las direcciones en Bitcoin, debemos estar al tanto de que en esta red se tienen las direcciones que comienzan por "1" llamadas direcciones _Pay To Public Key Hash_ (P2PKH) y las direcciones que comienzan por "3" llamadas _Pay To Script Hash_ (P2SH). Estas últimas son las direcciones utilizadas para gestionar las operaciones multifirma.

#### Funcionamiento de un monedero multifirma
Un monedero multifirma funciona gracias a que Bitcoin (como otras criptomonedas) permite especificar la cantidad de firmas o claves privadas necesarias para movilizar los tokens dentro de una dirección. 

- Para lograr esto, los monederos de bitcoins traducen estas firmas en un pequeño Script. 
- Esto permite crear una serie de condiciones de bloqueo que una dirección multifirma debe cumplir. 
- Una vez cumplidas las condiciones y desbloqueada la dirección se pueden movilizar los fondos de dicha dirección. Por supuesto, lograr esto requiere la exacta combinación de firmas digitales, porque de lo contrario es imposible. 

Por ejemplo: Atacar una dirección multifirma de Bitcoin con fuerza bruta, podría llevarle a un atacante cientos de millones de años en vulnerarla, incluso si usa las computadoras más potentes que existen en la actualidad. Esto sucede gracias a la criptografía usada para generar estos scripts donde participan los _hashes_ SHA-256 y RIPEMD-160 (para crear _hashes_ únicos), y la criptográfica asimétrica ECDSA (para generar las claves privadas y públicas de las direcciones).

Sin embargo, esto es solo una parte del funcionamiento de las direcciones multifirma. 

Como hemos dicho hace unos momentos, dichas direcciones pueden protegerse con variadas combinaciones de firmantes. 

**Así, es posible crear una dirección 2-de-3. ¿Qué significa esto? Que existen 3 firmantes para dicha dirección, pero la movilización de fondos solo es posible si 2 de esos 3 firmantes autorizan dicho movimiento.** 

Los esquemas en este sentido pueden ser más elaborados, pudiendo crear esquemas 2-de-2, 4-de-5, o incluso más, todo ello gracias a la programación que criptomonedas como Bitcoin pueden soportar: Una programación que se establece en el momento exacto en que dicha dirección es creada y que una vez se crea, no se puede cambiar de ninguna manera.

#### MuSig | Pros y contras
#####  Pros
1. **Permite darle mayor seguridad al dinero que se guarda en un monedero,** ya que, al necesitar de varias firmas para autorizar una transacción, existen menores posibilidades de perder dinero en caso de que se extravíe algunas de las claves.
2. **Dos o más personas pueden encargarse de realizar pagos** por una nómina de empleados, para darle mayor transparencia a la operación de la que tuviera en caso de que fuera una sola persona la encargada de esta tarea.
3. **También este tipo de cuentas multifirma son convenientes para fondos de ayuda humanitaria u ONGs** en la que varias personas deben firmar para que determinada cantidad de dinero se libere para cubrir alguna eventualidad.

##### Contras
1. **Se ha reportado vulnerabilidad en el uso de las direcciones multifirma, esta vulnerabilidad está ligada a la clave pública que deben compartir los participantes de una dirección multifirma.** Si un usuario tiene un dispositivo comprometido, este podría ser víctima de personas mal intencionadas.
2. **Una es mediante la generación de claves públicas falsas que conlleva un potencial riesgo de desviación de fondos y, dos, mediante el secuestro de la clave pública a través de algún _Ransomware_.** Este último caso se aplica en aquellas direcciones del tipo N de N, en el que el hacker puede tomar control de una de las claves y solicitar rescate para devolver el control a los participantes de la cartera multifirma.
3. **Como lo expresa Benma, desarrollador de _Shift Crypto_:** Una cartera en una computadora comprometida puede proporcionar las claves públicas de cofirmantes falsos a la cartera de hardware. Por ejemplo, en una multifirma 2 de 3, la cartera comprometida proveerá dos claves públicas que serán controladas por el atacante. Después de verificar la dirección de recepción comprometida, los fondos enviados a ella pertenecen al atacante.

### Optimizaciones de la Criptografía: zk-SNARKs
El desarrollo tecnológico actual puede ser tan beneficioso como perjudicial para la privacidad de los datos que se manejan en la red. 

Esta característica, la privacidad, siempre ha sido la más valorada por todos aquellos usuarios que desean realizar sus transacciones a través de criptomonedas. Incluso antes de existir las criptomonedas, desde la época de los criptoanarquistas.

La realidad es que, en tiempos de Big Data (donde redes neuronales artificiales están analizándonos sin parar, corporaciones y gobiernos absorbiendo todo cuanto hacemos para controlarnos a su antojo) es más importante que nunca la privacidad personal y la transparencia de las instituciones. Por ello, la creación de soluciones más poderosas y eficientes que resguardan la privacidad en el mundo digital hoy en día cobran mayor fuerza e importancia gracias a la llegada de las criptomonedas.

Hoy aprenderás una de las herramientas en este sentido: las pruebas de conocimiento cero zk-SNARKs. Se trata de una implementación criptográfica muy poderosa que permite demostrar la propiedad sobre cualquier información o datos sin la necesidad de tener que revelar dicha información o datos a ningún usuario o red, en ningún momento. Interesante ¿no? Pues veamos a profundidad de qué se tratan estos novedosos sistemas de prueba criptográfica ciega.  

#### Entendiendo que es un zk-SNARK
Acrónimo de _Zero-Knowledge Succinct Non-Interactive Argument of Knowledge_ o _Argumento de Conocimiento No Interactivo Sucinto de Conocimiento Cero_. 

Los zk-SNARKs son sistemas de prueba de conocimiento cero muy confiables y seguras. Pruebas que nos permiten probar la posesión sobre una información, demostrando que además dicha información es correcta. Pero que al mismo tiempo nunca se revela, sino que se mantiene en estricta confidencialidad y en secreto.

Es importante diferenciar entre protocolo ZKP y zk-SNARK. 

- ZKP es una forma o protocolo para hacer pruebas criptográficas. 
- zk-SNARK son algoritmos que ponen un protocolo ZKP en uso. 

**Es un caso similar al protocolo TCP/IP (la base de internet):** 

- Sobre él se crean implementaciones concretas como el protocolo SMTP (protocolo de envío de emails). 
- SMTP se crea sobre TCP/IP, usando TCP/IP de una determinada forma.

En este caso, el protocolo ZKP sería la base, y sobre este se fundamenta zk-SNARK.

Esta implementación concreta del protocolo ZK, tiene algunos matices que podemos descubrir entendiendo cada una de las letras que componen el nombre zk-SNARK:

1. **ZK. _Conocimiento cero_:** es un tipo de prueba criptográfica. Hace referencia a la confidencialidad y privacidad de la información entre los usuarios sin comprometer su seguridad. 
2. **S. _Sucinto_:** hace referencia a la brevedad y rapidez con la que se puede verificar y comprobar que la prueba es verdadera o legítima. Como las pruebas son una demostración de la posesión de información o datos, su tamaño es pequeño, por lo que se pueden verificar y validar en cuestión de milisegundos.
3. **N. _No interactivo_:** significa que no hay una interacción, comunicación o relación de intercambio constante entre el demostrador y el verificador. Es decir, en las pruebas de conocimiento cero solo hace falta enviar un mensaje con la prueba para demostrar la posesión sobre la información, sin necesidad de una comunicación constante o frecuente entre las partes.
4. **ARK. _Argumento de conocimiento_:** hace referencia a la prueba o conocimiento que tiene un probador y que puede demostrar ante un verificador, para convencerlo de que posee una información que conoce y que es correcta, pero sin revelar cuál es esa información.

**Básicamente:** Un zk-SNARK nos permite contarle que tenemos en nuestro poder una información secreta a un amigo, sin tener que revelar en ningún momento dicha información. Y al mismo tiempo, convencer a nuestro amigo al cien por cien de que la información realmente está en nuestro poder. Suena genial ¿No crees? De hecho, la utilidad de pruebas de este tipo es gigantesca, pero antes de eso sigamos entendiendo que más se esconde en las zk-SNARKs.

#### ¿Cómo funcionan los zk-SNARKs?
La tecnología que envuelve a los zk-SNARKs es profundamente compleja y novedosa. 

**Las bases de su construcción fueron diseñadas por los criptógrafos Shafi Goldwasser, Silvio Micalli y Charles Rackoff en 1985.** Lo que dio origen a los primeros protocolos para decir que se tiene conocimiento de un secreto que existe y que es correcto, pero sin revelarlo. Es, prácticamente, decir “Lo sé” sin ir más allá de esas palabras.

Sin embargo, detrás de esto se esconde una potente y compleja matemática que pocas personas pueden comprender del todo. Por ello, un ejemplo explicativo y sencillo expuesto por el criptógrafo Jean-Jacques Quisquater en 1990 puede ayudarnos a comprender cómo funcionan las pruebas de conocimiento cero. 

Veamos: El concepto de prueba de conocimiento cero se refleja como una parábola de la Cueva de las Mil Maravillas de Alí Babá. 

1. En este ejemplo, **la cueva es un círculo perfecto con una sola entrada.**
2. En su interior solo **existen dos caminos laterales y es necesario decir las palabras secretas correctas** para acceder.
3. **El usuario A quiere demostrarle al usuario B** que tiene conocimiento de cuáles son las palabras secretas correctas, aunque sin revelarlas en ningún momento.
4. **A llega a un acuerdo con B:** A estará al final de la cueva y B en la entrada.
5. **B dirá una palabra** para indicar que A debe aparecer por uno de los caminos.
6. **Cuando A escuche a B,** aparecerá por el camino que B le ha indicado, demostrando que sabe las palabras correctas.
7. **El proceso puede ser repetido N cantidad de veces** para demostrar que A conoce realmente la palabra secreta y no ha elegido el camino por una simple coincidencia.

#### Importancia de los zk-SNARKs
La facilidad de dar seguimiento o rastrear las transacciones que realizan los usuarios en las Blockchain públicas, ha llevado a la implementación de nuevos mecanismos de seguridad que garanticen la protección y el resguardo de la privacidad. 

**Tanto de los usuarios como de las criptomonedas, pues la privacidad también es un elemento que le brinda fungibilidad a las monedas digitales.**

> La implementación de protocolos de privacidad como zk-SNARK permite garantizar la privacidad de todos los usuarios y participantes en una red Blockchain, sin comprometer en ningún caso la privacidad ni la seguridad de ninguno de ellos.

El uso de los zk-SNARKs puede reducir cualquier tipo de conexión o relación que pueda existir entre el remitente y el destinatario, así como los montos involucrados en las transacciones. 

Este mecanismo de seguridad puede ser usado en conjunto con otras implementaciones de privacidad como Tor, para ocultar, por ejemplo, la IP de los usuarios. Haciendo más efectiva la garantía de privacidad en todas las operaciones. Aunque es importante destacar que zk-SNARK es un mecanismo que se activa de forma manual.

#### Zcash y los zk-SNARKs
La primera criptomoneda en aplicar las pruebas de conocimiento cero para garantizar la privacidad y seguridad de los usuarios es Zcash (ZEC). 

La implementación de las pruebas de conocimiento cero le permiten a Zcash poder verificar las transacciones realizadas en la red. Todo ello sin necesidad de revelar quién ha sido el remitente, el destinatario o la cantidad de dinero que ha sido transferida.

En Zcash, el protocolo ZKP elegido es la implementación zk-SNARKs. Una elección que le permite modificar completamente la manera en que se comparten los datos en una red. Permitiendo que las transacciones puedan permanecer cifradas, pero que aun así se pueda verificar y certificar su autenticidad y validez. Ofreciendo un grado de anonimato, privacidad, seguridad y confidencialidad sin precedentes para los usuarios.

> Zcash admite direcciones privadas y transparentes, donde ambas son totalmente interoperables entre sí y dependen de los usuarios la activación o la retirada de las protecciones sobre la información. Entonces, las direcciones transparentes en la Blockchain de Zcash operan de forma similar que en Bitcoin o Ethereum. Donde la información está visible públicamente.
  
Por el contrario, si se opera con direcciones privadas, solo se verá en la cadena que ha ocurrido un movimiento y que las tarifas de dicha transacción han sido canceladas. Pero no se tendrá conocimiento sobre las partes involucradas en dicha transacción, ni de los montos que fueron transferidos. Por lo que estos datos no son visibles al público, aunque estén dentro de la cadena pública.

Esto es posible solo gracias al uso de pruebas de conocimiento cero, que permiten cifrar o encriptar los datos dentro de la Blockchain.

##### Características principales de Zcash en zk-SNARK
- En Zcash se pueden efectuar transacciones de forma rápida, segura y privada con costos de transacción bajos de 0.0001 Zcash. 
- Con Zcash puede disfrutar de direcciones completamente privadas u optar por direcciones públicas y transparentes.
- Con las direcciones privadas, los campos de memos no son revelados públicamente. Por lo que puede incluir información importante para el destinatario de la transacción sin riesgos ni vulnerabilidades, ya que dicha información se encontrará protegida y encriptada.
- En las direcciones privadas, los usuarios pueden revelar detalles de sus transacciones en caso de auditorías o de tener que cumplir normas reglamentarias. No obstante, el usuario puede revelar toda la información de la transacción si lo desea. Así, podemos ver los montos transferidos, el campo memo o algún mensaje vinculado. Todo ello sin mostrar quién ha sido el destinatario o receptor de la operación.  

#### zk-STARK | Otros tipos de pruebas de conocimiento cero parecidas a zk-SNARK
Otro ejemplo de pruebas de conocimiento cero parecidas a zk-SNARK son las zk-STARKs.  

Los zk-STARK se crearon como una versión alternativa de las pruebas zk-SNARK y se consideran una implementación más rápida y económica de esta tecnología.  Pero, lo realmente importante de este sistema es que las zk-STARKs no requieren una configuración inicial de confianza (por lo tanto, la “T” es transparente). 

Adicionalmente, los zk-STARK tienen una mayor fortaleza contra ataques del tipo cuántico. Debido a esto se les considera una forma de criptografía más confiable contra este tipo de sistemas.

### Optimizaciones de la Criptografía: zk-STARKs
Este es un término que en español significa: Prueba de Conocimiento Cero con Argumentos Transparentes Escalables.

Las pruebas (o protocolos) de conocimiento cero (ZKP) han evolucionado mucho desde su creación, y una de esas evoluciones son las zk-STARKs. 

El término zk-STARK es el acrónimo de _Zero-Knowledge Scalable Transparent Arguments of Knowledge_. Dicho concepto hace referencia a una derivación de las conocidas pruebas zk-SNARKs que proyectos como Zcash usan en su Blockchain, para proveer un alto grado de privacidad y anonimato, y que ya hemos estudiado con anterioridad.

Sin embargo, las zk-STARKs son más que una pequeña derivación, son en realidad una mejora significativa de las zk-SNARKs. Y esto no es solo porque son menos complejas de realizar, sino porque son más seguras, e incluso resistentes a la computación cuántica. En pocas palabras, son el futuro inmediato de las pruebas de conocimiento cero, especialmente, si queremos estar seguros ante la cada vez más cercana tecnología de computación cuántica.

#### zk-STARKS, una mejora para algo ya de por sí sorprendente
Como hemos mencionado al principio, las zk-STARKs son una mejora de las conocidas pruebas zk-SNARKs. Una mejora necesaria debido a la enorme complejidad algorítmica, matemática y criptográfica que representan las pruebas zk-SNARKs. 

Es cierto: las zk-SNARKs son pruebas grandiosas y muy seguras, pero son muy complejas a nivel algorítmico. Tanto es así, que incluso especialistas en criptografía tienen problemas en detectar errores en las mismas.

 Lo anterior puede sonar como algo increíble, pero es cierto. Y esto se hizo patente cuando Zcash presentó un gravísimo error en su código. El error en cuestión permitía que cualquier persona pudiera crear criptomonedas de la nada. De esta forma, lo que todos creíamos que era imposible en las criptomonedas (generar monedas de la nada), un pequeño error en la criptografía zk-SNARK de Zcash lo hacía posible.

Sin embargo, para cierta tranquilidad de los desarrolladores de Zcash, el error era tan complejo de detectar, que solo unas pocas personas en el mundo hubieran tenido el conocimiento necesario para detectarlo y explotar el error. De cierta forma, evitaron el desastre de un alud de monedas “falsas” solo por el hecho de que la criptografía es tan compleja que pocos la entienden. Pero esta situación está muy lejos de ser la ideal y debe evitarse a cualquier costo, porque la “Seguridad por oscuridad” no es seguridad real.  

#### La extrema complejidad es enemiga de la seguridad
Por otro lado, este hecho también puso el énfasis en una realidad: las zk-SNARKS podrían convertirse en el peor enemigo de las monedas de privacidad como Zcash. Y es que, aunque cueste admitirlo, que un sistema de seguridad criptográfica sea tan complejo de depurar, no es nada bueno. Por suerte, esta es una realidad que ya era conocida mucho antes de este error, y fue lo que llevó al desarrollo de las zk-STARKs.  
A continuación, hablaremos más en detalle del origen de las zk-STARKS y de cómo pueden ofrecernos más seguridad, con menos complejidad.

#### Los inicios de una criptografía potente, pero simple
Para conocer los inicios de las zk-STARKs debemos trasladarnos al año de 1990, fecha en la que empezaron los primeros trabajos sobre estas pruebas. 

En ese momento se iniciaron las investigaciones y desarrollos preliminares de la tecnología de zk-STARKs. Sin embargo, estos sistemas iniciales resultaron ser poco prácticos.

No fue hasta que Eli Ben-Sasson, Iddo Bentov, Yinon Horesh y Michael Riabzev presentaron en 2018 su trabajo conjunto [Scalable, transparent, and post-quantum secure computational integrity](https://eprint.iacr.org/2018/046.pdf) (en español, Integridad computacional segura escalable, transparente y post-cuántica). 

El trabajo presentado es único en su estilo, demostrando una construcción criptográfica sólida, que dejaba muy atrás a las conocidas pruebas zk-SNARKs de Zcash. Y lo mejor de todo: Eran mucho más sencillas de aplicar y seguras que su contraparte.  
  
Esto lo lograrían con una aproximación mucho más elemental sobre cómo crear una prueba de conocimiento cero. Más específicamente el renunciar a la construcción de un área de trabajo criptográfica o “black box” altamente confiable. Lo que parece contrario a cualquier principio de seguridad en criptografía, era aplicado en este nuevo sistema. Pero, al mismo tiempo, dicha decisión permitía reducir la complejidad del sistema, el trabajo necesario para su realización, y no renunciaba a la seguridad, sino que al contrario habilitaba nuevas vías para ofrecer una mayor. 

De esta manera y haciendo uso de criptografía homomórfica, computación multipartita segura (MPC) y pruebas interactivas, estos investigadores lograron diseñar zk-STARK. En pocas palabras, zk-STARK es la unión de, cómo mínimo, 50 años de investigaciones en criptografía. Un trabajo en el que influyeron mentes tan brillantes como las de Shafrira Goldwasser y Silvio Micali.

Así con esta aventurada aproximación, zk-STARK comenzaría su camino para convertirse en un digno rival de zk-SNARK, apuntado a ser el sistema de criptografía que muchas criptomonedas usarán en el futuro, un futuro que podría estar dominado por las computadoras cuánticas.

#### ¿Qué significa zk-STARK?
El término de zk-STARK puede ser seccionado de la siguiente forma:
1. **zk:**  
    Como en conocimiento cero y con gran énfasis en preservación de la privacidad,
2. **Escalable (S – Scalable):**  
    La prueba es de un tamaño relativamente “pequeño” (o aceptable), y la verificación toma exponencialmente menos tiempo que la ejecución de cálculos ingenuos (es decir, es casi instantánea, incluso para pruebas grandes)
3. **Transparente (T – Transparent):**  
    No hay requisitos para una configuración confiable, como en los sistemas zk-SNARK.
4. **Argumento (AR – ARgument):**  
    Como en un esquema de prueba criptográfico computacionalmente seguro que logra la integridad y solidez de un lenguaje específico.
5. **Conocimiento (K – Knowledge):**  
    Ya que se basa en declaraciones relacionadas con información públicamente conocida.

#### Usos de los sistemas zk-STARK
El principal uso de sistemas de pruebas de conocimiento como zk-STARK, se centra en la creación de sistemas altamente seguros y privados. 

Sistemas donde exista una total descentralización de la información, y la misma solo pueda ser accedida bajo una serie de condiciones claramente expresas. Condiciones que además son difícilmente alcanzables por medios no convencionales como, por ejemplo, un hackeo.

Esto obviamente incluye a sistemas como las criptomonedas, donde el uso de criptografía no sólo habilita la seguridad de la red, sino que protege a los usuarios de la misma, les brinda privacidad y anonimato según sea el caso. Y es precisamente en estas últimas donde las  zk-SNARK brillan, porque como toda prueba de conocimiento cero, son perfectas para la privacidad y el anonimato al no revelar de ninguna manera la información, pero dejando al mismo tiempo una herramienta para validar la transacción de forma inequívoca y determinista. Es decir, zk-STARK no revela la información que cifra, pero siempre podrás validar su veracidad sin importar el que.

Otro posible uso de las zk-STARK está en impulsar la escalabilidad de la Blockchain, permitiendo que las pruebas criptográficas ocupen menos espacio. En criptomonedas como Bitcoin, donde el tamaño de bloque es un limitante en la cantidad de transacciones que se pueden procesar por segundo, esto es vital. Con pruebas criptográficas de menor tamaño, las transacciones también ocupan menos espacio, y caben más transacciones en cada bloque. El efecto se hace más grande a medida que se aplica en miles de transacciones, y con ello, se logra mejorar la escalabilidad. Sin embargo, esto es solo una parte dentro de una solución de escalabilidad, puesto que las pruebas criptográficas más pequeñas no harán que la Blockchain aumente su rendimiento de forma drástica.

Otros posibles usos de este tipo de sistemas serían, por ejemplo, los sistemas de streaming con copyright completamente cifrados y seguros. Con ello no serían necesarios los actuales sistemas de cifrado basados en criptografía simétrica en su mayoría. Los sistemas de votación electrónicos también se benefician enormemente de este tipo de sistemas. Esto gracias a que permiten que el elector pueda emitir su voto, este puede ser verificado, pero de ninguna manera sabremos quien lo emitió.

Como puedes ver el potencial de las zk-STARK no solo está en el mundo Blockchain, sino también mucho más allá.

#### Algunas diferencias entre zk-STARK y zk-SNARK
Algunas de las diferencias entre zk-STARK y zk-SNARK son las siguientes:
1. Los zk-SNARK requieren una fase de configuración confiable mientras que los zk-STARK usan aleatoriedad públicamente verificable para crear sistemas de cómputo verificables sin confianza.
2. Los zk-STARK son más escalables en términos de velocidad y tamaño computacional en comparación con los zk-SNARK.
3. Los zk-SNARK son vulnerables a los ataques de los ordenadores cuánticos debido a la criptografía que usan. Los zk-STARK son actualmente resistentes a los ordenadores cuánticos.
4. Otros aspectos importantes, podemos verlos en la siguiente tabla comparativa, donde podemos ver los diferentes campos donde destaca zk-STARK frente a otras pruebas ZKP conocidas.

#### zk-STARK y sus aplicaciones hoy en día
Desafortunadamente la tecnología es tan reciente (2018) que no ha sido extensamente probada ni estudiada, y aun no se aplica en ningún sistema de producción real. Ni siquiera en el mundo de las criptomonedas.

De momento, la única utilidad conocida de las zk-STARK está siendo desarrollada por Starkware, una empresa creada por los diseñadores de zk-STARK. El objetivo es diseñar una cama de prueba que habilite la tecnología para su uso en Blockchain, exchanges descentralizadas y mucho más. Sin embargo, pasarán algunos años más antes de que podamos ver la tecnología aplicada en esos espacios. Sin duda el futuro de la criptografía zk-STARK apunta a ser prometedor.

### Optimizaciones de la Criptografía: Bulletproofs
Uno de los protocolos de privacidad más recientes que existen en el ecosistema criptográfico son los Bulletproofs. 

Un protocolo implementado principalmente en la criptomoneda Monero con la finalidad de mejorar su nivel de privacidad y que fue lanzado a finales de 2017.

Este protocolo está basado en dos sistemas de privacidad: las pruebas de conocimiento cero (las zk-SNARKs precisamente) y las transacciones confidenciales (Confidential Transactions – CT). Es decir, el protocolo Bulletproofs hace una combinación bastante inteligente de ambos sistemas. En un concepto más técnico, los protocolos Bulletproofs son un método mucho más eficiente que las pruebas zk-SNARKs. 

Esto permite la verificación de ciertos parámetros de forma confidencial y segura, pudiendo utilizarse sin la necesidad de una configuración de confianza por parte del creador.

#### Origen e implementación de Bulletproofs
El protocolo Bulletproofs se desarrolló y se hizo público a finales del año 2017. Sus desarrolladores principales son Jonathan Bootle del University College de Londres, Inglaterra y por Benedikt Bunz de la Universidad de Stanford, Estados Unidos. 

Pero también participaron en su creación Dan Boneh, Andrew Poelstra, Pieter Wuille y Greg Maxwell.  El protocolo diseñado por estos dos desarrolladores llamó rápidamente la atención de la comunidad criptográfica, mostrando un genuino interés por conocer la forma en cómo funcionaba este nuevo protocolo y cómo podrían implementarlo dentro de sus Blockchains. 

Podéis consultar el whitepaper del protocolo [aquí](https://eprint.iacr.org/2017/1066.pdf).

Aunque el protocolo Bulletproofs ( conocido como “a prueba de balas” ) fue diseñado en un principio para ser implementado en la Blockchain de Bitcoin, han sido las de Monero y la red MimbleWimble quienes realmente han comenzado a utilizar este protocolo para mejorar su nivel de privacidad. Así mismo, el CEO de Litecoin también está evaluando la posibilidad de comenzar a implementar este protocolo dentro de la Blockchain de su criptomoneda.

Así mismo, aunque el protocolo Bulletproofs no ofrezca una privacidad o un anonimato total a los usuarios, su implementación sí permite ocultar las cantidades asociadas en las transferencias realizadas. Mostrando solamente el origen y el destino de la transacción, pero sin revelar en ningún momento las cantidades transferidas.

Por ello, el diseño de este nuevo protocolo fue impulsado por la creciente necesidad de los usuarios y de la comunidad de gozar de un nivel de privacidad superior al ofrecido por las Blockchains públicas, en el momento en que realizan sus transacciones y operaciones financieras.

Es bien conocido que una de las mayores ventajas que ofrece la tecnología Blockchain es su inmutabilidad y su nivel de transparencia al momento de registrar las transacciones realizadas. Pero para ciertas aplicaciones, estas propiedades de la Blockchain no son las más apropiadas. Cuando se trata de compañías que requieren de un nivel de privacidad y confidencialidad, o de simples usuarios que quieren disfrutar de estos beneficios, la transparencia de la tecnología Blockchain pública no es la mejor opción.

#### ¿Cómo funcionan los Bulletproofs?
La criptografía detrás de las Bullteproofs es tan compleja que solo unos pocos criptográfos la comprenden en profundidad. 

- **El objetivo de las Bulletproofs es ocultar los valores involucrados en una transacción,** sin que ello merme la capacidad de verificar su autenticidad por parte de la red. 
- **Para lograr esto, los protocolos Bulletproofs se basan en los compromisos de Pedersen** (Pedersen Commitment), un tipo especial de criptografía que recibe el nombre de criptografía homomórfica.
- **El funcionamiento de los Pedersen Commitment permite que los valores puedan ser validados sin necesidad de revelarlos públicamente en ningún momento.** Para lograr esto, usan un pequeño truco matemático que permite demostrar que la suma de las entradas es superior a las sumas de las salidas. Así que no se están generando monedas de la nada, ni se están utilizando monedas ya gastadas, o utilizando un saldo negativo que no se posee. Simplemente, estás enviando un mensaje cifrado en el que el resto puede verificar que realmente estás usando tu saldo, pero nadie sabe cuánto saldo es.
- **Estos protocolos se basan en el supuesto de un logaritmo discreto (logarithm discret):** Esto los hace extremadamente versátiles y compatibles con cualquier algoritmo de curva elíptica. Además, los protocolos Bulletproofs hacen uso de las técnicas criptográficas Heurísticas de Fiat-Shamir, lo que les permite ganar un carácter no interactivo y crear pruebas cortas de conocimiento cero. Esto tiene como finalidad crear sistemas de firmas criptográficas muy cortas, que pueden verificarse rápidamente y sin utilizar mucho poder de cómputo.

En definitiva, la unión de todas estas partes permite la creación de un sistema de pruebas criptográficas rápido, eficiente y seguro.

#### Capacidades de los protocolos Bulletproofs
Con los protocolos Bulletproofs los usuarios pueden disfrutar de un nivel de privacidad mayor que con la Blockchain de Bitcoin o de Ethereum. 

Por ejemplo, si se trata de compañías y empresas, no tendrán que preocuparse porque su competencia pueda ser cuánto dinero le transfieren a sus proveedores. En el caso de usuarios en general, no tendrán que preocuparse de que otras personas puedan ver cuánto dinero manejan en sus cuentas o cuánto dinero ganan en un mes.

Las transacciones realizadas a través de estos protocolos pueden tener una tarifa de comisión mucho más baja. Esto se debe a que los protocolos de Bulletproofs minimizan los excesos computacionales reduciendo el tamaño de las pruebas criptográficas significativamente.

Los protocolos Bulletproofs se pueden implementar en conjunto con CoinJoin. Así pueden proporcionar un nivel de privacidad superior a los usuarios que así lo deseen. Aunque estos protocolos ofrecen una solución mucho más lenta de confirmar y validar que las pruebas de conocimiento cero (zk-SNARKs) o las transacciones confidenciales (confidential transactions), son mucho más eficientes y seguros de implementar en las Blockchains de las criptomonedas.

Los protocolos Bulletproof proporcionan un alto nivel de confianza a los usuarios de las Blockchains que implementan este protocolo. Esto debido a que no requieren de una configuración de confianza como sí ocurre con las pruebas de conocimiento cero (zk-SNARKs). Esto quiere decir, que al momento de configurar los protocolos Bulletproofs, los parámetros no se tienen que configurar con un valor secreto. Los protocolos Bulletproofs son de código abierto. Así que cualquier usuario con conocimientos en criptografía puede dar sus aportes en pro de la mejora y el desarrollo de este protocolo.

#### Protocolos Bulletproofs | Casos de uso
Los protocolos de Bulletproofs son muy versátiles y poseen una gran variedad de aplicaciones que varían desde las redes Blockchain y los protocolos criptográficos hasta implementaciones en Smart Contracts o contratos inteligentes. 

Aunque en este último, el uso de estos protocolos es bastante complejo. Pese a su complejidad, y a ser tan novedosa esta innovación, ya se está utilizando en algunas criptomonedas.

Por una parte, la red Monero ha sido pionera en la implementación de este protocolo dentro de su Blockchain. Algo que le ha traído grandes beneficios a su comunidad. Por ejemplo, se ha visto una reducción significativa en el tamaño de los datos generados por las transacciones, lo que se ha proyectado hacia una reducción en las tarifas de comisión de las transacciones.

Además, podemos destacar la red MimbleWimble, donde la implementación de los protocolos Bulletproofs como reemplazo de las pruebas de rango en las transacciones confidenciales también ha contribuido en una reducción considerable del tamaño de los UTXO.

## U3. Criptografía aplicada a las criptomonedas
### Criptografía aplicada a las criptomonedas (Video)
![[391.B7_Criptografía_aplicada_a_las_criptomonedas.mp4]]
[Criptografia aplicada a criptomonedas](https://app.web3mba.io?wvideo=o1be0l1q3l)

Este algoritmo funciona a través de criptografía simétrica. Así, el sistema genera dos claves que reciben el nombre de clave privada y clave pública. Ambas claves están relacionadas por una compleja operación matemática realizada sobre una función de curva elíptica. Bajo este esquema de funcionamiento, SDSA garantiza en primera instancia lo siguiente: primero, firmas únicas e irrepetibles para cada conjunto de generación de claves privadas y públicas; segundo, la imposibilidad práctica de falsificar las firmas digitales. Esto es así porque la potencia computacional necesaria para ello está fuera de los límites actuales. Tercero, gracias a estas dos características anteriores, SDSA se considera un estándar seguro para desplegar sistemas de firmas digitales y, por ello, ha sido elegido para ser parte de Bitcoin y de su sistema de dinero digital sin confianza.

El funcionamiento de SDSeA para generar un par de claves puede describirse en el siguiente algoritmo. SK es el primer paso donde el algoritmo decide generar nuestra clave privada. Usando la curva secp256k1, dada por la fórmula \(y^2 = x^3 + 7\), lo que hace el algoritmo en esa primera línea es generar un número decimal muy grande de 256 bits o 32 bytes aleatorio y convertir dicho número en el factor x que se sustituye en la fórmula. Al resolver la fórmula, el sistema nos genera un decimal de 256 bits como el que muestra la siguiente imagen. Este número sería nuestra clave privada para nuestro monedero Bitcoin. Con nuestra clave privada, lo siguiente es generar nuestra clave pública, la cual se genera usando la fórmula \(SK \cdot G = P\), que vemos en la siguiente imagen. En esta fórmula, SK es igual a Y, que es la clave privada que hemos calculado. G es un punto dentro de las posibilidades de la curva SecP256K1. P, sin embargo, es nuestra clave pública generada para la clave privada obtenida. Finalmente, se elige un punto de la curva G y se multiplica por la clave privada, con lo que obtenemos la clave pública correspondiente a nuestra clave privada.

Calculados ambos números decimales, lo que sucede después es una transformación con el fin de reducir el tamaño de las claves, que en este caso es llevar ambas claves a su modo hexadecimal, con lo que nos quedaría la clave privada con muchos menos caracteres. Finalmente, estas claves son almacenadas en un formato conocido como WIF (Wallet Import Format), que permite trabajar de forma segura con las claves privadas, lo que nos deja las claves en este sentido. Con este procedimiento es que se generan las claves para manejar nuestros bitcoins. Por supuesto, cada monedero tiene su propia implementación, lo que les puede hacer más o menos seguros, dependiendo de las protecciones criptográficas que se tomen en cada una de ellas.

Ahora que ya tenemos nuestras claves públicas y privadas creadas, es momento de generar las direcciones de Bitcoin, que no son más que una forma sintetizada de la clave pública. Recordemos que en Bitcoin, las direcciones públicas tienen generalmente esta apariencia: son un conjunto de letras y números alternados cuya longitud varía entre 26 y 32 caracteres. Para crear una dirección, hace falta un total de 9 pasos que explicaremos detalladamente a continuación. El proceso para crear una dirección de Bitcoin se inicia con la generación de una clave privada. Esta nos proporcionará el uso exclusivo de los fondos. A partir de esta, se genera una clave pública que nos permitirá compartir información con otras personas sin poner en riesgo nuestros fondos. La obtención de la clave pública a través de la clave privada se debe a la aplicación del algoritmo SDCA, una implementación muy eficiente en la criptografía de curva elíptica, donde se emplea como punto generador a la curva Secp256k1 para obtener la clave pública.

Entonces, una vez generados este par de claves, se da inicio al proceso de generar las direcciones públicas de Bitcoin. El primer paso es seleccionar la clave pública obtenida a partir de la generación de claves. Esta clave debe estar en formato hexadecimal. Seguidamente, debemos aplicar un hashing a la clave pública por medio de la implementación del algoritmo SHA-256. Este algoritmo permite generar outputs de extensión fija a partir de un input de extensión variable que son irreversibles y no es posible deducir la clave privada a través de la clave pública. Luego de aplicar la función de hashing, obtendremos una secuencia de 256 bits. El tercer paso es hashear de nuevo la salida obtenida anteriormente, aplicando en este caso el algoritmo RIPEMD-160, con el cual se produce una secuencia de 160 bits, como muestra la imagen. Seguidamente, debemos añadir el byte de versión usado para la red principal de Bitcoin, 0x00, delante de la salida obtenida de la aplicación del algoritmo de hashing RIPEMD-160. Con esto obtendremos una dirección Bitcoin en formato hexadecimal que se verá como la siguiente imagen. Al añadir este byte, también permite identificar y distinguir las direcciones Bitcoin de otras criptomonedas que también emplean el mismo protocolo.

Ahora debemos realizar el hash con el algoritmo SHA-256 al resultado que hemos obtenido de realizar anteriormente el algoritmo RIPEMD-160. Este paso es necesario como mecanismo de verificación para comprobar que la dirección de Bitcoin está bien escrita. Y con ello, debemos aplicar el hash con el algoritmo SHA-256 nuevamente al resultado del hash anterior. Con este paso se concatena la dirección obtenida. Como ya mencionamos, el algoritmo SHA-256 se aplica dos veces como mecanismo de verificación. Ahora debemos elegir los cuatro primeros bytes del último hash de SHA-256 que representan el checksum de la dirección Bitcoin. Agregamos los 4 bytes del checksum del punto anterior al hash extendido de RIPEMD-160 del punto anterior. Esto es una dirección binaria de Bitcoin de 25 bytes. Finalmente, convertimos el resultado de la cadena de bytes utilizando la codificación en base 58, utilizada para codificar las direcciones de Bitcoin. Con lo que la cadena de bytes se transformará en una cadena en base 58, como muestra la imagen. Este es el formato más empleado para las direcciones de Bitcoin. Así, la codificación en base 58 convierte la cadena de bytes en un conjunto de números y letras mayúsculas y minúsculas. Esto con la finalidad de que sean más fáciles de distinguir, aunque en conjunto siguen siendo caracteres ilegibles y que a primera vista no son crípticos.

Para entender cómo funcionan y se verifican las transacciones de Bitcoin, debes tener muy en cuenta cómo se generan las claves públicas y privadas, y, segundo, lo que ello representa. El modelo matemático de SDSA ha sido diseñado para que nos permita generar pares de claves de forma muy rápida. Y hacemos mucho énfasis en generar porque crear las claves es sencillo a nivel matemático y computacional, pero romperlas es prácticamente imposible. Para dejarlo más claro aún, podemos tomar un número cualquiera con 256 bits de extensión y transformarlo en nuestra clave privada, usando SDSA con la curva SECP256K1. De ese número clave privada, podemos generar cientos de miles de millones de claves públicas relacionadas matemáticamente, siendo todas y cada una de ellas muy seguras. Lo que no se puede hacer es el proceso inverso, es decir, tomar una clave pública y obtener de la clave pública la clave privada de la misma, con lo que obtendremos el control de todo el sistema. Esto es posible porque el problema matemático presente en SDSA es tan complejo que ni todas las supercomputadoras del mundo juntas podrían hallar todas las soluciones posibles al mismo, y si lo hacen, les tomaría millones de años en hacerlo.

Ahora bien, ¿esto nos dice que las claves son seguras? Hasta el punto de que podemos decir que una clave es solo conocida por su auténtico dueño. Así, quien tome posesión de unos bitcoins en una dirección es su dueño porque tiene el control de la clave privada, usada para generar la clave pública a la que se ha enviado dicho Bitcoin. La dirección es una forma de clave pública sintetizada. Pero, ¿cómo se demuestra esto? La respuesta tiene dos partes: el script que acompaña la transacción y la firma digital dentro de la misma. Bitcoin autentifica las transacciones y los remitentes con firmas digitales creadas usando pares de claves. El remitente quiere que la cantidad correcta de Bitcoin sea transferida a la persona correcta, a su cartera, y el receptor quiere asegurarse de que los datos son exactos y provienen del remitente. La ejecución comprende cinco pasos. El primero, los datos. Se inyecta la operación en Bitcoin Script resolviendo previamente un acertijo. El segundo paso es SHA-256, con el cual se genera la operación. El tercer paso es SDSA, se toma la clave privada del remitente. El cuarto paso es la firma digital. Se crea una firma digital que el destinatario tendrá que resolver. El quinto paso es el desafío al destinatario. Aquí el destinatario ha de resolver el puzzle para acceder al dinero utilizando la clave privada de su monedero y generando una clave pública en forma de hash que tenga que ser idéntica. Solo en el último caso es cuando realmente una operación se autentica para gastos, un proceso en el que puede participar el dueño de la dirección, siendo que los mineros y los nodos tienen solo posibilidades para resolver una verificación parcial del script, lo que les permite decidir si la operación está bien formateada y, por lo tanto, es válida para integrarse al historial. O, por el contrario, está mal formateada y debe ser rechazada completamente, con lo que el destinatario verá que la transacción desaparece.

Detallando las operaciones, ahora que conocemos los fundamentos de las transacciones, vamos a sumergirnos en algunos detalles. Recibiendo Bitcoins. Usted decide vender su coche antiguo, y un comprador ofrece pagar con bitcoins, lo que debe proporcionar una dirección de bitcoins. Crea una dirección usando una clave pública derivada de tu clave privada, lo que da como resultado una PUBKeyHash, una clave pública en formato hash, la cual conviertes en una dirección Bitcoin que empieza por uno o por tres con el formato base 58. Se puede realizar ingeniería inversa del public key hash a partir de la dirección, pero no se puede obtener la clave pública a partir del public key hash. Con la dirección proporcionada se creará una salida de transacciones que contiene, primero, el TxId de la operación; segundo, la cantidad total en Satoshi, la unidad más pequeña de Bitcoin; y tercero, el script PubKey que bloquea la cantidad en su PubKey hash. Así, cuando finalmente quieras gastar los 10 Bitcoins, tu clave privada se utilizará para alimentar el PubKey script y desbloquear el Bitcoin recibido, en donde el pubkey hash es este que veis en la foto. Este dato es el que representará el desafío que debe completar el dueño de la dirección a la que se envían los fondos. Solo completando el desafío podrá tomar el control de los mismos. La transacción debe ser validada y minada por los mineros. Normalmente en 10 minutos, pero a veces puede ser que tarde un poco más para ser completada, y entonces, tu monedero indicará el depósito de 10 bitcoins. El monedero no contiene el dinero como un monedero del mundo real, solo una salida llamada UTXO. Los UTXOs se desbloquean cuando envías una parte o la totalidad de bitcoins a otra dirección, creando un nuevo UTXO. La red Bitcoin no es un sistema basado en cuentas, sino una matriz de UTXOs. Los monederos contienen las claves para desbloquear esos UTXOs y transferirlos a otros. Si envías cualquier cantidad de Satoshis, crearás un nuevo UTXO para esa transacción. Y o bien envías todo el Bitcoin con el nuevo UTXO único, o bien se crea un segundo UTXO nuevo con el resto, que se te devuelve directamente.

Ahora, ¿quieres gastar ese Bitcoin de la venta del coche para pagar tu casa nueva? Por lo tanto, crearás una nueva entrada y una nueva salida. La entrada. Así empiezas con el ID de la transacción y el índice para localizar el UTXO y el script pubkey de la venta. A continuación, se creará un nuevo script SIG y el script pubkey. Script de firma, que se les llama, que este script lo que hace es satisfacer el script de Pubkey y desbloquear los bitcoins que hemos recibido. Este script SIG o script de firma tiene una firma en la que se puede comprobar todos los datos de las transacciones para enviar y la clave pública del nuevo destinatario. Esos datos son el TxId de la transacción antigua, el índice antiguo, el script pubkey del remitente anterior y el script pubkey del nuevo destinatario, el total de Satoshis que van al nuevo destinatario, y todos estos datos se terminan convirtiendo en hash dos veces con el algoritmo SHA-256 y se firman con su clave privada. Este producto se añade entonces a su clave pública para crear el nuevo Script SIG. La salida en este caso contiene los Satoshis que se van a transferir, un nuevo índice y un nuevo script pubkey con la dirección del nuevo destinatario, la cual ha proporcionado para bloquear el Bitcoin a su dirección. Finalmente, enviamos la operación a la red y los mineros la toman. En este punto, los mineros tomarán el script y lo ejecutarán en el script pubkey. Si el resultado es verdadero, las transacciones se añaden al bloque y se valida. Si, por el contrario, es falso, se rechaza la operación porque la misma es inválida. En todo caso, el Script Pubkey utiliza el siguiente proceso apilado de seis pasos para verificar. Puede devolver falso, puede devolver verdadero. La transacción solo aplica al caso de transacciones P2PKH. Añadir el script SIG y luego aplicar sobre este la clave pública, la PubKey. En todo caso, el script PubKey utiliza el proceso de apilado para verificar si es verdadero o falso.

### Generación de claves para cuentas de BTC 
El algoritmo ECDSA bajo la curva elíptica secp256k1, es el algoritmo y modelo matemático de curva elíptica (ECC) elegido para la generación de las claves públicas y privadas para Bitcoin. 

Este algoritmo funciona bajo el mecanismo de criptografía asimétrica, que hemos visto con más detalle en la Unidad 2|02. 

Así, el sistema genera dos claves que reciben el nombre de clave privada y clave pública. Ambas claves están relacionadas por una compleja operación matemática realizada sobre una función de curva elíptica.

Bajo este esquema de funcionamiento, ECDSA garantiza en primera instancia lo siguiente:
1. **Firmas únicas e irrepetibles** para cada conjunto de generación de claves privadas y públicas.
2. **La imposibilidad práctica de falsificar las firmas digitales.** Esto es así porque la potencia computacional necesaria para ello, está fuera de los límites actuales.
3. **Gracias a estas dos características, ECDSA se considera un estándar seguro para desplegar sistemas de firmas digitales,** y por ello ha sido elegido para ser parte de Bitcoin y de su sistema de dinero digital sin confianza. 

El funcionamiento de ECDSA para generar un par de claves puede describirse en el siguiente algoritmo:
_def generate_ECDSA _keys():_

_**sk =** ecdsa.SigningKey.generate(curve=ecdsa.SECP256k1)_  
_**private_key =** sk.to_string().hex()_  
_**vk =** sk.get_verifying_key()_  
_**public_key =** vk.to_string().hex()_  
_**public_key =** base64.b64encode(bytes.fromhex(public_key))_

En el mismo, sk es el primer paso donde el algoritmo decide generar nuestra clave privada usando la curva secp256k1 dada por la formulación:
y² = x³+7

![[392.B7_formula.png]]

Lo que hace el algoritmo en esa primera línea es generar un número decimal muy grande (256 bits o 32 bytes) y aleatorio, y convertir dicho número en el factor X que se sustituye en la fórmula. Al resolver la formulación, el sistema nos genera un decimal de 256 bits como el siguiente:
**y =** 26659562846916060511922949034259915492435881110761592598091969364159099586702

Este número sería nuestra clave privada para nuestro monedero BTC.  Con nuestra clave privada, lo siguiente es generar nuestra clave pública la cual se genera usando la formulación:
sk * G = P

En esta formulación:
- **sk** **= y**, la clave privada que hemos calculado.
- **G,** es un punto dentro de las posibilidades de la curva secp256k1. 
- **P =** nuestra clave pública generada para la clave privada obtenida. 

Lo que pasa en este punto es que se elige un punto de la curva (G) y se multiplica por la clave privada, con lo que obtenemos la clave pública correspondiente a nuestra clave privada dada que en este caso es:
**P =** 256856522890203195270162196352093529975669564346194518212537584861552238876390

Calculados ambos números decimales, lo que sucede después es una transformación con el fin de reducir el tamaño de las claves, que en este caso es llevar ambas claves a su modo hexadecimal, con lo que nos queda:
- **Clave privada**
3af0c720dd3b7fd61eb55280bcaa2d90ed05b9385b59105ace5db2771b6c488e
- **Clave pública**
0237dfa3d97c3a163dc71765564366c4fb7ba4bd8bf5884e2fdbe259203b3f56e6

Finalmente, estas claves son almacenadas en un formato conocido como WIF (Wallet Import Format) que permite trabajar de forma segura con las claves privadas, lo que nos deja las claves en este sentido:

**WIF Clave Privada (descomprimida):**  
5JjdcuoJ1TmyKCPA1g9WmZgspZomgjg5YgEXauQ7BhXWvaMbKcx

Con este procedimiento se generan las claves para manejar nuestros BTC. Por supuesto, cada monedero tiene su propia implementación, lo que les puede hacer más o menos seguros, dependiendo de las protecciones criptográficas que se tomen en cada una de ellas. 

![[392.B7_ecc.png]]

### Generación de dirección BTC
Ahora que tenemos nuestras claves públicas y privadas es momento de generar las direcciones de BTC, que no son más que una forma sintetizada de la clave pública. 

Recordemos que, en Bitcoin, las direcciones públicas tienen generalmente esta apariencia: 
1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa. 

Como podemos ver son un conjunto de letras y números alternados cuya longitud varía entre 26 y 32 caracteres.

Para crear una dirección, hacen falta un total de 9 pasos que explicaremos detalladamente a continuación.

#### Proceso para crear una dirección Bitcoin
El proceso para crear una dirección Bitcoin se inicia  primero con la generación de una clave privada. 

Esta nos proporcionará el uso exclusivo de los fondos. A partir de esta, se genera una clave pública que nos permitirá compartir información con otras personas sin poner en riesgo nuestros fondos. La obtención de la clave pública a través de la clave privada se debe gracias a la aplicación del algoritmo ECDSA. Una implementación muy eficiente de la criptografía de curva elíptica, donde se emplea como punto generador a la curva secp256k1 para obtener la clave pública.

Una vez generadas este par de claves, se da inicio al proceso de generar las direcciones públicas de Bitcoin.

##### Paso 1:
Seleccionar la clave pública obtenida a partir de la generación de claves. 

Esta clave debe estar en formato hexadecimal, siendo nuestro caso:
03aea008599c02435fb85dae8ff6d08fe3b7ba685c518f54b0c85d0765e32b2fa5

##### Paso 2:
Aplicamos un _hashing_ a la clave pública por medio de la implementación del algoritmo SHA-256. 

Este algoritmo permite generar _outputs_ de extensión fija a partir de inputs de extensión variable, que son irreversibles. Por lo que son unidireccionales y no es posible deducir la clave privada a través de la pública.

**Después de aplicar la función _hashing_ obtendremos una secuencia de 256 bits:**
dcb3957e356cccf91bb03c2a16c8118824295653d8a2e7777f2b9a50eea28980

##### Paso 3:
_Hashear_ de nuevo la salida obtenida anteriormente, aplicando en este caso el algoritmo RIPEMD-160. Con el resultado que produce, obtendremos una secuencia de 160 bits:
ef29025ec92825f5303e463ced5d1d4a3eb616bd

##### Paso 4:
Añadimos el byte de versión usado para la red principal de Bitcoin (0x00) delante de la salida obtenida de la aplicación del algoritmo de hashing RIPEMD-160.

Con esto obtendremos una dirección Bitcoin en formato hexadecimal, que se verá así:
00ef29025ec92825f5303e463ced5d1d4a3eb616bd

Y al añadir este byte también permite identificar y distinguir las direcciones Bitcoin de otras criptomonedas que también emplean el protocolo.

##### Paso 5:
Realizamos el _H__ash_ con el algoritmo SHA-256 al resultado obtenido del RIPEMD-160. 

Este paso es necesario como mecanismo de verificación para comprobar que la dirección de Bitcoin está bien escrita.

0244eee8773612dd82024ac4428b100b1ab93cb2568e884de00846484100e0ba

##### Paso 6:
Con ello debemos aplicar el _H__ash_ con el algoritmo SHA-256 al resultado del _H__ash_ anterior. 

Con este paso se concatena la dirección obtenida. Como ya mencionamos, el algoritmo SHA-256 se aplica dos veces como mecanismo de verificación.

9040907e67ce3a6e4f2dfae4f180b5a5ad7e172eefe7a8b379066c35ae2d31e2

##### Paso 7:
Ahora debemos elegir los 4 primeros bytes del último hash SHA-256, que representan el _Checksum_ de la dirección Bitcoin.

En este ejemplo serían:
9040907e

##### Paso 8:
Agregamos los 4 bytes del _Checksum_ del punto anterior, al _H__ash_ extendido RIPEMD-160 del punto 4. 

Esto es una dirección binaria de Bitcoin de 25 bytes:

00ef29025ec92825f5303e463ced5d1d4a3eb616bd9040907e

##### Paso 9:
Finalmente, convertimos el resultado de la cadena de bytes utilizando la codificación Base58Check, utilizada para codificar las direcciones de Bitcoin**.** 

Con lo que la cadena de bytes se transformará en una cadena base58.

1NoZdDoXEWjFxQfv7ZRuKAEgGeYefE6WQV

Este es el formato más empleado para las direcciones de Bitcoin. Así la codificación Base58Check convierte la cadena de bytes en un conjunto de números y letras mayúsculas y minúsculas.

Esto con la finalidad de que sean más fáciles de distinguir. Aunque en conjunto siguen siendo caracteres ilegibles y que a primera vista no son crípticos.

### Verificación de operaciones
Para entender cómo funcionan y se verifican las transacciones de Bitcoin, debes tener muy en cuenta cómo se generan las claves públicas o privadas y lo que ello representa.

El modelo matemático de ECDSA ha sido diseñado para que nos permita generar pares de claves de forma muy rápida. 

Y hacemos mucho énfasis en generar, porque crear las claves es “sencillo” a nivel matemático y computacional, pero romperlas, es prácticamente imposible.

- **P****odemos tomar un número cualquiera con 256 bits de extensión y transformarlo en nuestra clave privada usando ECDSA con la ECC secp256k1.** 
- **De ese número o clave privada, podemos generar cientos de miles de millones de claves públicas relacionadas matemáticamente, siendo todas y cada una de ellas muy seguras.** 
- **Lo que no se puede hacer es el proceso contrario, es decir, tomar una clave pública y obtener de ella la clave privada, con lo que obtendremos el control de todo el sistema.**

Esto es posible porque el problema matemático presente en ECDSA es tan complejo, que ni todas las supercomputadoras del mundo juntas podrían hallar todas las soluciones posibles, y si lo hacen, les tomaría millones de años en hacerlo.

Ahora bien, esto nos dice que las claves son seguras hasta el punto en que podemos decir que una clave es solo conocida por su auténtico dueño. Así, quien tome posesión de unos BTC en una dirección es su dueño porque él tiene el control (la clave privada) usada para generar la clave pública a la que se ha enviado dicho BTC (la dirección es una forma de clave pública sintetizada).  

Pero, ¿Cómo se demuestra esto? La respuesta está en dos partes: 
- El Script que acompaña la transacción.
- La firma digital dentro de la misma.

#### Proceso básico de autenticación de transacciones en Bitcoin
Bitcoin autentifica las transacciones y los remitentes con firmas digitales creadas usando pares de claves.  

El remitente quiere que la cantidad correcta de bitcoins sea transferida a la persona correcta (cartera) y el receptor quiere asegurarse de que los datos son exactos y provienen del remitente.

**De este modo se ejecuta la siguiente operación:**
1. **Data:** Aquí se inyecta la data de la operación del Bitcoin Script. Para esto, el remitente debe resolver previamente un acertijo criptográfico que le permita controlar el saldo. Eso solo es posible si demuestra que el saldo en la dirección está bajo su control (la clave pública es generada por su clave privada).
2. **SHA-256:** Se genera un SHA-256 de la operación (TX ID)
3. **ECDSA Priv Key:** Se toma la clave privada del remitente y se prepara para el siguiente paso.
4. **Digital Signature:** Se genera una firma digital de la operación en la que, como remitentes, autorizamos el movimiento a la espera de que el destinatario pueda resolver el puzzle del Bitcoin Script que hemos creado usando su clave pública (la dirección BTC a la que enviamos las monedas).
5. **Desafío al destinatario:** En este punto, el destinatario ve el dinero en "Entrada". Si desea usar ese dinero, debe completar el puzzle que le ha enviado el remitente. Básicamente, su trabajo es tomar la clave privada de su monedero, generar la clave pública, su forma hash y verificar que las firmas digitales son idénticas y válidas. En este punto, si el destinatario realiza una operación con esos BTC, se reinicia el proceso con los nuevos participantes.

Solo en el último caso es cuando realmente una operación se autentifica para gastos, un proceso en el que solo puede participar el dueño de la dirección, de modo que los mineros y los nodos tienen solo posibilidades para resolver una verificación parcial del Script. Esto les permite decidir si la operación está bien formateada (y, por tanto, es válida para integrarse en el historial) o, por el contrario, está mal formateada y debe ser rechazada completamente (con lo que el destinatario verá que la transacción desaparece). 

#### Detallando las operaciones
Ahora que conocemos los fundamentos de la transacción, vamos a sumergirnos en algunos detalles.

##### Recibiendo BTC
Usted decide vender su coche antiguo y un comprador ofrece pagar con bitcoin, por lo que debe proporcionar una dirección bitcoin.  

Creas una dirección usando una clave pública derivada de tu clave privada, lo que da como resultado un "_PubKeyHash_" o una clave pública en formato hash, la cual conviertes en una dirección bitcoin que empieza por un 1 o un 3 con el formato Base58check.

Se puede realizar ingeniería inversa del _PublicKeyHash_ a partir de la dirección, pero no se puede obtener la clave pública a partir del _PublicKeyHash_. Con la dirección proporcionada, se creará una salida de transacción que contiene:
1. El TX ID de la operación.
2. La cantidad total en _satoshis_ (la unidad más pequeña de bitcoin)
3. El _script PubKey_ que bloquea la cantidad en su _PubKeyHash_

**Así, cuando finalmente quieras gastar los diez bitcoins, tu clave privada se utilizará para alimentar el PubKey Script y desbloquear el Bitcoin recibido. El resultado de todo esto sería el siguiente script:**

OP_DUP OP_HASH160 b2089ebaad05c87a6d714cc33fbaa8cf181a4e30 OP_EQUALVERIFY OP_CHECKSIG

Donde el _PubKeyHash_ es b2089ebaad05c87a6d714cc33fbaa8cf181a4e30. Este dato es el que representará el desafío que debe completar el dueño de la dirección a la que envían los fondos. Solo completando el desafío podrá tomar el control de los fondos. 

Por supuesto, la transacción debe ser validada y minada por los mineros (normalmente en 10 minutos, pero a veces más) para ser completada, y entonces tu monedero indicará el depósito de diez bitcoins.  El monedero no "contiene" el dinero como un monedero del mundo real, solo una salida llamada _Unspent Transaction Output_ (UTXO).  Los UTXO se desbloquean cuando envías una parte o la totalidad del bitcoin a otra dirección creando un nuevo UTXO. 

La red bitcoin no es un sistema basado en cuentas, sino una matriz de UTXOs.  Los monederos contienen las claves para desbloquear esos UTXOs y transferirlos a otros. 

##### Enviando BTC
Si envías cualquier cantidad de _satoshis_, crearás un nuevo UTXO para esa transacción. Y, o bien envías todo el bitcoin con el nuevo UTXO único o bien se crea un segundo UXTO nuevo con el resto, que se te devuelve directamente. 

**Ahora quieres gastar ese bitcoin de la venta del coche para pagar tu casa nueva. Por lo tanto, crearás una nueva entrada y una nueva salida.**

###### Entrada
Así, empiezas con el ID de la transacción y el índice para localizar el UTXO y el _Script PubKey_ de la venta del coche. 

A continuación, se crea un nuevo _ScriptSig_ (Script de Firma) que es para satisfacer el _Script PubKey_ y desbloquear los BTC que hemos recibido. Este _ScriptSig_ Firma tiene una firma en la que se puede comprobar todos los datos de la transacción para enviar y la clave pública del nuevo destinatario.  Esos datos son:
1. **TX ID** de la transacción antigua
2. **Índice antiguo**
3. _**Script PubKey**_ de remitente anterior
4. _**Script PubKey**_ del nuevo destinatario
5. **Total de _satoshis_,** que van al nuevo destinatario

Estos datos se convierten en _Hash_ dos veces con el algoritmo SHA-256 y se firman con su clave privada.  Este producto se añade entonces a su clave pública para crear el nuevo ScriptSig.

###### Salida
La salida, en este caso, contiene los satoshi que se van a transferir, un nuevo índice y un nuevo Script PubKey con la dirección del nuevo destinatario, dirección que ha proporcionado para bloquear el bitcoin a su dirección.

###### Proceso de minería e inclusión en la red 
Finalmente, enviamos la operación a la red y los mineros la toman. 

En este punto, los mineros tomarán el _ScriptSig_ y lo ejecutarán con el _Script PubKey._  Si el resultado es "verdadero", la transacción se añade al bloque y se valida. Si es falso, se rechaza la operación porque la misma es inválida (estás haciendo trampa). 

En todo caso, el _Script PubKey_ utiliza el siguiente proceso apilado de seis pasos para verificar (devolver una T o F) la transacción (solo aplica al caso de transacciones P2PKH):
1. **Añadir el Script Sig** y luego apilar sobre él la clave pública (PubKey)
2. **OP_DUP** duplica lo último añadido a la pila (la PubKey)
3. **OP_HASH160** hace un _Hash_ de la clave pública duplicada Pk _Hash_
4. **PubKey (Pk)** _Hash_ de la primera transacción (coche) se añade (Pk _Hash_ en el óvalo)
5. **OP_EQUALVERIFY** compara las dos partes superiores de la pila, el Pk _Hash_ de la transacción del coche (en el óvalo) y el Pk _Hash_ de la clave pública proporcionada al Script de Firma (en el cuadrado). Si son iguales, se eliminarán (saltarán) de la pila. (dejando la clave pública y la firma)
6. **OP_CHECKSIG** utilizará la clave pública para descifrar la firma. El _Script PubKey_ comprueba entonces la coincidencia entre la firma digital y la salida de los datos que se han cifrado y firmado dos veces, creando la firma (sig).  Si coinciden, la _Sig_ y la _PubKey_ se desprenden y un resultado "Verdadero" se añade al nuevo bloque y se valida en la red. Si es "Falso", la transacción falla y no se añade.

![[394.B7_evaluation_stack.png]]

## U4. Otros sistemas de seguridad
### Otros sistemas de seguridad (Video)
![[395.B7_Otros_sistemas_de_seguridad.mp4]]
[Otros Sistemas de Seguridad](https://app.web3mba.io?wvideo=ik5tlwxgsz)

El masking, data masking o enmascaramiento de datos, es una técnica informática utilizada para proteger la información sensible que maneja una aplicación en ambientes de producción. Generalmente, esta técnica busca sustituir los datos con versiones compuestas de los mismos mediante medios que incluyen hashing o diferentes procesos informáticos que permiten transformar dicha información en una que no dé acceso directo a los datos que se desean proteger. Esto resulta de enorme utilidad para distintas actividades, como el desarrollo de software, la realización de pruebas o, por ejemplo, la minería de datos.

Estas son algunas de las principales razones por las que las empresas utilizan el data masking. Primero, para proteger los datos de proveedores externos. El intercambio de datos con vendedores externos, consultores y otros es normal, pero cierta información debe mantenerse confidencial. Segundo, para proteger los datos de los usuarios externos. Los errores de operador son comunes. Las empresas confían en sus expertos para tomar buenas decisiones, pero las violaciones de datos a menudo son el resultado de un error del operador, y las empresas pueden salvaguardarse con el enmascaramiento de datos. Tercero, no todas las operaciones requieren el uso de datos totalmente reales y precisos. Hay muchas funciones dentro de un departamento de TI que no necesitan datos reales, por ejemplo, algunas pruebas y el uso de aplicaciones. Cuarto, definir el data masking significa comprender el importante papel que desempeña en la Estrategia General de Seguridad de Datos de la empresa. Y quinto, el objetivo principal del enmascaramiento de datos es proteger datos complejos y privados en condiciones en las que los datos puedan ser notorios para alguien sin su permiso.

Básicamente, existen tres tipos de enmascaramiento. El primero es el estático, que se refiere a un proceso en el que los datos importantes se enmascaran en el entorno de la base de datos original. El contenido se duplica para crear un entorno de más amplio acceso y luego se puede compartir con proveedores externos u otras partes necesarias. Los datos se enmascaran y se extraen de la base de datos principal, debidamente protegida, donde se encuentran los datos reales, y se trasladan a otra base de datos de servicio, donde ya están enmascarados. Si bien el data masking estático puede ser un proceso necesario para trabajar con consultores externos, su aplicación no es ideal. Esto se debe a que, durante todo el proceso de enmascaramiento de datos para una base de datos duplicada, se extraen datos reales que pueden dejar una puerta trasera abierta que fomenta las violaciones.

Después tenemos el enmascaramiento dinámico. En este caso, el proceso de enmascaramiento permite a los departamentos de TI proteger los datos en tiempo real. Esto significa que los datos nunca abandonan la base de datos principal; en caso de requerirse información, el sistema enmascara los datos según el usuario y su nivel de acceso que ha solicitado la información, haciendo verificación en todo momento de este proceso y reduciendo la superficie de ataque del sistema. Para ello, se necesita un sistema de enmascaramiento. Una herramienta de enmascaramiento dinámico encuentra y enmascara ciertos tipos de datos confidenciales utilizando un proxy inverso, un recurso de software que se encarga de revisar toda la información de forma totalmente transparente y que permite al sistema enmascarar los datos según se requiera. Así, solo los usuarios autorizados podrán ver los datos auténticos.

El tercer tipo que tenemos lo vamos a denominar sobre la marcha. Al igual que el enmascaramiento de datos dinámico, el enmascaramiento de datos sobre la marcha ocurre bajo demanda. En este tipo de enmascaramiento de datos se produce un proceso de extracción de carga de transformación donde los datos se enmascaran en la memoria de una aplicación de base de datos determinada. Esto es particularmente útil para compañías ágiles enfocadas en una entrega continua. En general, la selección de una estrategia de enmascaramiento de datos debe tener en cuenta el tamaño de la organización, así como la ubicación y la complejidad de los datos que desea proteger.

Existen diferentes técnicas de enmascaramiento de datos, entre las que podemos mencionar el key masking. Esta técnica devuelve los datos enmascarados con resultados deterministas para los mismos datos de origen. El enmascaramiento será siempre el mismo para cada valor de entrada. Segundo, el random masking. Una columna configurada para el random masking producirá resultados aleatorios previo a la configuración de un diccionario que contiene los valores de sustitución de todos los datos de origen. Su uso requiere una tabla relacional que contenga los datos de sustitución, así como un número de serie para cada fila de la tabla. Tercero, sustitución. Con esta regla de enmascaramiento se reemplaza una columna de datos con datos similares, pero no relacionados que hemos definido con anterioridad. Cuarto, formatos especiales. Los formatos especiales son útiles para enmascarar datos identificativos como el número de seguro social, tarjetas de crédito, números de teléfono, URLs o cualquier otra cosa. Al aplicarlos, cambiamos estos datos por valores realistas en el mismo formato, pero que no son válidos. Quinto, masking de gráfico. Son técnicas usadas para ocultar la identidad de una persona en fotos y demás elementos visuales, en plataformas que hacen uso de este tipo de recursos, por ejemplo, la plataforma KYC. Sexto, masking de documentos. Son técnicas usadas para ocultar información sensible de documentos y demás elementos electrónicos dentro de una plataforma.

Adicionalmente, la importancia de la herramienta de enmascaramiento de datos se ve resaltada por su estrecha relación con la seguridad, en la que deben tenerse en cuenta los siguientes elementos. Primero, cumplimiento de la normativa de privacidad. Las soluciones de enmascaramiento de datos contribuyen a garantizar el cumplimiento de estas leyes reguladas sobre la protección de datos de clientes, proveedores o, por ejemplo, de los mismos empleados de la organización. Su función evita a la empresa elevadas multas en caso de posibles inspecciones. En este apartado, la seguridad también está vinculada a la obligación moral de toda organización de proteger los datos privados, en particular, todos los sensibles. Segundo, evitar el riesgo de fuga. El enmascaramiento de datos bloquea la exposición de datos sensibles de producción a usuarios no autorizados, reduciendo el riesgo de filtraciones de datos críticos, que son bastante frecuentes, como los robos o ataques cibernéticos. Tercero, en otro orden, cabe destacar que la nube constituye una gran oportunidad para reducir costes de infraestructura, pero al mismo tiempo entraña nuevos riesgos de seguridad para los datos. Se trata, en suma, de aplicar políticas de seguridad de datos que garanticen que los datos que residen en la organización se encuentren debidamente protegidos.

En este aspecto, el enmascaramiento de datos debería formar parte de la rutina de trabajo de todas las organizaciones que manejan datos sensibles, un concepto variable en cuanto a su confidencialidad, pero que, sin embargo, a nivel legal, tiene las pautas muy definidas en cuanto se trata de información de tipo personal. El enmascaramiento de datos también ayuda a ahorrar costes en muy distintas situaciones, como la pérdida de datos, fugas o filtraciones, robos, o, por ejemplo, la imposibilidad de llevar a cabo proyectos que impliquen un nivel de seguridad que no tengamos y que exija la implementación de herramientas de enmascaramiento de datos. En este sentido, podríamos dejar de ganar dinero o tener pérdidas precisamente por el mismo motivo, sin olvidar las importantes acciones económicas que pueden llevar a incumplir la normativa de privacidad.

En general, la eficiencia se logra con una adecuada gestión de los datos en terrenos clave, como su calidad y seguridad, y nos ayudará a conseguir una reducción de costes gracias a la eficiencia de la gestión y los mismos procesos operativos. Con la introducción de estándares de privacidad internacionales cada vez más estrictos, las organizaciones tienen una mayor responsabilidad de proteger los datos personales de sujetos que incluyen clientes, proveedores y empleados. Por ejemplo, en la Unión Europea, las multas por el incumplimiento del Reglamento General de Protección de Datos pueden ascender a 20 millones de euros o al 4% de la facturación global, el mayor de ambos. Cumplir con esta legislación lleva a las empresas a solicitar expreso y en términos claros el consentimiento para la utilización de los datos, especificar qué datos se están utilizando y cómo se están tratando, para qué y quién es la persona responsable de los mismos.

Por otro lado, aunque en Estados Unidos y Japón están muchos pasos por detrás de Europa en cuanto a la protección de datos, la primera ley de privacidad del consumidor entró en Estados Unidos en 2020 y la ley de protección de datos personales de Japón ya ha adoptado una serie de enmiendas que planean entrar en vigor en 2022. Es, por tanto, imprescindible ceñirse a las normas vigentes y, ante todo, jamás eludir las obligaciones impuestas por motivos tanto éticos como legales. Las malas prácticas podrían poner en duda la reputación de su negocio y sumar demandas multimillonarias que pondrían en peligro la continuidad de su empresa.

La ofuscación de datos es una forma de enmascaramiento de datos donde los mismos se representan en formas complejas con el fin de evitar su comprensión. De esta manera, la ofuscación funciona como una forma de cifrado que busca hacer ininteligibles o confusos los datos que son tratados en esta técnica. En informática, la ofuscación es conocida como una medida de seguridad por oscuridad, es decir, una medida de seguridad que busca ocultar algo sensible por medio de una técnica compleja que puede ser rota con análisis de la fuente de esa información. La ofuscación de datos tiene varios objetivos, entre los que podemos mencionar, primero, agregar seguridad. Si queremos proteger datos sensibles, incluso luego de un acceso no autorizado a los mismos, la ofuscación puede ayudarnos a esto. Segundo, dificultar la ingeniería inversa del software. El código ofuscado suele ser más complejo de decompilar y, por tanto, más complejo de entender cómo funciona y generar funciones parecidas. Tercero, hace que las firmas estáticas utilizadas por los vendedores de antivirus no puedan detectar el malware, ya que estas firmas se basan en secuencias de bytes específicas en el binario. Cuarto, protección de la propiedad intelectual. Quizás no quieras que tu competencia copie cierto algoritmo que has utilizado. Un buen ejemplo de estos objetivos lo podemos ver en la ofuscación usada en el código, con el fin de que si un atacante obtiene acceso al código fuente de un programa, al estar ofuscado, entender el mismo sea extremadamente complejo para todos los atacantes y averiguar cómo funciona, protegiendo así esta propiedad intelectual.

La ofuscación de datos busca aplicar esta técnica en las variables, constantes, funciones y estructuras que forman parte de un programa. Entre estas técnicas podemos mencionar el constant blending, una técnica que busca sustituir los valores de las constantes por medio de funciones de manipulación de bits dentro de las funciones que usan dichas constantes, o bien por medio de funciones XOR, apuntando a punteros con valores aleatorios. La idea es que la constante no sea usada directamente y su valor se ajuste a la necesidad real de la función en el momento en el que sea llamada, es decir, en tiempo de ejecución. Segundo, cambio de tipo de variables. Cambiando la codificación de las variables se busca ocultar el valor original de la variable. Por ejemplo, podemos cambiar la codificación de un string por su valor equivalente en otra codificación, como una codificación base64. Tercero, conversión de datos estáticos en procesos. Consiste en convertir un dato en un proceso que generará este mismo dato en tiempo de ejecución. Cuarto, cambio del tiempo de vida de las variables. Esta técnica consiste en convertir variables globales en variables locales, las cuales incluso pueden ser manipuladas dentro de esta función o funciones externas. Hay también un largo etcétera de manejo de arrays, donde puedes juntarlos todos, puedes expandirlos, puedes cambiar la longitud o puedes cambiar el número de líneas o el número de columnas, todo con el mismo fin. Muchas de estas funciones son bastante complejas de aplicar. Algunas generan errores de compilación o agregan complejidad adicional al código generado, lo que hace más compleja su depuración. De ahí que deba usarse de forma limitada y en secciones de código que se consideren críticas para mantener la seguridad de un sistema y bajo un estricto desarrollo y revisión del código.

Tenemos diversas técnicas de ofuscación del diseño. La primera podría ser el class merging. Esta técnica consiste en la unión de una o más clases de un programa en una sola clase. Después tenemos el class splitting. Esta técnica consiste en dividir una clase en un determinado programa en varias clases. Y por último, tenemos las técnicas de ofuscación de flujo de control. Consiste en una serie de transformaciones que alteran el flujo de ejecución de un programa. El flujo de ejecución de un programa se puede representar por un grafo de control de flujo en el que los nodos son los bloques básicos de ejecución del programa y las aristas son los enlaces entre bloques básicos de ejecución, que son los conjuntos de instrucciones que se ejecutan secuencialmente, en los que la primera instrucción es el único acceso al bloque y la última instrucción es la única de salida. Esta es una de las técnicas más complejas de ofuscación, hasta el punto que los malware y los ransomware avanzados hacen uso de la misma para evitar que las técnicas de heurística y análisis de software de herramientas avanzadas de seguridad y antivirus que existen en la actualidad los detecten. El nivel de este tipo de técnicas es tal que su uso correcto requiere de un amplio conocimiento de las características de los controles de flujo de los kernels, compiladores y librerías. Uno de los métodos más exitosos en este punto es el de null code, una técnica en la que se agrega código al programa que al final no hace nada, pero que está ahí para disfrazar funciones vitales del programa, evitando ciertas técnicas de análisis.

Desde la creación de las máquinas virtuales, la virtualización de código como método para la ofuscación es una viabilidad. La ofuscación VM-Based, como se conoce en inglés, es un método avanzado de ofuscación. La técnica consiste en reemplazar instrucciones del programa con instrucciones virtuales con las que el atacante no está familiarizado. Posteriormente, estas instrucciones serán traducidas a código de máquina nativa en tiempo de ejecución para ser ejecutadas por el hardware. En un principio, este tipo de tácticas podían ser fácilmente detectadas debido a la enorme cantidad de recursos que podían requerir para su funcionamiento. Pero con la llegada del hardware con funciones de virtualización incluidas, estas técnicas se han hecho cada vez más comunes en el malware y en el software de uso común. En el mundo de las criptomonedas, este tipo de técnicas también son usadas, siendo el uso más conocido el que Monero le da dentro del algoritmo RandomX, el cual ejecuta una máquina virtual sobre el computador para realizar la minería de datos. Todo esto está cifrado con un algoritmo AES-256.

Las organizaciones a menudo necesitan copiar datos de producción almacenados en estos espacios de datos hacia bases de datos de no producción o de prueba. Esto se realiza para completar de manera realista la prueba de funcionalidad de la aplicación y cubrir escenarios en tiempo real o en casos de prueba para minimizar errores o defectos de producción. Como resultado de esta práctica, un entorno de no producción puede convertirse en un blanco fácil para los ciberdelincuentes o empleados malintencionados que buscan datos sensibles que pueden ser expuestos o robados. Debido a que un entorno de no producción no está tan estrechamente controlado o administrado como el entorno de producción, podría costar mucho dinero a las organizaciones el daño a la reputación o al valor de la marca en caso de que ocurra un incidente o una brecha de datos.

Los requisitos regulatorios son otro factor clave para la ofuscación de datos. Por ejemplo, el estándar de seguridad de datos de la industria de tarjetas de pago, el PCI DSS, alienta a los comerciantes a mejorar la seguridad de los datos de las tarjetas de pago con la adopción de medidas consistentes en seguridad de datos que proporcionan una base de requisitos técnicos y operacionales. El PCI DSS requiere que los datos e información de los comerciantes no se utilicen para pruebas y desarrollo. La exposición inadecuada de estos datos, ya sea por accidente o por un incidente malicioso, podría tener consecuencias graves.

El anonimato es el carácter o la condición de ser anónimo, es decir, el hecho de mantener la identidad de una persona o entidad completamente desconocida para el público. Esto puede ser simplemente porque no se haya pedido su identidad, como en un encuentro ocasional entre extraños, o porque la persona no puede o no quiere revelar su identidad, por motivos de seguridad o simplemente porque no es su deseo hacerlo. El anonimato ha sido una práctica que ha estado presente en la historia humana desde la antigüedad, especialmente en momentos históricos donde la vida de esa persona estuviera en especial riesgo, ya sea porque sus acciones eran peligrosas para el poder establecido o simplemente porque contravenían las creencias de la sociedad del momento.

En la actualidad, el anonimato es una característica que muchas personas buscan en su vida digital, por una razón: la privacidad. El mundo digital actual permite a las instituciones acceder a grandes cantidades de información sobre nuestra vida y actividades, hasta el punto de que saben más de nosotros que nosotros mismos. Frente a esa realidad distópica, el anonimato y el pseudoanonimato se erigen como una de las mejores herramientas para contrarrestar a las empresas que buscan monetizar nuestros datos a su favor. Básicamente, buscamos usar estos dos conceptos y herramientas para contrarrestar que las empresas nos transformen en meros productos y fuentes de información para su beneficio.

En el mundo digital existen una gran cantidad de herramientas para ayudarnos a mantener nuestra privacidad, utilizando para ello el anonimato o el pseudoanonimato. Herramientas que, en su mayoría, fueron creadas durante la primera y segunda CryptoWorld, entre 1990 y 2010. Por ejemplo, los remailers fueron una de las herramientas más usadas para mantener el anonimato de los usuarios de correo electrónico, con el fin de proteger su identidad, y de hecho, su efectividad es tal que aún hoy se siguen usando ampliamente. Después de todo, los remailers se encargan de llevar tu correo por distintos servidores de correo con el fin de reescribir la metadata de los mismos hasta llegar a su destino, sin pizca alguna de datos personales digitales en ellos.

Otros buenos ejemplos de anonimato se pueden ver en los Proxys Chain, en SSH Tunneling, en el SOCKS5 Tunneling, en la ofuscación IP, en las VPN... Todo esto para hacer que tu conexión web no pueda ser directamente rastreada hacia tu dirección IP real, permitiéndote usar pseudónimos en redes como IRC o Usenet de forma segura. Junto a esto, la creación de herramientas como Tor o I2P habilita nuevas formas de privacidad y anonimato online que pueden garantizar cierto nivel de seguridad, especialmente si usamos dichas herramientas de forma correcta. Sin embargo, con la mayor masificación de Internet, la llegada a la web 2.0 y ahora la 3.0, es necesario dar un paso más allá y transformar estas herramientas en un estándar para proteger nuestra privacidad.

¿Qué derecho tiene una empresa como Microsoft de rastrear, analizar, almacenar y vender la actividad que realizas con tu ordenador o sus servicios? Después de todo, estás pagando una suscripción por sus servicios o por usar su sistema operativo. Y, en definitiva, ese acceso que te dan no es gratuito en su mayoría, porque incluso en los servicios gratuitos la publicidad está siempre presente. Aquí usamos el nombre de Microsoft y pensarás que es la peor empresa en este sentido, pero empresas como Meta, Alphabet y Apple no se quedan atrás. Seguramente dirás que el software libre puede protegerte de ello, pero incluso en ese ambiente ya comienzan a verse prácticas parecidas. Por ejemplo, en Audacity, un conocido desarrollador de software libre, comenzó a ejercer este tipo de prácticas y, aunque se ha demostrado que son datos de uso anonimizados, otros proyectos pueden no tener un espíritu en esa línea.

Por curioso que te parezca, los gobiernos del mundo parecen no estar muy de acuerdo con que podamos mantener el anonimato o siquiera el pseudoanonimato en la web. Y hay muchos aspectos de nuestra vida. Después de todo, a ellos les mueve el control sobre la población y por ello podemos ver casos tan descabellados como escribir en una ley una cosa y hacer otra totalmente distinta. Por ejemplo, en la Unión Europea, el derecho al anonimato en Internet está contemplado en la legislación europea y reconoce el derecho fundamental a la protección de datos, la libertad de expresión y la libertad de impresión. La Carta de Derechos Fundamentales de la Unión Europea reconoce el derecho de todas las personas a la protección de datos personales que les concierne. El derecho a la intimidad es ahora esencialmente el derecho del individuo a tener y mantener el control sobre la información que le concierne. Sin embargo, los Estados miembros buscan mil y una formas para restringir este derecho, especialmente con el uso de criptomonedas, abogando por la aplicación de leyes o reglamentos que directamente contradicen la Carta de Derechos Fundamentales.

Dicho esto, el tema de la legalidad sobre el anonimato y el pseudoanonimato es un tema especialmente cambiante y que toda empresa e individuo debe tener presente cuando realiza actividades frecuentes en Internet.

### ¿Qué es el Masking?
El Masking, _Data Masking_ o _Masking de Datos_ es una técnica informática usada para “enmascarar” datos de tal forma que podamos proteger la información sensible que maneja una aplicación en ambientes de producción.

Generalmente, esta técnica busca sustituir los datos con versiones compuestas de los mismos por diferentes medios. Estos incluyen el _hashing_ o diferentes procesos informáticos que permitan transformar dicha data en una que directamente no de acceso a los datos que desean ser protegidos. Esto resulta de enorme utilidad para distintas actividades, como el desarrollo de software, realización de pruebas o, por ejemplo, la minería de datos.

#### Objetivo del Masking
El Masking de datos es útil en varios escenarios de seguridad. Estas son algunas de las principales razones por las que las empresas utilizan el data Masking:
1. **Para proteger los datos de proveedores externos:** El intercambio de algunos datos con vendedores externos, consultores y otros es normal, pero cierta información debe mantenerse confidencial.
2. **Error del operador:** las empresas confían en sus expertos para tomar una buena decisión, pero las violaciones de datos a menudo son el resultado de un error del operador y las empresas pueden salvaguardarse con el Masking de datos.
3. **No todas las operaciones requieren el uso de datos totalmente reales y precisos:** hay muchas funciones dentro de un departamento de TI que no necesitan datos reales, por ejemplo, algunas pruebas y uso de aplicaciones.
4. **Definir el data Masking significa comprender el importante papel que desempeña en la estrategia general de seguridad de datos de la empresa.**
5. **El objetivo principal del Masking de datos es proteger datos complejos y privados** en condiciones en las que los datos pueden ser notorios para alguien sin su permiso.

#### Tipos de Masking
Básicamente existen tres tipos de Masking que son:

##### ==Estático==
Este se refiere a un proceso en el que los datos importantes se enmascaran en el entorno de la base de datos original.

El contenido se duplica para crear un entorno de más amplio acceso y luego se puede compartir con proveedores externos u otras partes necesarias. Los datos se enmascaran y extraen en la base de datos principal (debidamente protegida y donde se encuentran los datos reales) y se trasladan a la base de datos de servicio (donde están enmascarados).

Si bien el data Masking estático puede ser un proceso necesario para trabajar con consultores externos, su aplicación no es ideal. Esto se debe a que, durante todo el proceso de Masking de datos para una base de datos duplicada, se extraen datos reales que pueden dejar una puerta trasera abierta que fomenta las violaciones. 

##### ==Dinámico==
En este caso, el proceso de Masking permite a los departamentos de TI proteger los datos en tiempo real.

Eso significa que nunca abandona la base de datos principal, sino que, en caso de requerirse una información, el sistema enmascará los datos según el usuario y el nivel de acceso que ha solicitado la información. Además, verifica en todo momento este proceso y reduce la superficie de ataque del sistema. 

Para ello, una herramienta de Masking dinámico encuentra y enmascara ciertos tipos de datos confidenciales utilizando un proxy inverso, un recurso de software que se encarga de revisar toda la información de forma totalmente transparente y que permite al sistema enmascarar los datos según se requiera. Así, solo los usuarios autorizados podrán ver los datos auténticos. 

##### ==Sobre la marcha==
Al igual que el Masking dinámico de datos, el Masking de datos sobre la marcha ocurre bajo demanda.

En este tipo de Masking de datos, se produce un proceso de extracción de carga de transformación donde los datos se enmascaran en la memoria de una aplicación de base de datos determinada. Esto es particularmente útil para compañías ágiles enfocadas en la entrega continua.

En general, la selección de una estrategia de Masking de datos debe tener en cuenta el tamaño de la organización, así como la ubicación y la complejidad de los datos que desea proteger.

#### Técnicas de Masking de datos
Existen diferentes técnicas de Masking de datos entre las que podemos mencionar:
1. **Key Masking:** Devuelve los datos enmascarados con resultados deterministas para los mismos datos de origen. El Masking será siempre el mismo para cada valor de entrada.
2. **Random Masking:** Una columna configurada para el random Masking producirá resultados aleatorios, previa configuración de un diccionario que contiene los valores de sustitución de los datos de origen. Su uso requiere de una tabla relacional que contenga los datos de sustitución, así como un número de serie para cada fila de la tabla.
3. **Expression Masking:** Se aplica una expresión a un puerto para cambiar o crear datos. Al configurar el Masking expresion, puedes crear una expresión en el editor. Puedes seleccionar los puertos de entrada y salida, funciones, variables y operadores para construir expresiones.
4. **Sustitución:** Con esta regla de Masking se reemplaza una columna de datos con datos similares, pero no relacionados que hemos definido con anterioridad en un diccionario.
5. **Formatos especiales:** Los formatos especiales son útiles para enmascarar datos identificativos, como el número de la seguridad social, números de tarjetas de crédito, números de teléfono, URLs, direcciones de IP o de correo electrónico, entre otros. Al aplicarlos cambiamos esos datos por valores realistas en el mismo formato, pero no son válidos.
6. **Masking gráfico:** Técnicas usadas para ocultar la identidad de una persona en fotos y demás elementos visuales, en plataformas que hacen uso de este tipo de recursos (por ejemplo, plataformas de KYC).
7. **Masking de documentos:** Técnicas usadas para ocultar información sensible de documentos y demás elementos electrónicos dentro de una plataforma.

#### Masking de datos y su importancia
El Masking de datos proporciona herramientas fundamentales para que las organizaciones puedan afrontar los retos de seguridad que plantea la gestión de los datos sensibles (confidenciales o privados) de la mejor manera.

El Masking de datos evita que los datos circulen con ligereza en entornos no productivos y, como tantas veces ocurre, acaben filtrándose o sean susceptibles de usos indebidos o robos.

Su eficacia se revela como una solución necesaria para poder trabajar sin problemas con datos, exportarlos y protegerlos frente a amenazas internas y externas.  Si, por un lado, las políticas de data Masking buscan crear conjuntos de datos operativos para entornos no productivos y hacerlo logrando una información consistente, por otra parte, su objetivo es hacerlo de un modo seguro, cumpliendo tanto con la obligación moral de preservarla como con la normativa de privacidad de datos y demás legalidad vigente relacionada con la organización. Y esto es algo aún más prioritario para las empresas desde la entrada en vigencia del RGPD.

No en vano, la privacidad de los datos y su seguridad es uno de los pilares fundamentales que deben cumplirse para ajustarse a estándares que garanticen la seguridad en entornos TI y, desde un enfoque general, también para afrontar retos de los que, en última instancia, incluso depende la supervivencia de la organización.

#### Masking como elemento clave para la seguridad
Adicionalmente, la importancia de las herramientas de Masking de datos se ve resaltada por su estrecha relación con la seguridad, en la que se deben tener en cuenta los siguientes elementos:
1. **Evitar el incumplimiento de la normativa:** las soluciones de Masking de datos contribuyen a garantizar el cumplimiento de las leyes reguladoras sobre la protección de datos de clientes, proveedores o, por ejemplo, de los mismos empleados de la organización. Su función evita a la empresa elevadas multas en caso de posibles inspecciones. En este apartado, la seguridad también está vinculada a la obligación moral de toda organización de proteger los datos privados, en particular, y los datos sensibles en general.
2. **Evitar el riesgo de fuga:** el Masking de datos bloquea la exposición de datos sensibles de producción a usuarios no autorizados, reduciendo el riesgo de filtraciones de datos críticos. Estos últimos son bastante más frecuentes que los robos o ataques cibernéticos.
3. **En otro orden, cabe destacar que la nube constituye una gran oportunidad para reducir costes en infraestructura,** pero al mismo tiempo, entraña nuevos riesgos de seguridad para los datos.

Se trata, en suma, de aplicar políticas de seguridad de datos que garanticen que los datos que residen en la organización se encuentran debidamente protegidos. En este aspecto, el data Masking debería formar parte de la rutina de trabajo de todas las organizaciones que manejan datos sensibles. Es un concepto variable en cuanto a su confidencialidad, pero que, sin embargo, a nivel legal tiene las pautas muy definidas cuando se trata de información de tipo personal.

#### Reducción de costes operativos con Masking
El data Masking también ayuda a ahorrar costes en muy distintas situaciones: como la pérdida de datos, fugas o filtraciones, robos o, por ejemplo, la imposibilidad de llevar a cabo proyectos que impliquen un nivel de seguridad que no tengamos y que exija la implementación de herramientas de data masking.

En este sentido, podríamos dejar de ganar un dinero o tener pérdidas precisamente por el mismo motivo, sin olvidar las importantes sanciones económicas que puede conllevar incumplir la normativa.

En general, la eficiencia que se logra con una adecuada gestión de los datos en terrenos clave ( como su calidad y seguridad ) nos ayuda a conseguir una reducción de costes gracias a la eficiencia en la gestión y en los mismos procesos operativos. 

En cuanto a la implementación, las herramientas de data Masking escalables de alto rendimiento también hacen una gran diferencia en el ahorro de costes a largo plazo, en especial cuando se implementan de forma progresiva.

En el caso de la exportación de datos a la nube, por último, el ahorro de costes se traduciría en el importante ahorro que conlleva alojar datos de forma virtual. Recordemos aquí que la normativa de protección de datos exige enmascarar la información.

#### Legislación sobre el Masking
Con la introducción de estándares de privacidad internacionales cada vez más estrictos, las organizaciones tienen una mayor responsabilidad de proteger los datos personales de sujetos que incluyen clientes, empleados y prospectos.

**Por ejemplo, en la Unión Europea, las multas por el incumplimiento de la RGPD pueden ascender a los 20 millones de euros. Cumplir con esta legislación lleva a que las empresas deban solicitar expreso e inequívoco consentimiento para la utilización de los datos, especificar qué datos están utilizando, cómo los están tratando, para qué y quién es la persona responsable de los mismos.**

Por otro lado, aunque Estados Unidos y Japón están muchos pasos por detrás de Europa en cuanto a protección de datos, la primera ley de privacidad del consumidor (CCPA) entró en vigor en Estados Unidos en 2020 y la Ley de Protección de Datos Personales (APPI) de Japón ya ha adoptado una serie de enmiendas que planean entrar en vigor en 2022.

Es, por tanto, imprescindible ceñirse a las normas vigentes y, ante todo, jamás eludir las obligaciones impuestas por motivos tanto éticos como legales. Las malas prácticas podrán poner en entredicho la reputación de su negocio, y sumar demandas multimillonarias que pondrán en peligro la continuidad de su empresa.

### ¿Qué es la Ofuscación de datos?
La ofuscación de datos (DO) es una forma de enmascaramiento de datos, donde los mismos se representan de formas complejas con el fin de evitar su comprensión. 

De esta manera la ofuscación funciona como una forma de “cifrado” que busca hacer ininteligibles o confusos los datos que son tratados con esta técnica.

En informática, la ofuscación es conocida como una medida de seguridad por oscuridad, es decir, una medida de seguridad que busca ocultar algo sensible por medio de una técnica compleja, que puede ser rota con análisis de la fuente de esa información. 

#### Objetivo de la ofuscación de datos
La ofuscación de datos tiene varios objetivos, dependiendo del objetivo de uso de esta técnica, siendo que podemos mencionar los siguientes:
1. **Agregar seguridad.** Si queremos proteger datos sensibles incluso luego de un acceso no autorizado a los mismos, la ofuscación puede ayudarnos a eso.
2. **Dificultar la ingeniería inversa del software.** El código ofuscado suele ser más complejo de descompilar y por tanto es más complejo saber cómo funciona y generar funciones parecidas.
3. **Hace que las firmas estáticas utilizadas por los vendedores de antivirus no puedan detectar malware,** ya que las firmas se basan en secuencias de bytes específicas en el binario
4. **Protección de la propiedad intelectual.** Quizás no quieres que tu competencia copie cierto algoritmo que has utilizado.  

Un buen ejemplo de estos objetivos lo podemos ver en la ofuscación usada en el código. Con el fin de que si un atacante obtiene acceso al código fuente de un programa ( al estar ofuscado el código ) resulte extremadamente complejo para él entender y reconocer como funciona, consiguiendo proteger la propiedad intelectual de dicho código y aumentando su seguridad.  

#### Técnicas de Ofuscación
La ofuscación puede ser aplicada por varios métodos o técnicas entre las que tenemos: 
1. Ofuscación de datos
2. Ofuscación del diseño
3. Ofuscación del flujo de control
4. Ofuscación con virtualización de código

##### 1 | Técnicas de ofuscación de datos
La ofuscación de datos busca aplicar esta técnica en las variables, constantes, funciones y estructuras que forman parte de un programa. Entre esas técnicas podemos mencionar:
1. **Constant blinding.** Una técnica que busca sustituir los valores de las constantes por medio de funciones de manipulación de bits dentro de funciones las funciones que usan dichas constantes o bien por medio de funciones XOR apuntando a punteros con valores aleatorios. La idea es que la constante no sea usada directamente y su valor se ajuste a la necesidad real de la función en el momento en el que sea llamada.
2. **Cambio de tipo de variables.** Cambiando la codificación de las variables se busca ocultar el valor original de la variable, por ejemplo, podemos cambiar la codificación de un string por su valor equivalente en otra codificación (por ejemplo, codificación a Base64).
3. **Conversión de datos estáticos en procesos.** Consiste en convertir un dato en un proceso que generará ese mismo dato.
4. **Cambio del tiempo de vida de variables.** Esta técnica consiste en convertir variables globales en variables locales, pudiendo ser (incluso) manipuladas dentro de esa función o funciones externas.
5. **Merging variables.** Esta técnica consiste en agrupar variables en estructuras más complejas, con el fin no solo de cambiar su estructura sino de alterar su tratamiento dentro de las funciones que manejan dichas variables. Por ejemplo, juntando enteros individuales en una struct y accediendo a esos valores por medio de una función externa por medio de un puntero.
6. **Splitting variable.** En este caso, las variables de una función pueden dividirse en dos o más variables que son usadas de distintas maneras incluyendo funciones de manejo de bit o haciendo merging variable.
7. **Agregación de arrays.** Consiste en agrupar varios arrays en uno solo.
8. **Separación de arrays.** Consiste en dividir arrays y representar un único array mediante varios de ellos.
9. **Aplanamiento de arrays.** Consiste en utilizar una variable de array de menor dimensión para representar un array de mayor dimensión.
10. **Despliegue de arrays.** Consiste en utilizar una variable de array de mayor dimensión para representar un array de menor dimensión.

Muchas de estas funciones son bastante complejas de aplicar, algunas generan errores de compilación (por violar reglas de seguridad de los compiladores) o agregan complejidad adicional al código generado que hace más compleja su depuración. De allí que deba usarse de forma limitada y en secciones de código que se consideren críticas para mantener la seguridad de un sistema bajo un estricto desarrollo y revisión de código. 

##### 2 | Ofuscación del diseño
1. **Class merging.** Esta técnica consiste en la unión de una o más clases del programa en una sola clase.
2. **Class splitting.** Esta técnica consiste en dividir una clase de un determinado programa en varias clases.
3. **Type hiding.** Consiste en utilizar los interfaces para oscurecer la intención final del diseño del programa

##### 3 |Ofuscación de flujo de control
Consisten en una serie de transformaciones que alteran el flujo de ejecución de un programa. 

**El flujo de ejecución de un programa se puede representar por un grafo de control de flujo (CFG), en el que los nodos son los bloques básicos de ejecución del programa, y las aristas son los saltos entre bloques básicos de ejecución (conjuntos de instrucciones que se ejecutan secuencialmente, en los que la primera instrucción es el único acceso al bloque y la última instrucción es la única de salida).**

Esta es una de las técnicas más complejas de ofuscación hasta el punto que los _malware_ y _ransomware_ avanzados hacen uso de la misma para evitar las técnicas de heurística y análisis de software de herramientas avanzadas de seguridad y antivirus que existen en la actualidad. El nivel de este tipo de técnicas es tal que su uso correcto requiere de un amplio conocimiento de las características CFG de los kernels, compiladores y librerías de sus objetivos, con el fin de usar dichas características y debilidades a su favor de modo que puedan permanecer ocultos en todo momento. 

Dos de los métodos más usados en este punto son el _null code_, una técnica en la que se agrega código al programa (que al final no hace nada pero que está allí) para disfrazar funciones vitales, evitando ciertas técnicas de análisis. 

Y la segunda es el _CFG Flattening_, que consiste en modificar y reordenar los bloques básicos de un programa (basic block, BB). Esto busca crear una estructura que se altera a sí misma en cada ejecución e iteración del código, en una forma de polimorfismo avanzado. Resultado: las herramientas de análisis tienen graves problemas en detectar la estructura de funcionamiento real del programa, requiriendo de una descompilación y una serie de análisis para detectar el patrón flattening usado.  

##### 4 | Ofuscación con virtualización de código
Desde la creación de las máquinas virtuales (como las que vemos en Java), la virtualización de código como método para la ofuscación era una viabilidad. _Obfuscation VM-based_, como se le conoce en inglés, es otro método avanzado de ofuscación.

**La técnica consiste en reemplazar instrucciones del programa con instrucciones virtuales con las que el atacante no está familiarizado. Posteriormente estas instrucciones serán traducidas a código de la máquina nativa en tiempo de ejecución para ser ejecutada por el hardware.** 

En un principio este tipo de tácticas podían ser fácilmente detectadas debido a la enorme cantidad de recursos que pueden requerir para su funcionamiento, pero con la llegada de hardware con funciones de virtualización incluidas (por ejemplo, en las CPU Intel y AMD), estas técnicas se han hecho cada vez más comunes en el malware y el software de uso común. 

Por ejemplo, en Windows 10, Microsoft habilitó dos funciones de seguridad avanzadas construidas con virtualización de código: VBS (Virtualization-Based Security) y HVCI (Hypervisor-Protected Code Integrity). Estas características junto con el uso de TPM, permiten que la seguridad del sistema operativa se vea fuertemente mejorada con respecto a versiones anteriores, hasta el punto de aislar de forma correcta kernels parcialmente comprometidos (sin llegar al anillo seguro bajo VBS-HVCI).  La medida de seguridad busca ser implementada en el kernel Linux para incrementar las capacidades de las funciones de seguridad del kernel (como lockdown). 

En el mundo de criptomonedas, este tipo de técnicas también son usadas, siendo el uso más conocido el que Monero le da dentro de su algoritmo RandomX, el cual ejecuta una máquina virtual sobre el computador para realizar la minería sobre esa máquina virtual la cual tiene todo su espacio de ejecución cifrado con un algoritmo AES-256. 

#### Necesidad de técnicas de ofuscación de datos
Las organizaciones a menudo necesitan copiar datos de producción almacenados en bases de datos de producción hacia bases de datos de no producción o prueba.

Esto se realiza para completar de manera realista la prueba de funcionalidad de la aplicación, y cubrir escenarios en tiempo real o casos de prueba, para minimizar los errores o defectos de producción.

**Como resultado de esta práctica, un entorno de no producción puede convertirse en un blanco fácil para los ciberdelincuentes o empleados malintencionados que buscan datos sensibles que pueden ser expuestos o robados.** Debido a que un entorno de no producción no está tan estrechamente controlado o administrado como el entorno de producción, podría costar millones de dólares para que las organizaciones remedien el daño a la reputación o al valor de la marca, en caso de que ocurra un incidente de brecha de datos.

Los requisitos reglamentarios son otro factor clave para la ofuscación de datos. Por ejemplo, el estándar de seguridad de datos de la industria de tarjetas de pago (PCI DSS) alienta a los comerciantes a mejorar la seguridad de los datos de las tarjetas de pago con la adopción amplia de medidas consistentes de seguridad de datos, que proporcionan una base de requisitos técnicos y operacionales. PCI DSS requiere que los datos e información de los comerciantes "no se utilicen para pruebas y desarrollo". La exposición inadecuada de los datos, ya sea por accidente o un incidente malicioso, podría tener consecuencias devastadoras y podría conducir a excesivas multas o acciones legales impuestas por la violación de las reglas.

### Anonimato y Pseudo-anonimato
El anonimato es el carácter o la condición de anónimo, es decir, el hecho de mantener la identidad de una persona o entidad completamente desconocida para el público. 

Esto puede ser simplemente porque no se le haya pedido su identidad (como en un encuentro ocasional entre extraños) o porque la persona no puede o no quiere revelar su identidad por motivos de seguridad, o simplemente porque no es su deseo hacerlo. 

El anonimato ha sido una práctica que ha estado en la historia humana desde la antigüedad, especialmente en momentos históricos donde la vida de esa persona estuviera en especial riesgo bien sea porque sus acciones eran un peligro para el poder establecido o simplemente porque contravinieran las creencias de la sociedad del momento. 

> En la actualidad, el anonimato es unas características que muchas personas buscan en el mundo digital por una razón: Privacidad. 

El mundo digital actual permite a las instituciones acceder a grandes cantidades de información sobre nuestra vida y actividad, hasta un punto que “saben más de nosotros, que nosotros mismos” y frente a esa realidad distópica: el anonimato y el pseudo-anonimato se erigen como las mejores herramientas para contrarrestar a las empresas ávidas por nuestros datos para monetizarlos a su favor. Básicamente, buscamos usar estos dos conceptos y herramientas para contrarrestar que las empresas nos transformen en meros productos y fuentes de información para su beneficio. 

#### Anonimato y pseudo-anonimato en un mundo digital
En el mundo digital actual existen gran cantidad de herramientas para ayudarnos a mantener nuestra privacidad, usando para ello el anonimato o el pseudoanonimato. Herramientas que en su mayoría fueron creadas durante la Primera y Segunda _CryptoWar_ (en los años 90 y 2010, para ser precisos).

Por ejemplo, los _remailers_ fueron una de las herramientas más usadas para mantener el anonimato de los usuarios de correo electrónico, con el fin de proteger su identidad y, de hecho, su efectividad es tal que aún en día se siguen usando ampliamente.

Después de todo, los _remailers_ se encargan de llevar tu correo por distintos servidores de correos con el fin de reescribir la metadata de los mismos hasta llegar a su destino, sin pizca alguna de tus datos personales digitales en ellos. 

Otros buenos ejemplos de anonimato se pueden ver en los _proxies chains_, _SSH tunneling_, SOCKS5 _tunneling_, ofuscación IP y los VPNs usados para hacer que tu conexión web no pudiera ser directamente rastreada hacia tu dirección IP real, permitiéndote usar seudónimos en redes como IRC o Usenet de forma segura.  Junto a esto, la creación de herramientas como Tor o I2P, habilita nuevas formas de privacidad y anonimato online que pueden garantizar cierto nivel de seguridad, especialmente si usamos dichas herramientas de forma correcta. 

> ¿Qué derecho tiene una empresa como Microsoft de rastrear, analizar, almacenar y vender la actividad que realizas con tu computadora o sus servicios?

Sin embargo, con la mayor masificación de Internet, la llegada de la Web 2.0 y ahora de la Web 3.0, es necesario dar un paso más allá y transformar estas herramientas en un estándar, para proteger nuestra privacidad. 

Piénsalo un momento, ¿Qué derecho tiene una empresa como Microsoft de rastrear, analizar, almacenar y vender la actividad que realizas con tu computadora o sus servicios?. **Después de todo estás pagando una suscripción por sus servicios, por usar su sistema operativo y en definitiva ese acceso que te dan NO ES GRATUITO en su mayoría, porque incluso en los servicios gratuitos la publicidad siempre dice presente.** Aquí usamos el nombre Microsoft y pensarás que es la peor empresa en ese sentido, pero empresas como Meta, Alphabet (Google) y Apple no se queda atrás (estos últimos, muchas veces vistos como “paladines” de la privacidad). 

Seguramente dirás que el Software Libre puede protegerte de ello, pero incluso en ese ambiente ya comienzan a verse prácticas parecidas, por ejemplo, Audacity un conocido desarrollo de software libre comenzó a ejercer este tipo de prácticas y, aunque se ha demostrado que son datos de uso anonimizados, otros proyectos pueden no tener el mismo espíritu. 

#### Legalidad sobre el anonimato y el pseudo-anonimato
Por curioso que parezca, los gobiernos del mundo parecen no estar muy de acuerdo con que podamos mantener anonimato o siquiera pseudo-anonimato en la Web, y en muchos aspectos de nuestra vida.

**Después de todo, a ellos les mueve el control sobre la población y por ello podemos ver casos tan descabellados como escribir en la Ley una cosa, y hacer otra totalmente distinta.**

Por ejemplo, en la Unión Europea, el derecho al anonimato en Internet está contemplado en la legislación europea que reconoce el derecho fundamental a la protección de datos, la libertad de expresión y la libertad de impresión. 

La Carta de Derechos Fundamentales de la Unión Europea reconoce en su artículo 8 (Título II: "Libertades") el derecho de toda persona a la protección de los datos personales que le conciernen. El derecho a la intimidad es ahora esencialmente el derecho del individuo a tener y mantener el control sobre la información que le concierne. Sin embargo, los estados miembros buscan mil y una formas para restringir este derecho, especialmente con el uso de criptomonedas, abogando por la aplicación de leyes o reglamentos que directamente contradicen la Carta de Derechos Fundamentales. 

> La misma situación se ve en los Estados Unidos, donde la Primera Enmienda, da el derecho a sus ciudadanos a ejercer la libertad de expresión y respeta la figura del anonimato, pero al mismo tiempo crea leyes que van en contra de dicha enmienda, junto con su profundo significado legal y social.

Dicho esto, el tema de la legalidad sobre el anonimato y pseudo-anonimato es un tema especialmente cambiante, y que toda empresa e individuo debe tener presente cuando realiza actividades frecuentes en Internet.

### Casos de fallos de seguridad
La ciberseguridad ha sido desde sus inicios un verdadero campo de batalla entre quienes trabajan para asegurar los sistemas informáticos y aquellos que desean romperlos.

Es un área tan dinámica que ambos bandos trabajan día y noche para desarrollar herramientas de alto nivel para lograr sus objetivos. 

Sin embargo, pese al enorme trabajo detrás los fallos de seguridad, siempre están allí. Y por tanto la explotación de los mismos es posible, dejando la puerta abierta para romper la seguridad y robar datos de los distintos sistemas informáticos.

**Algunos casos de esos fallos de seguridad más recientes y ampliamente conocidos podemos mencionar:**

#### SolarWinds
El hackeo a SolarWinds es uno de los hackeos más graves que se han visto en la industria, hasta el nivel que su ex CEO, Kevin Thompson, tuvo que declarar en una audiencia conjunta de los comités de Supervisión de la Cámara de Representantes y Seguridad Nacional de Estados Unidos. 

El Comité buscaba investigar este desastre en ciberseguridad informática sucedido en su compañía, descubrir cómo su seguridad fue comprometida por primera vez y como es que no fueron capaces de descubrir el código malicioso oculto. Este código malicioso persistió en actualizaciones de software que la compañía envió a sus 18.000 clientes en una lista que daba idea de la dimensión del caso, ya que incluía agencias federales, las cinco ramas del ejército de Estados Unidos, el Departamento de Estado, la NSA, la Oficina del Presidente de Estados Unidos y los 10 principales proveedores de telecomunicaciones del país.

El hackeo de SolarWinds es considerado en el mundo de la ciberseguridad como un “hackeo de ciberguerra estatal”, ya que para su desarrollo como mínimo se necesitó del trabajo de al menos 1000 hackers para programar toda la infraestructura del malware y así mismo, su CDC (Centro de Control) es tan avanzado que solo un Estado podría mantener tal estructura. 

Detrás del ataque estaría el grupo ruso Nobelium (conocido como [APT29 en el MITRE](https://attack.mitre.org/groups/G0016/)), y ha estado detrás del desarrollo de ataques a distintas empresas y estados. 

#### Log4j
Apache Software Foundation publicó soluciones para contener una vulnerabilidad de día cero explotada activamente que afectaba a Apache Log4j. 

Basada en Java, es una biblioteca de registro ampliamente utilizada que podría utilizarse como arma para ejecutar código malicioso y permitir una toma de control completa de los sistemas vulnerables.

Etiquetada como CVE-2021-44228, conocida por apodos como “Log4Shell” o “LogJam” y descubierta por el equipo de seguridad de Alibaba, el problema se refiere a un caso de ejecución remota de código no autenticado (RCE) en cualquier aplicación que use esta utilidad de código abierto y afecte a las versiones no parcheadas, de Apache Log4j 2.0-beta9 hasta la 2.14. 1. El error fue calificado con la puntuación máxima de 10 sobre 10 en el sistema de clasificación CVSS, lo que indica la enorme gravedad del problema.

La explotación se puede lograr mediante una sola cadena de texto, que puede provocar que una aplicación se comunique con un host externo malicioso si se registra a través de la instancia vulnerable de Log4j, lo que le otorga al atacante la capacidad de recuperar una carga útil de un servidor remoto y ejecutarlo localmente.

La vulnerabilidad de día cero de Apache Log4j es probablemente la vulnerabilidad más crítica que hemos visto este año. Log4j es una biblioteca ubicua utilizada por millones de aplicaciones Java para registrar mensajes de error. Es una vulnerabilidad trivial de explotar y en extremo peligrosa por su alcance. 

Y es que Log4j se utiliza como un paquete de registro en una variedad de software popular de múltiples fabricantes, incluidos Amazon, Apple iCloud, Cisco, Cloudflare, ElasticSearch, Red Hat, Steam, Tesla, Twitter o incluso videojuegos como Minecraft. En este caso, los atacantes han podido ejecutar código malicioso remotamente simplemente pegando un mensaje especialmente diseñado en el cuadro de chat.

Desde la Fundación Apache se recomienda actualizar sistemas a la mayor brevedad con la nueva versión 2.15.0, que soluciona el fallo deshabilitando la capacidad de un atacante que, en versiones anteriores, podía controlar los mensajes de registro o parámetros del log. Así, ejecutaba código arbitrario cargado desde servidores LDAP cuando se habilitaba la sustitución del mensaje de búsqueda. Este comportamiento es el que se ha desactivado de manera predeterminado.

#### PrintNightmare
Varias vulnerabilidades se sumaron a la conocida de 2020 del servicio de impresión de Windows. La primera, una vulnerabilidad crítica localizada en la cola de impresión. 

- A principios de junio, Microsoft publicó el CVE-2021-1675 titulado “_Windows Print Spooler Remote Code Execution Vulnerability_”. Es decir, Vulnerabilidad de ejecución remota de código en el administrador de impresión de Windows. Nada hizo pensar, en su momento, que su trascendencia fuera a escalar posteriormente.
- Ya en julio, las principales agencias de seguridad del mundo empezaron a emitir comunicados en los que alertaban sobre una actualización importante de CVE-2021-1675. Mensajes que urgían a usuarios y organizaciones públicas y privadas a adoptar, de inmediato, medidas para protegerse de esta amenaza. En ese mismo espacio temporal, Microsoft publicaba la vulnerabilidad CVE-2021-34527, que es a la que le corresponde el sobrenombre de _PrintNightmare_.
- Y es que _PrintNightmare_ se ganó, desde un primer momento, la calificación de vulnerabilidad crítica, pues permite la ejecución de código de manera remota. Desde ese momento se han producido varias actualizaciones, y Microsoft no ha dejado de trabajar en este problema grave, ya que cualquier instalación de Windows es susceptible de ser atacada.
- ¿Qué hace que _PrintNightmare_ sea tan peligroso? Seguro que ya lo has deducido: cuando hablo de instalar una impresora me refiero a su controlador, que un administrador puede instalar aunque no esté firmado y que, como ya puedes imaginar, puede contener cualquier función maliciosa. De este modo, un atacante que logra acceso a un sistema y emplea _RpAddPrinterDriverEx()_ para ejecutar código malicioso puede escalar privilegios, enviar cargas útiles al sistema comprometido e incluso tomar el control completo del mismo.
- Solo un mes después, llegó otra vulnerabilidad CVE-2021-36958, está relacionada con cómo se gestionan los archivos que cuentan con privilegios del sistema. Y es que, de nuevo, la falta de medidas de seguridad a la hora de ejecutar binarios supuestamente confiables en algún proceso relacionado con el sistema de impresión, es decir, lo que viene definiendo a _PrintNightmare_ desde sus inicios, se puede traducir en la ejecución de código arbitrario que comprometería la seguridad del sistema afectado.

#### Blockchain y DeFi Hacks
El mundo de la tecnología Blockchain también ha tenido sus episodios de fallos de seguridad. 

**Los hackeos a Mt.Gox, Cryptopia y Binance, dejo claro que los exchanges son los principales objetivos de los hackers debido a su centralización y a que en su complejidad, pueden cometerse errores que lleven a abrir la puerta a dichos ataques, con penosas consecuencias (como las perdidas totales en Mt.Gox y Cryptopia) o perdidas parciales (en el caso de Binance).** 

Sin embargo, incluso los protocolos descentralizados y las mismas Blockchain también tienen fallos. Por ejemplo, Bitcoin ha sufrido de 35 episodios de este tipo en toda su historia. Uno de esos fallos está relacionado con fallos de lógica en su Bitcoin Script, el cual llevó a la deshabilitación de varias funciones OP_CODES de este lenguaje. Otra situación llevó a la generación de 85 millones de BTC en una sola transacción manipulada (cuando en Bitcoin solo está permitida la existencia de 21 millones, bajo un esquema bien definido). 

Si bien 35 vulnerabilidades pueden parecer un número muy alto, la realidad es que, para tener más de 13 años de desarrollo, Bitcoin tiene un historial de seguridad envidiable. No solo porque de esas vulnerabilidades pocas eran de importancia (solo 8 están por sobre un score de 5.0 en CVE). Y, de hecho, la mayoría de esos fallos fueron arreglados en su mayoría, al día siguiente de ser descubiertos, lo que cerraba la puerta para su explotación continua. Esta realidad se ha visto también en otros proyectos, donde los fallos son rápidamente corregidos. 

Sin embargo, con la llegada de los _Smart Contracts_ de Ethereum las cosas han cambiado mucho. Los Smart Contracts de Ethereum son muy potentes, pero su naturaleza Turing Completa abre las puertas a vectores de ataques que muchas veces no se analizan y ni siquiera se imaginan, lo que lleva a que se cometan errores no solo al construir la EVM, sino también al programar los Smart Contracts en sí mismo. Hackeos como The DAO, Cashio, Wormhole, BadgerDAO, UniswapV3, entre otros nos recuerdan que, si bien los Smart Contracts habilitan un mundo descentralizado, son también una daga de doble filo que puede causar daño si no se tiene cuidado con la seguridad de su desarrollo. 

Si te interesa mantenerte al día sobre los fallos de seguridad en DeFi quizás te interesa mantener entre tus favoritos esta web ([Rekt en Español](https://rekt.news/es)) donde se habla y explica de forma completa los distintos hacks que tienen y han tenido lugar en la comunidad DeFi.

## U5. Wallets & Nodos
### Wallets / Nodos (Video)
![[400.B7_Wallets-Nodos.mp4]]
[WalletsNodos](https://app.web3mba.io?wvideo=7le7t1cp6q)

Si eres usuario de criptomonedas, debes saber que, como bienes digitales, es fundamental mantener siempre una alta seguridad en dichos entornos, tanto en lo que usas en tu monedero como en tus nodos. En ningún momento debes dejar la seguridad por defecto, ya que, evidentemente, es la más débil de todas, por ser la seguridad a la que se puede acceder públicamente y la que se vulnera primero. Este punto de vista se aplica sin importar la plataforma en la que te encuentres, ya sea Windows, Linux o Mac. Nunca uses la seguridad por defecto.

Esto mismo aplica para tus monederos y nodos, los cuales debes conocer a fondo con el fin de identificar sus debilidades y fortalezas. Esto te permitirá fortalecer y mejorar la seguridad de los mismos, ajustándola a tus necesidades. Aunque pienses que es complejo, la realidad es que es bastante sencillo y gratificante, ya que podrás tener la certeza de que tus criptomonedas están mejor protegidas. Dicho esto, comenzaremos a revisar algunos puntos básicos para la securización de nuestros nodos y monederos de criptomonedas, que la mayor parte del tiempo dejamos pasar sin darnos cuenta de su alcance.

Instalar un nodo de criptomonedas generalmente no requiere permisos administrativos, por lo que prescindir de ellos es una buena manera de proteger tu sistema al limitar el acceso de un atacante en caso de que logre vulnerarlo. En su lugar, lo mejor es crear una cuenta en la que tengas instalado tu nodo y que solo pueda accederse a dicho nodo desde esa cuenta. Por ejemplo, si eres usuario de Linux o de Mac, no es necesario usar permisos de root para instalar el nodo de Bitcoin. Basta con descargar el software y ejecutarlo desde una cuenta de usuario normal, a la que incluso puedes negar el acceso a herramientas administrativas, como el sudo, con el fin de limitar aún más las capacidades de afectar al sistema a niveles más elevados.

Lo mismo ocurre en Windows, donde puedes crear una cuenta de usuario normal para ejecutar el software y evitar por todos los medios posibles usar la cuenta administrativa. Lo más recomendable es desactivar la cuenta de usuario administrativa por defecto, el admin. Crea una cuenta administrativa con otro usuario y una clave segura, y restringe el acceso a la misma desde otras cuentas, evitando así la posibilidad de escalar privilegios. En la imagen puedes ver cómo se está instalando un nodo de Bitcoin Core sin necesidad de ejecutarlo como usuario administrativo. Para hacer esto de forma exitosa, solo ten en cuenta crear una cuenta sin permisos administrativos, descargar el software del nodo y ejecutarlo donde haya espacio.

Esto es especialmente útil si usas dicho nodo como medio para almacenar tus criptomonedas y manejarlas de forma cotidiana con el software del nodo, el cual se ejecuta sin interrupciones en el computador que tú hayas dejado para tal fin. Por supuesto, lo anterior es la forma más sencilla de realizar este proceso, ya que hay un nivel mucho más avanzado que incluso te permite dejar ejecutando el nodo en segundo plano con su propio usuario y mantener el acceso al mismo sobre el sistema aislado. Esto es necesario si tienes servicios vitales que dependen del nodo y quieres aislar el acceso al mismo, e incluso sobre tu propio sistema de uso, si es para uso personal y mantienes ciertas medidas de seguridad.

Una de las medidas más básicas es mantener un buen firewall instalado en nuestros sistemas, con el fin de filtrar las conexiones que salen y entran de nuestro computador, desde y hacia Internet. Un firewall puede evitar que algún actor malicioso intente no solo rastrear tu sistema y reconocer los servicios que ejecutas, sino también determinar si son vulnerables, lo que inicia su trabajo para romper el sistema. La práctica totalidad de los sistemas operativos actuales tienen capacidad de generar muy buenos firewalls por defecto, pero sus configuraciones iniciales son deficientes o inexistentes. Por ejemplo, en Windows, la configuración básica permite la salida de información, pero no la entrada, a menos que esta esté permitida con las reglas del sistema, que son muchas.

Una configuración correcta pero deficiente, en especial porque muchas de esas entradas posiblemente jamás las usarás. En este caso, una buena idea sería cerrar todos esos accesos. Para ello, debes ir a la opción de Firewall de Windows y cerrar esos accesos que no usas. Esto es una tarea tediosa y complicada, pero con buenos resultados. En Linux, por otro lado, la mayoría de las distribuciones vienen sin un firewall configurado, pero se puede instalar. Por ejemplo, la siguiente captura está tomada de una instalación por defecto de Ubuntu 22. Claramente se ve que no hay ninguna regla activa en el firewall. De hecho, está todo en modo aceptar, lo que quiere decir que cualquier conexión que entre o que salga o requiera redirección por parte del sistema pasará sin problemas. Es un riesgo altísimo de seguridad.

Esto significa que si nuestro computador y nodo están conectados directamente a Internet, cualquiera puede rastrearlos. ¿Recuerdas nuestro nodo de Bitcoin instalado al principio? Si lo ejecutamos en esa máquina y usamos una segunda máquina con un analizador de vulnerabilidades, encontraremos cosas muy interesantes. Fácilmente podemos ver que el nodo de Bitcoin está siendo ejecutado, que el estado del puerto 8333 TCP está abierto y que efectivamente es un nodo de Bitcoin ejecutándose en la máquina. La creación de una regla en el firewall para evitar esto solucionaría el problema de seguridad y, a la vez, mantendría tu nodo funcionando sin problemas. Es decir, pasaría a ser transparente de cara a la red.

En la siguiente imagen puedes ver la regla para impedir el acceso de la máquina que ejecuta nuestro nodo. Y en la siguiente, el resultado del escaneo mostrando que ya no se puede acceder al nodo; ya es invisible. Por supuesto, puedes indicar al nodo de Bitcoin o de cualquier otra criptomoneda que use un puerto distinto para escuchar transacciones, especialmente si usas una infraestructura propia. En este caso, tus decisiones de securización deben adaptarse a tu uso del nodo. El software de los nodos tiene varias opciones de configuración que debes conocer con el fin de hacerlos más seguros.

Por ejemplo, los nodos de Bitcoin Core generalmente son usados para capturar todo el historial de la blockchain de Bitcoin y para conectarlos a la red sin ningún intermediario, más que el monedero que deseamos usar para tal fin. En este punto, el nodo se puede configurar de dos formas. Primero, como nodo con Wallet Active, el cual nos permite usar el nodo como punto de conexión de la red y también como medio para manejar las criptomonedas usando capacidades de monedero. Esta es la opción más común, pero también la más insegura, porque cualquiera con acceso al monedero tiene acceso al wallet. Y segundo, el nodo con wallet inactivo, el cual permite todo lo anterior, pero sin dejar la capacidad de manejar las criptomonedas, ya que el monedero y sus claves privadas permanecen en otro dispositivo distinto que está bajo nuestro control.

Otras opciones de seguridad que puedes activar en tus nodos son las claves de acceso al mismo. En Bitcoin Core puedes, por ejemplo, crear un acceso mediante clave para que solo proporcionando la misma puedas conectarte al nodo y al monedero del mismo en caso de que lo tengas activo. Si el nodo y los monederos que deseas asegurar pueden ser accedidos por varios métodos, por ejemplo, si son parte de un exchange, debes garantizar una estructura de escalado de privilegios para que ese acceso sea seguro. Por ejemplo, puedes crear una estructura de monederos de solo vista o visualización para obtener de ellos, por ejemplo, mediante un API, toda la información necesaria para mostrar saldos o generar direcciones para recibir criptomonedas desde la red.

Así puedes separar de forma efectiva los nodos de la red para seguir su evolución, recibir transacciones o mantener un seguimiento de las mismas, y los nodos de igual seguridad, aquellos que mantienen los saldos separados mediante mecanismos multifirma, que permiten realizar operaciones de retirada y movilización de saldos. En un exchange, esto es básico y algo que el software para este tipo de servicio tiene muy en cuenta. Incluso si eres un usuario de criptomonedas, puedes aplicar este tipo de estrategias. Por ejemplo, puedes generar un monedero MetaMask y usarlo con una Hardware Wallet. Así puedes usar el monedero MetaMask en modo vista, sin conectar la Hardware Wallet, y acceder a los protocolos donde tienes los saldos. Pero no podrías movilizar dichos saldos hasta que no conectes tu Hardware Wallet, que es la que tiene tu clave privada.

Otro punto a tener en cuenta es la actualización del sistema. No basta solo con mantener el sistema operativo actualizado. También debes mantener actualizado el software de los nodos y cualquier software que uses e interactúe con ellos, especialmente si dicha actualización es de seguridad o contiene alguna corrección de seguridad. Esto no solo requiere mantener un rastreo de seguridad de todo lo que instales en tu computador, sino también mantener un acceso claro a los registros y logs de cada uno de estos componentes. Uno de los puntos más importantes en un monedero es la generación de las claves del mismo. De ser posible, realizar este proceso en modo offline garantiza que el proceso se lleve a cabo con los recursos de tu ordenador o de tu teléfono móvil, brindando una capa de seguridad adicional.

Esto solo es válido para los monederos cuyos nodos deben estar siempre en línea, pero debido a que es posible separar los nodos de las claves de un monedero, mantener estos últimos offline ofrece una protección que pocos hackers realmente pueden atacar, especialmente si lo manejas de la forma correcta. Coinomi es un proyecto de software privativo que permite que los monederos que se encuentran en el mercado gocen de una buena política de seguridad desde sus inicios. Sin embargo, los errores se cometen y el equipo de desarrollo de Coinomi cometió un grave error. En 2019, un usuario indicó que había perdido cerca de 70,000 dólares por culpa de Coinomi, debido a que este monedero enviaba peticiones HTTP al servicio de Google de Spellcheck, con la seed phrase del monedero, algo que fue aprovechado para vulnerar su monedero y realizar el robo.

Este usuario incluso posteó un vídeo donde se demostraba esta realidad y con el cual exigía a Coinomi que le ingresaran su dinero. Todo ello sin darse cuenta de que el vídeo que había grabado sería su propia perdición. Usó un software llamado Fiddler, muy utilizado para interceptar tráfico web y desencriptar el mismo usando una opción de proxy HTTPS. El problema de esto es que para interceptar tráfico HTTPS con Fiddler es necesario instalar manualmente un certificado propio que se usa para crear un proxy transparente que manipule ese propio tráfico HTTPS, lo que recibe desencripta y cifra usando el nuevo certificado, el cual es válido para el sistema porque debe instalarse manualmente.

Como resultado, el usuario fue rápidamente expuesto como mentiroso por la comunidad de Twitter, algo que era cierto porque su propio vídeo lo dejó en evidencia, pero al mismo tiempo fue un dolor de cabeza para Coinomi, porque dejó en claro algo que jamás debía hacerse: usar un servicio, Spellcheck Online, para un monedero, ya que basta que Google comience a recopilar dicha información para obtener en sus manos una base de datos gigantes de frases semilla, válidas para este monedero. El error fue corregido posteriormente por Coinomi, quien explicó que se debía a un fallo de seguridad. Y CipherBlade realizó un análisis completo del fallo, incluyendo un análisis de rastreo de transacciones relacionadas con este evento.

Esto nos deja algunas lecciones. Primero, que los monederos con larga trayectoria en la comunidad son generalmente seguros, pero incluso en esos casos puede haber errores. No importa si es software libre o privativo, siempre habrá errores. Segundo, de ser posible, la mejor forma de guardar tu dinero, y en especial si son grandes sumas, es usando mecanismos de seguridad adicionales, como hemos hablado sobre el tema de la multifirma. De esta manera, evitas que un dispositivo vulnerado pueda simplemente arruinarte el día. Tercero, si tienes una empresa que desarrolla productos para criptomonedas, lo mejor es mantener el control del software que usas en dichos productos. Esta es una tarea compleja y requiere de grandes recursos, pero es la mejor solución de seguridad en este sentido.

El error de Coinomi en este caso fue hacer uso directo de las actualizaciones de código JxBrowser. El año 2019 fue un mal año para Electrum, debido a que se intensificaron los ataques a su red. De hecho, la red fue tan afectada que cerca del 70% de los nodos de la misma eran nodos vulnerados. Todo empezó a finales de diciembre de 2018 con el siguiente aviso en GitHub. El problema rápidamente escaló y, en dos campañas de ataque, los usuarios de Electrum perdieron más de 1,500 bitcoins. La razón fue un problema en la estructura de confianza entre los monederos de Electrum y los nodos de ElectrumX. El error ha sido corregido, pero los 1,500 bitcoins jamás se recuperarán.

En este caso, podemos aprender lo siguiente. Primero, si deseas ejecutar monederos con grandes cantidades de criptomonedas en ellos, lo mejor es confiar en el software descargado de fuentes oficiales y usar mecanismos de seguridad adicionales. Segundo, si creas un software para manejar criptomonedas, no generes interfaces que le permitan a un tercero personalizar mensajes desde el servidor. Respuestas genéricas, como el HTTP 404, que indica que lo solicitado no existe o no es accesible, son mejores para estos casos, dejando que los códigos estén hardcodeados dentro del software. Esto evita, hasta cierto punto, la manipulación de la red y sus nefastas consecuencias.

### Securización de nodos y monederos
Si eres usuario de criptomonedas debes saber que, como bienes digitales, debes tener siempre en cuenta la seguridad de los entornos digitales en los que utilizas tu monedero o nodos.

En ningún momento debes dejar la seguridad por defecto, ya que obviamente es la más débil de todas (por ser la seguridad públicamente accesible para todos y la primera en ser vulnerada).

Este punto de vista aplica sin importar la plataforma en la que te encuentres y, con el fin de dejarlo más claro, sin importar si usas Windows, GNU/Linux o MacOS, nunca uses la seguridad por defecto. 

Esto mismo aplica para tus monederos y nodos, los cuales debes conocer a fondo con el fin de conocer sus debilidades y fortalezas. Esto te permitirá fortalecer y mejorar la seguridad de los mismos ajustada a tus necesidades y, aunque pienses que es complejo, la realidad es que es bastante sencillo y gratificante hacerlo, ya que podrás tener la certeza de que tus criptomonedas están mejor protegidas. 

#### Puntos básicos para la securización de nodos y monederos
Dicho esto, comencemos a revisar algunos puntos básicos para la securización de nuestros nodos y monederos de criptomonedas, puntos tan básicos que la mayor parte del tiempo los dejamos pasar, sin darnos cuenta de su alcance. 

1. Asegura la cuenta y sus privilegios
2. Configura el firewall de tu sistema
3. Configura tu nodo para ser seguro
4. Crea estructuras de acceso bien definidas
5. Mantén tu sistema actualizado y con rastreo de seguridad
6. Mejor offline

##### 1 | Asegura la cuenta y sus privilegios
Instalar un nodo de criptomonedas generalmente no requiere de permisos administrativos, por lo que prescindir de ellos es una buena manera de proteger tu sistema y limitar el acceso de un atacante en caso de que logre vulnerar el mismo. En su lugar, lo mejor es crear una cuenta en la que tengas instalado tu nodo y sólo pueda accederse a dicho nodo desde esa cuenta.

Por ejemplo, si eres un usuario de GNU/Linux o MacOS, no es necesario usar permisos de root (administrador del sistema) para instalar un nodo de Bitcoin. Basta con descargar el software y ejecutarlo desde una cuenta de usuario normal, a la que incluso le puedes negar el acceso a herramientas administrativas (como sudo) con el fin de limitar aún más sus capacidades o afectar el sistema a niveles más elevados. 

Lo mismo pasa en Windows. Puedes crear una cuenta de usuario normal para ejecutar el software y evitar, por todos los medios, usar la cuenta administrativa. De hecho, lo más recomendable es desactivar la cuenta administrativa por defecto (conocida como Admin), crear una cuenta administrativa con otro usuario (creado por ti mismo) y una clave segura y restringir el acceso a la misma desde otras cuentas (evitando escalar privilegios). 

![[401.B7_instalacion.png]]
  _En la imagen arriba puedes ver cómo se está instalando un nodo de Bitcoin Core sin necesidad de ejecutar el mismo como usuario administrativo (el usuario no es root)._ 

Para hacer esto de forma exitosa solo ten en cuenta crear una cuenta sin permisos administrativos, descarga el software de nodo que deseas y ejecútalo desde ese espacio. Esto es especialmente útil si usas dicho nodo como medio para almacenar tus criptomonedas y manejarlas de forma continua con el software del nodo, el cual se ejecuta sin interrupciones en el computador que has dejado para tal fin. 

Por supuesto, lo anterior es la forma más sencilla de realizar este proceso. Hay un nivel mucho más avanzado que ,incluso, te permite dejar ejecutando el segundo plano el nodo (usando la opción bitcoind) con su propio usuario y mantener el acceso al mismo sobre un sistema aislado (algo necesario si tienes servicios vitales que dependen del nodo y quieres aislar el acceso al mismo) e incluso sobre tu propio sistema de uso (si es para uso personal y mantener ciertas medidas de seguridad). 

##### 2 | Configura el firewall de tu sistema
Una de las medidas más básicas es mantener un buen muro de fuego instalado en nuestros sistemas con el fin de filtrar las conexiones que salen y entran en nuestro computador desde, y hacia, Internet.

Un firewall puede evitar que algún actor malicioso intente no solo rastrear tu sistema y reconocer que servicios ejecuta, sino también que versiones y sí son vulnerables, con lo que inicia su trabajo para romper el sistema. 

La práctica totalidad de los sistemas operativos actuales tienen capacidad de generar muy buenos firewalls por defecto, pero son deficientes o inexistentes. Por ejemplo: en Windows la configuración básica permite la salida de información, pero no la entrada a menos que esté permitida por las reglas del sistema (que son muchas). 

Una configuración correcta, pero deficiente; en especial porque muchas de esas entradas posiblemente jamás las usarás y en ese caso es una buena idea cerrar esos accesos, algo para lo que deberás ir a la opción de Firewall de Windows y cerrar esos accesos que no usas (una tarea tediosa, pero con buenos resultados). 

  ![[401.B7_firewall.png]]

**En GNU/Linux por otro lado, la mayoría de las distros vienen sin un muro de fuego configurado (pero si instalado, conocido como iptables).** 
Por ejemplo, la siguiente captura es tomada de una instalación por defecto de Ubuntu 22.04 LTS (la última versión de Ubuntu GNU/Linux).

  
![[401.B7_reglas.png]]

**Claramente, se ve que no hay reglas de filtrado en el muro de fuego y, de hecho, todo está en modo “ACEPTAR”. Esto quiere decir que cualquier conexión que entre, salga o requiera redirección por parte del sistema, pasará sin problemas (un riesgo de seguridad).** 

Esto significa que, si nuestro computador y nodo está conectado directamente a Internet, cualquiera puede rastrearlo. 

¿Recuerdas nuestro nodo de Bitcoin instalado al principio? si lo ejecutamos en esa máquina y usamos una segunda máquina con un analizador de vulnerabilidades, encontraremos cosas muy interesantes.

![[401.B7_vulnerabilidades.png]]

**Fácilmente podemos ver que el nodo Bitcoin está siendo ejecutado, que el estado del puerto 8333/TPC está abierto y que efectivamente es un nodo Bitcoin ejecutándose en la máquina.** 

La creación de la regla de muro de fuego para evitar esto soluciona el problema de seguridad, a la vez que mantiene a tu nodo funcionando sin problemas.  En la siguiente imagen puedes ver la regla de para impedir el acceso en la máquina que ejecuta nuestro nodo:

![[401.B7_nodo.png]]

Y en la siguiente imagen el resultado del escaneo mostrando que ya no se puede acceder al nodo:

![[401.B7_escaneo.png]]

Por supuesto, puedes indicar al nodo de Bitcoin (o cualquier otra cripto) que use un puerto distinto para escuchar transacciones, en especial si usas una infraestructura propia. En este caso, tus decisiones de securización deben adaptarse a tu uso sobre el nodo. 

##### 3 | Configura tu nodo para ser seguro
El software de los nodos tiene varias opciones de configuración que debes conocer, con el fin de hacerlos más seguros. 

Por ejemplo, los nodos de Bitcoin Core generalmente son usados para capturar todo el historial de la Blockchain de Bitcoin y para conectarnos a la red sin ningún intermediario, más que el monedero que deseamos usar para tal fin. 

En este punto, el nodo se puede configurar en dos formas:
1. **Nodo con wallet activa:** nos permite usar el nodo como punto de conexión de la red y también como medio para manejar criptomonedas usando sus capacidades de monedero. Esta es la opción más común, pero también la más insegura, porque cualquiera con acceso al monedero tiene acceso a tu monedero.
2. **Nodo con wallet inactiva:** nos permite todo lo anterior, pero sin la capacidad de manejar criptomonedas ya que el monedero y sus claves privadas permanecen en otro dispositivo distinto que está bajo nuestro control (puede ser otro Bitcoin Core, una _Hardware Wallet_ u otro monedero capaz de interactuar con Bitcoin Core por medio de RPC).

Otras opciones de seguridad que puedes activar en tus nodos son las claves de acceso al mismo. En Bitcoin Core puedes, por ejemplo, crear un acceso por medio de clave para que solo proporcionando la misma puedas conectarte al nodo y al monedero del mismo en caso de que lo tengas activo. 

##### 4 | Crea estructuras de acceso bien definidas
Si el nodo y los monederos que deseas asegurar pueden ser accedidos por varios métodos (por ejemplo, si son parte de un Exchange) debes garantizar una estructura y escalado de privilegio para que ese acceso sea seguro. 

Por ejemplo, puedes crear una estructura de monederos de “solo vista” para obtener de ellos (por medio de una API) toda la información necesaria para mostrar saldos o generar direcciones para recibir criptomonedas desde la red. 

Así, puedes separar de forma efectiva los nodos de la red (para seguir su evolución, recibir transacciones y mantener un seguimiento de la misma) y los nodos y monederos de seguridad (aquellos que mantienen los saldos separados, por medio de mecanismos multifirma, MPC y que permiten realizar operaciones de retiro y movilización de saldos). 

En un Exchange esto es básico y algo que el software para este tipo de servicio tiene muy en cuenta, pero incluso si eres un usuario de criptomonedas puedes aplicar este tipo de estrategias. Por ejemplo, puedes generar un monedero MetaMask y usarlo con una _Hardware Wallet_. Así, puedes usar el monedero MetaMask en modo vista (sin conectar la _Hardware Wallet_) y acceder a los protocolos donde tienes saldos, pero solo podrás movilizar dichos saldos si conectas tu _Hardware Wallet_ (ya que en ella se encuentra tu clave privada). 

##### 5 | Mantén tu sistema actualizado y con rastreo de seguridad
Otro punto a tener en cuenta es la actualización del sistema. 

No basta solo con mantener el sistema operativo actualizado, también debes mantener actualizado el software de los nodos y cualquier software que uses e interactúe con ellos, especialmente si dicha actualización es de seguridad o contiene alguna corrección de seguridad para dicho software.

Esto no solo requiere mantener un rastreo de seguridad de todo lo que instales en tu computador, sino también, mantener un acceso claro a los registros y _logs_ de cada uno de esos componentes. 

##### 6 | Mejor off-line
Uno de los puntos más importante en un monedero es la generación de las claves del mismo. 

De ser posible, realizar este proceso en modo _off-line_ garantiza que el proceso se lleve solo con los recursos computacionales de tu computador o smartphone, brindando una capa de seguridad adicional. 

Esto solo es válido para los monederos. Los nodos deben siempre estar en línea, pero debido a que es posible separar los nodos de las claves de un monedero, mantener estos últimos _off-line_ ofrece una protección que pocos hackers realmente pueden atacar. Especialmente si la manejas de forma correcta.

### Casos de uso real de securización de nodos y monederos
#### Coinomi
Uno de los monederos multi-cripto más seguros que se han diseñado es Coinomi, un proyecto de software privativo que ha gozado de una buena política de seguridad desde sus inicios.

Sin embargo, los errores se cometen y el equipo de desarrollo de Coinomi cometió uno muy grave. En 2019, el usuario Warith Al Maawali indicó que había perdido cerca de 70 mil $ USD por culpa de Coinomi, debido a que este monedero enviaba “_peticiones HTTP al servicio de Google Spellcheck_” con la seed phrase del monedero, algo que habría sido aprovechado para vulnerar su monedero y realizar el robo. 

Al Maawali incluso posteó un vídeo donde se mostraba esta “realidad” y con el cual exigía a Coinomi le regresarán su dinero, todo ello sin darse cuenta de que el vídeo que había grabado sería su propia perdición. 

Al Maawali usó un software llamado _Fiddler_, muy usado para interceptar tráfico Web y desencriptar el mismo usando su opción de Proxy HTTPS. El problema de esto es que para interceptar el tráfico HTTPS (tráfico cifrado) con _Fiddler_ es necesario instalar a mano un certificado propio que es usado para crear un proxy transparente que manipula el tráfico HTTPS (lo recibe, desencripta y cifra usando el nuevo certificado, lo que es válido para el sistema porque debe instalarse a mano). 

Como resultado, Al Maawali fue rápidamente expuesto como mentiroso por la comunidad Twitter (algo que era cierto, porque su propio vídeo le dejó en evidencia) pero al mismo tiempo fue un dolor de cabeza para Coinomi porque dejó claro algo que jamás debe hacerse: usar un servicio de _spellcheck_ online para un monedero, ya que basta que Google comience a recopilar dicha información para tener en sus manos una base de datos gigantes de _seed phrase_ válidas para este monedero. 

El error fue corregido posteriormente por _Coinomi_ quien explicó por qué se debía el fallo de seguridad y _CypherBlade_ realizó un [análisis completo](https://medium.com/@cipherblade/how-not-to-react-when-your-cryptocurrency-is-stolen-92f7c72616af) del fallo incluyendo análisis y rastreo de transacciones relacionadas a este evento. 

Esto nos deja algunas lecciones: 
1. **Los monederos con larga trayectoria en la comunidad son generalmente seguros, pero incluso en esos casos, puede haber errores.** No importa si es software libre o privativo, siempre habrá errores (_Coinomi_ es privativo, pero el núcleo del monedero es libre).
2. **De ser posible, la mejor forma de guardar tu dinero (en especial si son grandes cantidades) es usando mecanismos de seguridad adicionales (multi-firma 2-de-3, por ejemplo).** De esta manera, evitas que un dispositivo vulnerado pueda, simplemente, arruinarte el día.
3. **Si tienes  una empresa que desarrolla productos para criptomonedas, lo mejor es mantener el control del software que usas en dichos productos.** Esta es una tarea compleja y requiere de grandes recursos, pero es la mejor solución de seguridad en este sentido. El error de _Coinomi_ en este caso es hacer uso directo de las actualizaciones de código de _jxBrowser_ (el núcleo Chromium usado por el monedero) para crear su monedero (tanto desktop como móvil) sin tener en cuenta los servicios habilitados por defecto (como el hecho de que todo lo que escribes en _jxBrowser_ es enviado a Google pro medio de su API _Google Spellcheck_).

#### Electrum
El año 2019 fue un mal año para Electrum, debido a que en este año se intensificaron los ataques a su red. De hecho, la red fue tan afectada que cerca del 70% de los nodos de la misma eran nodos vulnerados. Todo empezó el 26 de diciembre de 2018, con el siguiente [head up en GitHub](https://github.com/spesmilo/electrum/issues/4968).

![[402.B7_electrum.png]]

El problema rápidamente escaló, y en dos campañas de ataque los usuarios de _Electrum_ perdieron más de 1500 BTC en ese entonces. La razón: un problema con la estructuración de la confianza entre los monederos _Electrum_ y los nodos _ElectrumX_. El error ha sido corregido pero los 1500 BTC perdidos no se recuperan jamás. 

En este caso podemos aprender lo siguiente:
1. **Si deseas ejecutar monederos con grandes cantidades de criptomonedas en ella,** lo mejor es confiar en el software descargado de fuentes oficiales y usar mecanismos de seguridad adicionales (MuSig, MPC, entre otros).
2. **Si creas un software para manejar criptomonedas, no generes interfaces que le permitan a un tercero personalizar mensajes desde el servidor.** Respuestas genéricas (como HTTP 404, que indica que lo solicitado no existe o no es accesible) son mejores para estos casos, dejando que los códigos estén hardcoded dentro del software. Esto evita hasta cierto punto la manipulación de la red y sus nefastas consecuencias.

## U6. Introducción al Hacking
### Introducción al Hacking (Video)
![[403.B7_Introducción_al_Hacking.mp4]]
[Introduccion al Hacking](https://app.web3mba.io?wvideo=gl7o64asiz)

El mundo del cine, la televisión y los medios de comunicación nos hacen ver al hacker como el villano de la sociedad, alguien que puede realizar tareas imposibles y que busca hacernos daño en todo momento, sin entender que existen distintos tipos de hackers y, por tanto, de hacking. En la cultura hacker, hacer hacking incluye una serie de tareas tan benignas como mejorar la seguridad de un sistema, buscando vulnerabilidades del mismo y reparándolas. Por ello, se suele ver al hacking como romper las cosas para mejorarlas. Por supuesto, lo que sirve para hacer el bien también puede usarse para hacer el mal. Pero son dos cosas distintas, dos moralidades y éticas encontradas en constante lucha, lo que nos lleva a diferenciar a los hackers de la siguiente manera.

Los White Hats son una clase de hackers dedicados a la detección y corrección de vulnerabilidades en el software, así como a la definición de metodologías, medidas de seguridad y defensa de sistemas mediante distintas herramientas. Son aquellas personas que se dedican a la seguridad en aplicaciones, sistemas operativos y protección de datos sensibles, garantizando de esta forma la confidencialidad de la información de los usuarios. Generalmente, también se usa este concepto para incluir a los desarrolladores de hardware y software que buscan crear y mejorar el ecosistema informático para todos. Un White Hat puede tener grandes habilidades para romper sistemas, obtener información y más. Sin embargo, su ética y moral le mantienen centrado en un punto: trabajar para hacer del mundo digital un espacio mejor y seguro para todos.

Otra clasificación son los Black Hats. Este tipo de hacker se dedica a la obtención y explotación de vulnerabilidades en sistemas de información, bases de datos, redes informáticas, sistemas operativos y determinados productos de software, entre otros. Por lo tanto, también son conocidos como atacantes de sistemas y expertos en romper la seguridad de los mismos para diversos fines, normalmente en busca de su propio beneficio. También podemos encontrarnos con hackers que se denominan Grey, Blue y Red Hats. Pero el mundo de los hackers no se divide solo en blanco y negro; también hay términos intermedios. Por ejemplo, un Grey Hat es un hacker que puede robar información y liberarla al mundo con la finalidad de lograr el bien común para todos. Las acciones llevadas a cabo por Anonymous son un claro ejemplo de hackers Grey Hats. Herramientas como LOIC, creadas por Anonymous, permitieron que cualquiera, de acuerdo con su ideal, participara en sus cadenas de ataques de denegación de servicio, a la vez que realizaban ataques a empresas o comunidades que atentaban contra la seguridad o la verdad.

Otra representación de los hackers la podemos ver en los Green Hats, que se usan para referirse a los iniciados en el hacking. Mientras que los Blue Hats pueden definirse como los Black Hats que trabajan para compañías, ya sea para mejorar su propia seguridad o para romper la seguridad de otros sistemas en beneficio propio. Son el equivalente a los mercenarios. Finalmente, tenemos a los Red Hats, considerados muchas veces como los hackers más especializados en el mundo del hacking. Un Red Hat es un vigilante, un tipo de hacker que busca de forma activa y pasiva la actividad de otros hackers, Black, Grey y Blue, para detener su avance y ganarles la batalla. Generalmente, los Red Hats ocupan espacios de gestión de ciberseguridad en las empresas porque su principal interés no es solo conocer la última técnica de seguridad o de hacking, sino aplicarlas y buscar formas de contrarrestar sus efectos.

Los objetivos de hacking siempre van dirigidos a atacar los distintos vectores que intervienen en los sistemas informáticos. La infraestructura puede ser hardware o software. Las aplicaciones pasan por atacar las vulnerabilidades o fallos que puedan tener, por ejemplo, aplicaciones web. Y finalmente, el usuario, que es el eslabón más débil de todos, es el que suele ser atacado. Podemos ver que hay varios tipos de usuarios y distintos ejemplos de hacking a lo largo del tiempo, como el hacking que sufrió NVIDIA. Recientemente, en 2022, la compañía fue víctima de un hackeo a sus servidores e infraestructura digital interna por parte de un grupo de hackers Black Hat llamado LAPUS. Como resultado de este ataque, los hackers pudieron acceder a un tera de datos confidenciales de la empresa, entre los que se encontraba el código fuente de sus drivers, el software de desarrollo y documentación detallada de sus arquitecturas, entre otros muchos datos que aún no se han hecho públicos por parte del grupo de hackers.

Curiosamente, el grupo de hackers trató de usar la información adquirida para presionar a NVIDIA y equilibrar el código de drivers de GNU/Linux, algo que, por cierto, NVIDIA ha empezado a hacer bajo otro esquema de colaboración con la comunidad GNU/Linux. Los hackers indican que tuvieron acceso a la red de NVIDIA a través de su servicio VPN, creado para que sus trabajadores pudieran trabajar de forma remota, de manera segura y conectarse así a su red interna. Una debilidad en dicha estructura fue la utilizada para obtener el acceso y robar los datos de NVIDIA. NVIDIA, por su parte, hizo uso de un grupo de Blue Hats con el fin de evitar que LAPUS pudiera leer dicha información, algo que intentaron sin éxito infectando las computadoras de los hackers con un ransomware. Este sería uno de los primeros casos conocidos públicamente en los que una empresa hace uso directo de hackers para atacar un objetivo.

Otro caso muy conocido es el de la empresa SolarWinds, la cual sufrió recientemente un hackeo en sus instalaciones. El hackeo a SolarWinds lo ejecutó un sofisticado colectivo de ciberdelincuentes, aparentemente sin un móvil económico; solo pretendían espiar a sus víctimas. Según destacaron los investigadores de la firma de ciberseguridad FireEye, que también se vio afectada por este incidente, se cree que detrás de este ataque hay una gran cantidad de Blue Hats trabajando a manos de algún gobierno, ya que el trabajo es extremadamente sofisticado. La dimensión total de la cantidad de empresas y organizaciones que se han visto afectadas por este hackeo es masiva. Todavía no se ha podido determinar con exactitud, pero se incluyen todas las ramas de la Armada de Estados Unidos; empresas muy importantes como Microsoft e Intel también se han visto afectadas. Cisco, NVIDIA, VMware y Belkin han sido algunas de las otras empresas que también se han visto afectadas por este ataque. Pero este golpe es notable por el alto nivel de empresas y administraciones que han resultado víctimas.

Tampoco podemos evitar el hackeo en otras compañías y en otros mundos, como el de las criptomonedas. Por ejemplo, en Bitcoin, el bug de inflación le permitió a un hacker crear una sala de transacción con varios millones de bitcoins que pudo llevar a su monedero. Sin embargo, el fallo fue detectado y se corrigió el problema en solo seis horas. La situación nos dejó un claro mensaje: incluso sistemas seguros como Bitcoin y su blockchain son susceptibles a ataques. La situación se repitió tanto a nivel on-chain, es decir, dentro de los protocolos de criptomonedas, como off-chain, en servicios externos como los exchanges centralizados. Algunos de esos casos fueron corregidos, como el caso de DAO en Ethereum, el cual llevó a un hard fork para recuperar los fondos, pero en otros eventos no se ha corregido con tanta suerte, llevando a la pérdida de fondos.

Cualquier hackeo se puede englobar en seis fases. La primera es la recolección de información. En este punto, el hacker comienza a recolectar toda la información posible de la víctima o sistema objetivo. El fin de esta etapa es reconocer el objetivo, encontrar los puntos de ataque con mayor probabilidad de éxito y preparar todo para el siguiente paso. El segundo paso es el scanning. Durante esta etapa, el hacker comienza a recolectar información técnica del objetivo. Para ello, realiza un escaneo de sus servicios o, en su defecto, se comienza con el proceso de social engineering con el fin de lograr éxito en una campaña de ingeniería social. El tercer paso es el análisis de las vulnerabilidades. Una vez que se han analizado y escaneado los vectores para el ataque, llega la hora de un análisis más profundo de aquellos vectores que pueden ser potencialmente explotables. Para ello, se realiza un análisis de vulnerabilidades.

El cuarto paso es el desarrollo del plan de ataque y la selección de herramientas de hacking. Una vez que se encuentran vulnerabilidades, es hora de idear el plan de ataque y conseguir todo lo necesario para realizar el ataque de forma exacta. En este punto, el hacker decide la hora y la fecha del ataque y prepara todas las herramientas necesarias para acceder al sistema, conseguir la información y, de ser posible, pasar totalmente desapercibido y mantener el acceso a los sistemas con el fin de seguir obteniendo información del mismo. El quinto paso es el ataque. Finalmente, durante el ataque se realiza la explotación de las vulnerabilidades detectadas, se logra el objetivo de acceder al sistema y se puede salir. Se escalan privilegios para obtener toda la información que se desea del mismo. En este punto, dependiendo del nivel de acceso y la forma en cómo funciona la red, se pueden acceder a servicios adicionales, que pudieron o no detectarse durante los análisis iniciales. Si es posible atacarlos de la misma forma, se realiza el ataque; y si no se puede, se planifica su ataque posterior.

Ya en una etapa de post-ataque, el objetivo de los hackers, una vez realizado el ataque, es, por un lado, mantener el acceso al sistema. Generalmente, esto lo hacen por medio de programas ocultos que les garantizan dicho acceso cuando lo deseen. Luego, indican que han tenido acceso y piden una suma de dinero por no revelar la información, especialmente si dicha información podría darle a la competencia ventaja sobre sus productos y servicios.


### Fundamentos de Hacking
Cuando hablamos de _Hacking_ o mencionamos _Hacker_ se nos viene a la mente una persona con grandes conocimientos de informática, hardware, software y sobre todo ciberseguridad y vulnerabilidades para pasar por todo tipo de sistemas.

Esa idea no es errónea, sin embargo, el mundo del cine, TV y los medios de comunicación nos hacen ver al hacker como el malo de la sociedad, aquel que puede hacer tareas imposibles. Como alguien que busca hacernos daño en todo momento sin entender que existen distintos tipos de hackers y, por tanto, de hacking.

En la cultura hacker, hacer _hacking_ incluye una serie de tareas tan benignas como mejorar la seguridad de un sistema, buscando vulnerabilidades del mismo y reparándolas. 

Por ello, se suele ver al hacking como “romper las cosas, para mejorarlas”. Por supuesto, lo que sirve para hacer el bien, también se puede usar para hacer el mal, pero son dos cosas distintas; dos moralidades y éticas encontradas y en constante lucha que nos llevan a diferencias a los hackers de la siguiente manera:
1. White Hat
2. Black Hat
3. Gray, Blue y Red Hat

#### 1 | White Hat
Se dedica a la detección y corrección de vulnerabilidades de software, definición de metodologías, medidas de seguridad y defensa de sistemas por medio de distintas herramientas. 

Son aquellas personas que se dedican a la seguridad en aplicaciones, sistemas operativos y protección de datos sensibles, garantizando de esta forma la confidencialidad de la información de los usuarios. 

Generalmente también se usa este concepto para incluir a los desarrolladores de hardware y software que buscan crear y mejorar el ecosistema informático para todos. 

Un _White Hat_ puede tener grandes habilidades para romper sistemas, obtener información y más, sin embargo, su ética y moral le mantienen centrado en un punto: Trabajar para hacer del mundo digital un espacio mejor y seguro para todos. 

#### 2 | Black Hat
Hacker especializado en la obtención y explotación de vulnerabilidades en sistemas de información, bases de datos, redes informáticas, sistemas operativos, determinados productos de software, etc. 

Por lo tanto, son también conocidos como atacantes de sistemas y expertos en romper la seguridad de los mismos para diversos fines (normalmente en busca de su propio beneficio).

#### 3 | Gray, Blue y Red Hat
Pero, el mundo de los hackers no se divide solo en “blanco y negro” y también hay términos intermedios. 

- **Un _Gray Hat_ es un hacker que puede robar información y liberarla al mundo con la finalidad de lograr el bien común para todos.** Por ejemplo, las acciones de Anonymous son un claro ejemplo de _Gray Hats_. Herramientas como LOIC creadas por Anonymous, permitieron que cualquiera de acuerdo con su ideal participara en sus cadenas de ataques DDoS, a la vez que realizaban ataques a empresas o comunidades que atentaban contra la seguridad o la verdad.  
- **El término _Green Hackers_ se usa para referirse a los iniciados en el hacking.** 
- **Los _Blue Hats_ suelen ser _B__lack Hats_ que trabajan para compañías, bien sea para mejorar su propia seguridad o romper la seguridad de otros sistemas para su propio beneficio:** El equivalente a los mercenarios. 
- **Un _Red Hat_ es un vigilante; un tipo de hacker que busca, de forma activa y pasiva, actividad de otros hackers (_Black, Gray y Blue_) para detener su avance y ganarles la batalla.** Generalmente, los Red Hat ocupan espacios de gestión de ciberseguridad de las empresas, porque su principal interés no es solo conocer la última técnica de seguridad o de hacking, sino aplicarlas y buscar formas de contrarrestar sus efectos. 

#### Figuras importantes en el movimiento hacker
Algunas figuras importantes en este punto son:
1. **Linus Torvalds,** quien es el creador del kernel Linux, ampliamente usado en los servidores de Internet y dispositivos como los smartphones con sistema Android. Linus es mayormente conocido por crear el kernel Linus y mantenerlo hasta nuestros días, pero también es el creador de Git, el software de control de versiones más usado en el mundo del software libre. Linus es considerado uno de los grandes White hats que existen en la actualidad.
2. **Richard Stallman,** fundador de la GNU Foundation, creador del compilador libre GCC y de la mayoría de las herramientas GNU, que forman parte del bipartito GNU/Linux.  Su papel ha sido fundamental para la creación del software libre tal como lo conocemos, especialmente por la creación de la licencia GPL. Stallman es considerado un gran White Hat, ya que su trabajo derivó en la creación de toda una serie de sistemas operativos basados en Unix.
3. **Jeff Moss,** uno de los White hackers más conocidos en el mundo que usaba el seudónimo de Dark Tangent. Moss fundó las conferencias de seguridad Black Hat y DEFCON, consideradas como las más importantes en el mundo de seguridad informática.
4. **Theo de Raadt,** quizás no es un nombre tan conocido como Linus Torvalds o Richard Stallman, pero de Raadt ha hecho enormes contribuciones al mundo del software libre y la ciberseguridad, siendo considerado "el incorregible perfeccionista de la ciberseguridad”. Raadt es el creador del sistema operativo OpenBSD, considerado el sistema operativo más seguro del mundo y ampliamente usado en hacking.

Raadt es ampliamente conocido por ser uno de los “Red Hat” (aunque no le gusta esa descripción) por diseñar y poner en práctica técnicas de ciberseguridad únicas entre las que tenemos:
- **La primera implementación del protocolo IPv6 del mundo (inetv6),** creada para OpenBSD y puesta en marcha en 1999.
- **W^X,** una medida de protección para marcar las páginas de memoria exclusivamente como Write o Execute (Escritura o Ejecución) lo que evita inyecciones arbitrarias de código, creada en 2003. 
- **Stack Guard Pages,** protector de espacios memoria. 
- **ASLR en todo el sistema.** ASLR es una técnica que aplica un algoritmo de asignación de recursos de memoria de forma aleatoria, para evitar la explotación de los programas. Una medida implementada en 2003 en todo el sistema, y que sistemas como GNU/Linux, MacOS, Windows e incluso FreeBSD no pueden igualar o simplemente no aplican. 
- **OpenBSD** de momento es el único sistema con esto aplicado a todo nivel incluyendo relinking dinámico usando ASLR sobre el mismo kernel (el kernel se regenera en cada boot y se acomoda para generar una imagen aleatoria de sí mismo). Hasta el momento, OpenBSD es el único SO con este tipo de funciones. 
- **La implementación de pila Web (TCP/IP, IPSEC, SSH (OpenSSH),** inet (IPv4 e IPv6), SSL (llamada LibreSSL), NTP (OpenNTPD), entre otros servicios) más segura y estandarizada que existe hasta el momento. 
- **La creación del firewall o muro de fuego,** pf, considerado como uno de los muros de fuegos más completos y seguros (NFT, el reemplazo de iptables en GNU/Linux, está fuertemente inspirado en pf e ipfs, un derivado de FreeBSD). 
- **Funciones criptográficas** como bcrypt y arc4random.
- **Las primeras protecciones completas contra abusos de API/ABI con respecto al sistema operativo (unveil, RETGUARD, MAP_CONCEAL).** OpenBSD nuevamente es el único sistema con funciones a este nivel. 
- **Las primeras protecciones completas contra hardware bugs como Spectre y Meltdown.** [Raadt lleva hablando de fallos de este tipo desde 2007](https://linuxreviews.org/Theo_de_Raadt_on_the_Intel_Core_2_Jun_27,_2007), 11 años antes de que se hicieran públicos los ataques Spectre, Meltdown y sus evoluciones.

### Medidas para protegernos del hacking (Video)
![[413.B7_Tipos_y_Tecnologías_de_Hacking.mp4]]
[Medidas para protegernos del hacking](https://app.web3mba.io?wvideo=c6hop4mxx4)

¿Qué medidas podemos tomar para protegernos de los hackeos? No solo a nivel personal, sino también empresarial, con el fin de proteger a nuestras empresas, sus productos y servicios, y lo más importante, la información y privacidad de nuestros clientes.

El primer paso para protegernos de los hackeos es pensar en construir buenas defensas para nuestros sistemas. En ese caso, la seguridad defensiva es la rama de la ciberseguridad que tiene la finalidad de proteger la organización bajo cualquier concepto, desde el estudio e investigación de la red actual hasta el completo bastionado de la infraestructura de red de la organización, diseñando un plan de seguridad que permita garantizar la efectividad de los controles de seguridad desplegados. Veamos algunos ejemplos.

La seguridad defensiva es un diseño que se aplica en proyectos de informática, software o infraestructura desde sus bases. Por ejemplo, durante el diseño de una aplicación, los desarrolladores que aplican lineamientos de seguridad defensiva diseñan sus proyectos de software pensando en la seguridad desde su más bajo nivel. No solo eso, sino que durante la producción, el software es sometido repetidamente a análisis de seguridad y todo tipo de pruebas para intentar romperlo.

Un EDR es un software especializado que permite asegurar una infraestructura empresarial contra nuevas amenazas, incluso aquellas que son completamente nuevas y no detectadas hasta entonces, las cuales son conocidas como amenazas persistentes avanzadas o, por sus siglas, APT. Los EDR generalmente son instalados en computadoras, portátiles o celulares empresariales, con el fin de rastrear la actividad de los mismos y mantenerlos seguros. Debido a su papel en la seguridad de los sistemas, los EDR suelen ser un punto de ataque que los hackers buscan explotar. Después de todo, hacer caer el EDR o traspasar su seguridad le permite al atacante pasar desapercibido sus ataques a las empresas y poder lograr acceso a todos los equipos dentro de la misma.

Ahora bien, es bueno que sepamos las diferencias entre un antivirus, un firewall y un endpoint. Generalmente, el software antivirus y firewall son elementos de protección de los endpoints, vistos como equipos clientes, porque estos softwares, antivirus y firewall, ofrecen protección a los mismos. Dicho de otra forma, los endpoint security software son soluciones completas de seguridad con capacidades avanzadas de detección y respuestas intuitivas que ayudan a las organizaciones a tener un control total de su seguridad.

Uno de los beneficios, principalmente, de implementar este tipo de software es proporcionar un sistema integral para prevenir, detectar y corregir de forma proactiva los ataques de malware evasivos, crear funciones de puntos extremos maduros para protegerte contra ataques cibernéticos conocidos y desconocidos, utilizar las prácticas recomendadas de la industria que aumentan la seguridad de los puntos extremos para combatir los ataques dirigidos y evasivos, y reconocer las altas tasas de captura y los bajos fallos de seguridad que garantizan la eficacia en la seguridad eficiente y en una prevención oportuna. Tener un análisis automatizado de datos forenses ofrecerá información detallada sobre las próximas amenazas. La contención total de los ataques y su remediación restauran rápidamente cualquier sistema infectado.

Los servidores de correo o email servers son uno de los vectores de ataque más usados hoy en día por los ciberdelincuentes. Frente a esta realidad, uno de los puntos a fortificar en las empresas son estos servicios, especialmente porque dichos correos son los que permiten a los empleados, clientes y proveedores comunicarse con la empresa de forma rápida y segura. Pero, ¿qué medidas de seguridad se pueden tomar para proteger los servicios de email contra ataques de hacking? Bien, entre esas opciones podemos mencionar…

Asegurarse de que sus cuentas de usuario sean seguras. Aunque probablemente esté usando SCLTLS, es importante porque a veces la contraseña de los usuarios no es la más fuerte. En todo caso, recuerda que mantener las políticas de contraseña seguras y habilitar la autenticación de dos pasos nos permite mantener una seguridad en nuestra cuenta de correo electrónico. La importancia de activar la autenticación en dos pasos nos permite que, si algún atacante logra acceso a nuestro usuario y contraseña a partir de distintos métodos, por ejemplo, como puede ser un ataque phishing, puede ser que estemos utilizando nuestra misma contraseña para otros servicios, como redes sociales. Por algún motivo, si un atacante logra hacerse de nuestro usuario y contraseña, no va a poder ingresar a nuestra cuenta si tenemos habilitado el segundo factor de autenticación.

El segundo factor de autenticación generalmente lo tenemos en otro dispositivo, usualmente en nuestro dispositivo móvil a través de una aplicación, lo cual nos garantiza que, para poder acceder a nuestra cuenta, la persona no solo va a tener que tener nuestro usuario y contraseña, sino que también va a tener que poseer nuestro dispositivo móvil, poder ingresar a nuestro dispositivo y hacerse del código que tenemos en nuestra aplicación, por ejemplo, Google Authenticator.

Las soluciones NAC o Network Access Control permiten definir políticas que deben cumplir todos los dispositivos antes de conectarse a nuestra red corporativa. Los dispositivos fijos y móviles que no cumplen las políticas establecidas no podrán interactuar con la red. De esta forma, aislamos estos dispositivos de forma preventiva hasta la resolución del incumplimiento. Las soluciones NAC son complementarias a los firewalls, ya que, una vez traspasada la barrera de seguridad perimetral, el firewall, el NAC actúa como un control de acceso propio del dispositivo a la red. De este modo, se dispone de un control de todos los elementos que acceden a la red, independientemente de su naturaleza y detección en tiempo real.

Otro punto a tener en cuenta en la seguridad defensiva son los principios de la ciberseguridad que se pueden ver en la siguiente imagen. Conocida como CIA, Confidencialidad, Integridad y Disponibilidad, estos principios son la base para la construcción de las políticas de ciberseguridad. La confidencialidad de la información, también conocida como privacidad, hace referencia a que la información solo debe ser conocida por las personas que necesitan conocerla y que han sido autorizadas para ello. Este principio asegura que la información no va a ser divulgada de manera fortuita o intencionada.

La integridad de la información hace referencia a que la información que se encuentra almacenada en los dispositivos o la que se ha transmitido por cualquier canal de comunicación no ha sido manipulada por terceros de manera malintencionada. Esto garantiza que la información no será modificada por personas no autorizadas. La disponibilidad de la información se refiere a que la información debe estar disponible siempre para las personas autorizadas para accederla y tratarla, y además puede recuperarse en caso de que ocurra un incidente de seguridad que cause su pérdida o corrupción. Es decir, permite que la información esté disponible cuando sea necesario.

La ciberseguridad es un concepto muy amplio que engloba muchas disciplinas, como pueden ser la criptografía, la ciberinteligencia, el análisis de malware o el reversing. Debido a la transformación digital y a la especialización de los ciberdelincuentes, la seguridad informática no deja de crecer y expandirse, y por ello nacen nuevas técnicas como la seguridad ofensiva. La seguridad ofensiva o seguridad activa es un conjunto de herramientas o soluciones que tiene como objetivo identificar en tiempo real el grado de exposición que tiene una organización y cómo afectaría cualquier incidente que se produjera.

Uno de los retos a los que se enfrentan las organizaciones es la demanda de nuevos perfiles tecnológicos que lleven a cabo este tipo de medidas. Estos profesionales reúnen información para prevenir futuros ataques y, para ello, se sirven del conocimiento y la experiencia sobre el entorno externo y las redes internas. Los análisis de vulnerabilidades son auditorías que tienen como objetivo evaluar las debilidades que puedan existir en un determinado sistema, aplicación o software que pudiera afectar su integridad durante su vida útil. Con este servicio se determina el nivel de seguridad que tiene la empresa y cómo pueden llegar a afectar estas vulnerabilidades a la continuidad del negocio.

El análisis variará dependiendo del entorno donde realicemos las pruebas. Si el entorno es interno, el análisis de vulnerabilidades se realiza desde la red interna del cliente, desde su propia intranet, en sus oficinas o mediante una conexión VPN. Si el análisis de vulnerabilidades es externo, el mismo se realiza desde el exterior de la red, generalmente desde internet. El pentesting está enfocado a la realización de pruebas de penetración atacando a los sistemas de información o a la propia organización. Estas pruebas tienen la finalidad de descubrir cualquier tipo de vulnerabilidad que pudiera afectar al entorno y a las bases que permitan prevenir este tipo de ataques.

Cuando hablamos de realizar un hacking ético, nos referimos a realizar un pentesting que abarca absolutamente todo. O dicho de otro modo, no hay un objetivo determinado, todo es explotable y no hay limitación más allá de las pactadas con el cliente para la realización de las pruebas, en las que se puede excluir algún tipo de pruebas. En ejercicios de este tipo se simulan comportamientos de un ataque real realizado por un grupo de cibercriminales que tiene el objetivo de comprometer la organización en su totalidad, haciendo uso de técnicas propias de bandas cibercriminales organizadas. Este tipo de pruebas no son necesarias, son las que están más a la vanguardia en cuanto a seguridad ofensiva, haciendo uso de vectores de ataques conocidos o incluso diseñando nuevos vectores para poner a prueba las defensas de las mejores organizaciones.

La duración de estos ejercicios suele variar entre unas pocas semanas y varios meses, y son pactadas en el alcance del proyecto. En resumidas cuentas, un hacking ético aporta el mayor valor para el cliente en cuestiones de auditoría y seguridad técnica, teniendo como objetivo la toma del control de la organización bajo cualquier concepto e incluso persistiendo en la red hasta la finalización del ejercicio.

Mientras que un programa bug bounty es un contrato que una empresa u organización establece con una comunidad de hackers éticos con el fin de que estos detecten vulnerabilidades en los sistemas y redes de dicha empresa. Un hacker ético es una persona que usa sus conocimientos avanzados en informática para hacer el bien. Su trabajo consiste en realizar pruebas en sistemas y redes con el fin de detectar vulnerabilidades que a su vez son reportadas a las empresas para que tomen las medidas necesarias y eviten así futuros ataques. Estos programas generalmente se llevan a cabo para ejecutar los servicios de revisión de aplicaciones, pruebas de penetración, revisión de código, ingeniería inversa, etc., entre otros, y por lo general se llevan a cabo antes de que la versión final salga al público.

Algunas de las principales buenas prácticas que garantizan el cumplimiento de los tres principios fundamentales de la seguridad de la información son las que se comentan a continuación.

Política de mínimos privilegios. Las personas de una organización no deberían acceder a toda la información de esta, solo aquellas que sean de utilidad e importantes para la ejecución de su trabajo. Aplicando efectivamente una política de gestión de privilegios de los usuarios, estamos minimizando los riesgos de fuga de información, manipulación no autorizada de la misma y minimizando la superficie de ataques de nuestra organización.

Política de control de acceso cerrado por defecto, o en inglés se conoce también como Zero Trust, confianza cero. Todos los accesos a la información y a los sistemas que la tratan o almacenan deberían estar cerrados para todos los usuarios, y se permitiría solo acceso a aquellos que estén autorizados a hacerlo.

Segregación de funciones. Se debería definir e implementar una separación efectiva de las funciones y responsabilidades del personal de las organizaciones para evitar conflictos de interés y minimizar los riesgos de seguridad de la información derivados de la acumulación de privilegios y conocimiento en las personas.

Defensa en profundidad. Ante la gran cantidad de riesgos para la seguridad de la información a la que están expuestas las organizaciones, derivadas de la utilización y dependencia de las TIC, cada vez la superficie de ataque de estas es mayor, por lo que sería necesario diseñar e implementar varios niveles de seguridad acorde a un análisis de riesgo riguroso de sus activos de TIC.

Formación en ciberseguridad. El eslabón más débil de la seguridad de la información de una compañía son las personas. La mayoría de los incidentes de seguridad que sufren las organizaciones están originados por personal interno, de estas de manera no intencionada o fortuita y derivadas de su desconocimiento de las mejores prácticas de ciberseguridad o de las políticas y procedimientos a tal efecto de la organización. Por eso, es fundamental definir e implantar planes formativos en seguridad informática para todo el personal de la compañía y acorde a sus funciones y responsabilidades.

Auditorías de seguridad informática. Es recomendable realizar controles de auditoría donde se verifique la efectividad y el cumplimiento de las políticas, procedimientos, medidas técnicas y organizativas de la seguridad de la información en la organización, y que permitan detectar debilidades o vulnerabilidades que puedan ser explotadas por potenciales atacantes. En base a los resultados de las mismas, se debería diseñar y poner en marcha planes de acción correctivos para solucionar los hallazgos detectados durante las mismas.

### Objetivos del Hacking
Los objetivos del hacking siempre van dirigidos a atacar los distintos eslabones o vectores que intervienen en los sistemas informáticos:
1. **La infraestructura,** haciendo mención a los computadores o servidores en las que se ejecuta la aplicación. Así como elementos tales como la red que permite la conexión o cualquier elemento de hardware o software que permite construir las bases del funcionamiento de la aplicación que será atacada.
2. **La aplicación,** que pasa por atacar las vulnerabilidades o fallos que tenga la misma. Entiéndase aplicación a cualquier código fuente o binario que se ejecuta sobre un servidor o serie de servidores, con el fin de proporcionar la funcionalidad que los usuarios desean. Esto puede ser, por ejemplo, una aplicación Web centralizada o descentralizada o una aplicación no Web, pero cuyo recurso puede ser accedido por medio de red o por ejecución local.
3. **Finalmente, el usuario ya que este es el eslabón más débil de todos a ser atacado.** El usuario final se centra en usar un software sin preocuparse la mayor parte del tiempo en la seguridad de su sistema, las actualizaciones, o el origen mismo de la aplicación. En definitiva, el usuario y sus recursos son los más fácilmente explotables y por tanto son los que más reciben atención en el hacking, especialmente cuando se atacan aplicaciones o infraestructuras (los dos vectores pasados) que están fuertemente protegidos.  

**En todos los vectores dado el objetivo es el mismo:** romper la seguridad y acceder a los recursos y sistemas que protegen y tienen acceso, sin necesidad de contar con un acceso autorizado para el mismo e incluso, permitiendo obtener permisos administrativos completos, con los cuales el hacker puede hacer prácticamente todo en dichos sistemas.

### Casos reales de Hacking
1. NVidia
2. Solarwind
3. Criptomonedas

#### 1 | NVidia
Recientemente, en 2022, la compañía Nvidia fue víctima de un hackeo a sus servidores e infraestructura digital interna por parte de un grupo de hackers Black Hat, de nombre _Lapus$_. 

- Como resultado de este ataque, los hackers pudieron acceder a 1 TB de datos confidenciales de la empresa, entre los que encontraba código fuente de sus drivers y software de desarrollo, documentación detallada de sus arquitecturas, entre otros datos que aún no se han hecho públicos por parte del grupo de hackers. 
- Curiosamente, el grupo de hackers trató de usar la información adquirida para “doblar” a Nvidia para que liberaran el código de drivers para GNU/Linux, algo que por cierto Nvidia ha empezado a hacer, bajo otro esquema de colaboración con la comunidad GNU/Linux.
- Los hackers indican que tuvieron acceso a la red de Nvidia por medio de su servicio VPN creado para que sus trabajadores en remoto pudieran acceder de forma segura a su red interna, una debilidad en dicha estructura fue la usada para obtener el acceso y robar los datos.
- Nvidia, por su parte, hizo uso de un grupo de _Blue Hats_ con el fin de evitar que Lapus$ pudiera leer dicha información, algo que intentaron sin éxito, infectando los computadores de los hackers con un _ransomware_. Este sería uno de los primeros casos conocidos públicamente en los que una empresa hace uso directo de hackers para atacar un objetivo.

#### 2 | SolarWind 
Otro caso reciente, el hackeo a _SolarWind,_ lo ejecutó un sofisticado colectivo de ciberdelincuentes sin un aparente móvil económico: Tan solo pretendían espiar a sus víctimas, según destacaron investigadores de la firma de ciberseguridad _FireEye_, que también se vio afectada por este incidente. 

Se cree, que detrás de este ataque hay una gran cantidad de _Blue Hats_ trabajando a manos de un gobierno, ya que el trabajo es extremadamente sofisticado. 

La dimensión total de la cantidad de empresas y organizaciones que se han visto afectadas por este hackeo masivo todavía no se ha podido determinar, pero se incluyen a todas las ramas de la _US Army, Microsoft, Intel, Cisco, Nvidia, VMware y Belkin_. Pero este golpe es notable por el alto nivel de las empresas y administraciones que han resultado víctimas. 

#### 3 | Criptomonedas
El mundo cripto tampoco está exento de los casos de hacking desde sus inicios. Por ejemplo, en Bitcoin, el bug de inflación le permitió a un hacker crear en una sola transacción 184 mil millones de BTC que llevó a su monedero. 

Sin embargo, el fallo fue detectado por Jeff Garzik (actual CEO de Bloq) y se corrigió el problema en solo 6 horas. Sin embargo, la situación nos dejó un claro mensaje: incluso sistemas seguros como Bitcoin y su blockchain son susceptibles de ataques. 

La situación se repitió tanto a nivel _on-chain_ (dentro de los protocolos de criptomonedas) como _off-chain_ (en servicios externos como los exchanges centralizados). Algunos de esos casos fueron corregidos, como el caso de The DAO en Ethereum, el cual llevó a un _hard fork_ para recuperar los fondos; pero en otros eventos, no se ha corrido con tanta suerte, llevando a la pérdida de fondos.

### Ciclos del Hacking
Para realizar un hacking exitoso, se debe tener en cuenta un ciclo muy claro que podemos describir en la siguiente imagen:

![[408.B7_ciclos.png]]

Estas reglas se aplican a todos los tipos de hackers, sin importar si su objetivo es atacar.

#### 1 | Recolección de información
En este punto, el hacker comienza recolectar toda la información posible de la víctima o sistema objetivo. 

La búsqueda de información puede ser pasiva o activa, usando distintos medios (desde bots, metadatos en buscadores y redes sociales, dorks, publicaciones del objetivo e incluso ingeniería social). 

El fin de esta etapa es: 
- Reconocer el objetivo. 
- Encontrar los puntos de ataque con mayor probabilidad de éxito. 
- Preparar todo para el próximo paso. 

#### 2 | Scanning
Durante esta etapa el hacker comienza a recolectar información técnica del objetivo. 

Para ello realiza un escaneo de sus servicios o, en su defecto, se comienza con el proceso de “social bombing” con el fin de lograr éxito en una campaña de ingeniería social.

 Toda esta información es tomada en bruto, analizada y dividida según su utilidad con el fin de servirse de ella para el próximo paso. 

#### 3 | Análisis de vulnerabilidades
Una vez que se han analizado y escaneado los vectores para el ataque, llega la hora de análisis a mayor profundidad de aquellos vectores con mayor potencial de explotabilidad. 

Para ello, se realiza un análisis de vulnerabilidades. 

En este caso, si, por ejemplo, se está atacando un sitio Web, se busca detectar si el servidor en cuestión está actualizado y protegido contra vulnerabilidades ya conocidas y que son peligrosas. Si el servicio analizado es un servidor de correo, se analiza igualmente si está actualizado y protegido.

Por supuesto, el análisis de vulnerabilidades no solo se centra en servidores; las aplicaciones Web también pueden tener fallos aprovechables (como seguridad débil frente a ataques XSS, CSRF o fallas en autenticación). En definitiva, el análisis de vulnerabilidades se ajusta a la realidad del objetivo y los datos arrojados por el scanning del objetivo. 

#### 4 | Desarrollo de plan de ataque y herramientas de hacking
Una vez que se encuentran vulnerabilidades, es hora de idear el plan de ataque y conseguir todo lo necesario para realizar el ataque de forma exitosa. 

En este punto, el hacker decide la hora y fecha del ataque y prepara todas las herramientas necesarias para acceder al sistema, conseguir la información y, de ser posible, pasar totalmente desapercibido y mantener el acceso al sistema para seguir obteniendo información. 

#### 5 | Ataque
Finalmente, durante el ataque se realiza la explotación de las vulnerabilidades detectadas, se logra el objetivo de acceder al sistema y escalar privilegios para obtener toda la información deseada. 

En este punto, dependiendo del nivel de acceso y la forma en cómo funciona la red, se pueden acceder a servicios adicionales, que pudieron o no detectarse durante los análisis iniciales. En este punto, si es posible atacarlos de la misma forma, se realiza el ataque; y si no se puede, se planifica su ataque posterior. 

#### 6 | Post-ataque
El objetivo de los hackers una vez realizado el ataque es:
1. **Mantener el acceso al sistema.** Generalmente, esto lo hacen por medio de programas ocultos que les garanticen dicho acceso cuando lo desee.
2. **Indicar que han tenido acceso y pedir una suma de dinero por no revelar la información,** especialmente si dicha información podría darle a la competencia ventaja sobre sus productos y servicios.

En todo caso, el post-ataque dependerá de las intenciones finales del hacker y lo que busca lograr con su ataque a la plataforma.

### Seguridad en Email
Los servidores de correo o email servers, son uno de los vectores de ataque más usado hoy en día por los ciberdelincuentes.

Frente a esta realidad, uno de los puntos a fortificar en las empresas son estos servicios. Especialmente porque dichos correos son los que permiten a los empleados, clientes y proveedores comunicarse con la empresa de forma rápida y segura.

Pero ¿Qué medidas de seguridad se pueden tomar para proteger los servicios de email contra ataques de hacking? Pues bien, entre esas opciones podemos mencionar:
1. Usar servidores seguros
2. End User Side Encryption
3. Conexiones seguras al servicio
4. Uso de DNSBL y URIBL para evitar el spam
5. SPF, DKIM y DMARC para verificar el origen y validez de los correos
6. Filtrado de contenido
7. Webmail Two Factor Authentication (2FA)

#### Medidas de seguridad
##### 1 | Usar servidores seguros
Los servicios de correo han mejorado mucho desde sus inicios y en la actualidad, la mayoría de los servidores de correo cuenta con potentes medidas de seguridad.

Por ejemplo, el servidor de correo Dovecot es considerado uno de los servidores de correo más potentes y extensibles que existen en la actualidad. Es un desarrollo de software libre ampliamente probado y bien desarrollado, que es usado por miles de empresas en todo el mundo.

Otras opciones equivalentes son **Cyrus IMAP** y **OpenSMTPD** (un proyecto en manos de la comunidad OpenBSD). Este último es el más interesante de todos, ya que en conjunto con un sistema OpenBSD correctamente configurado, OpenSMTPD se sostiene como el servidor de correo más seguro que existe en la comunidad, puesto que en toda su existencia solo ha tenido cinco problemas de seguridad (2008 hasta la actualidad) y ofrece soporte para cifrado, entre otras opciones de seguridad avanzadas. 

© 2 | End User Side Encryption
El uso de PGP/MIME y S/MIME permite a los usuarios de correo cifrar los correos de tal forma que solo el remitente y destinatario puedan leer la información del correo; y si un tercero tiene acceso a dicho correo, solo verá un conjunto de datos inteligible porque no tendrá en su poder las claves para descifrar dicho correo.  

Ambas medidas son efectivas porque en caso de que un hacker obtenga acceso al servidor de correos, este no podrá tener acceso a dicha información, y la razón es sencilla: el cifrado de los mensajes se da en el lado cliente, lo que imposibilita o lleva a un nivel de dificultad enorme romper el cifrado que protege dichos correos. 

##### 3 | Conexiones seguras al servicio
Una de las medidas de seguridad que debes activar en este tipo de servicios es el uso de cifrado de conexiones (usando estándar TLS 1.2 o, TLS 1.3 en el mejor de los casos).

Al cifrar las conexiones con TLS, los mensajes enviados entre los usuarios y el servidor de correo son totalmente seguros y nadie podrá interceptarlos sin que salten las alarmas. Por supuesto, esta medida debe ser correctamente configurada, especialmente con la actualización y el buen manejo de los certificados de seguridad para que TLS funcione de forma correcta. 

Esto puede sonar muy complejo, pero la mayoría de los servidores de correo (como Dovecot u OpenSMTPD) pueden realizar esto de forma muy sencilla e incluso se puede automatizar usando servicios como Let’s Encrypt u otros servicios integrados que permiten realizar esta tarea con un par de clics si se tienen los permisos administrativos para ello. 

##### 4 | Uso de DNSBL y URIBL para evitar el spam
DNSBL es el acrónimo de “lista negra del sistema de nombres de dominio”, es una mejora de la lista de agujeros negros en tiempo real (RBL), un tipo de servicio que proporciona una lista negra de dominios y direcciones IP conocidos que tienen la reputación de ser una fuente de spam.

Normalmente, el software del servidor de correo puede configurarse para comprobar uno o varios de estos listados.

Un DNSBL es más un mecanismo de software que una lista específica. Existen muchas, que utilizan una amplia gama de criterios que pueden hacer que una dirección aparezca o no en la lista: listado de direcciones de máquinas que se utilizan para enviar spam, proveedores de servicios de Internet (ISP) conocidos por albergar spammers, etc.

Por su parte, el servicio URIBL es una lista de dominios detectados como emisores de spam, el cual complementa el potencial de protección de DNSBL. En conjunto, ambas medidas permiten que, si nuestro servidor recibe un correo proveniente de algún servidor dentro de estas listas o sus parámetros, simplemente se descarta, evitando que su contenido llegue a nuestros servidores. 

##### 5 | Uso de SPF, DKIM y DMARC para verificar el origen y validez de los correos
SPF (Sender Policy Framework) es una entrada TXT de DNS (un tipo de registro del tipo texto que contiene una cadena que es analizada por el servidor de correo para saber si puede o no recibir correos desde ese registro) que tiene una lista de servidores que deben ser considerados como autorizados para enviar correo en nombre de un dominio específico.

Al ser una entrada DNS puede considerarse como una forma de hacer cumplir el hecho de que la lista de entradas es de confianza para el dominio, ya que las únicas personas autorizadas a añadir o cambiar esa zona de dominio son los propietarios o administradores del mismo. 

Por su parte, DKIM (DomainKeys Identified Mail) es un método para verificar que el contenido de los mensajes es digno de confianza, mostrando que el contenido no fue modificado desde el momento en que el mensaje salió del servidor de correo inicial y hasta que llegó al destino. Esta capa adicional de consistencia se logra mediante el uso de un proceso estándar de firma de clave pública/privada. Como en el caso del SPF, los propietarios o administradores del dominio añaden un registro DNS que contiene la clave pública DKIM que será utilizada por los receptores para verificar que la firma DKIM del mensaje es correcta; y en el lado del remitente, el servidor utilizará la clave privada correspondiente a la clave pública presente en el registro DNS para firmar los mensajes de correo. 

Finalmente, DMARC (Domain-based Message Authentication, Reporting, and Conformance) es un protocolo que utiliza SPF y DKIM para determinar si el mensaje de correo electrónico es auténtico. En esencia, facilita a los ISP la tarea de evitar que terceros malintencionados realicen prácticas como la suplantación de dominios para suplantar la información privada de los usuarios. DMARC establece una política clara tanto sobre SPF como sobre DKIM y permite establecer una dirección que debe utilizarse para enviar informes sobre los mensajes de correo enviados por el servidor. Esta política debe ser utilizada por todos los servidores y clientes receptores.

##### 6 | Filtrado de contenido
Los filtros de contenido permiten escanear e inspeccionar los mensajes entrantes y salientes y tomar las medidas correspondientes en función de los resultados de forma automática.

Estos servicios escanean principalmente el contenido del mensaje de correo electrónico y deciden si el contenido coincide con los filtros de spam y bloquean el mensaje para que no llegue a la bandeja de entrada. Los escaneos también examinan los metadatos de las imágenes y las cabeceras, así como el contenido del texto del mensaje.

##### 7 | Webmail Two Factor Authentication (2FA)
Asegurarse de que sus cuentas de usuario son seguras, aunque probablemente esté usando SSL/TLS, es importante porque a veces las contraseñas de los usuarios no son las más fuertes.

En todo caso, recuerda que mantener políticas de contraseñas seguras y habilitar la autenticación de dos factores puede mejorar en gran medida la seguridad de la cuenta de cada usuario, y proteger sus datos de terceros malintencionados que de otro modo podrían tener acceso a su cuenta. Esto puede pasar porque pueden haber obtenido su contraseña de otro servicio que estaban utilizando que tenía una puerta trasera de seguridad.

#### Firewall
Un Firewall es un dispositivo de seguridad perimetral que se instala en la red y ofrece múltiples funciones de seguridad, entre ellas que pueden ser desplegadas por medios físicos (hardware Firewall) o virtuales. 

En todo caso, los Firewall tienen la capacidad de realizar gran cantidad de tareas, entre las que podemos mencionar: 
1. **Routing avanzado de tráfico (RIP, OSPF, BGP),** con el fin de ajustar el tráfico de la empresa, su origen y funciones dentro de la red.
2. **Permitir el acceso a segmentos de la red o aplicaciones teniendo en cuenta el origen de la conexión,** usando desde direcciones IP específicas pasando por MAC address (direcciones físicas de equipos) o una combinación de ambas. 
3. **Detectar actividad anormal en la red (como ataques de DDoS, scanning y pentesting, hasta actividad de malware)** y detener dicha actividad dentro de la red, evitando la propagación o el éxito de dichas actividades. 
4. **Control de navegación y acceso a contenidos.** Los Firewall son una buena herramienta para ejercer reglas duras de acceso a ciertas Webs o contenidos (haciendo shapping o QoS) limitando el acceso a los mismos en determinadas franjas horarias o simplemente negando el acceso a dichos recursos. Generalmente, este tipo de funciones se acompañan de otras soluciones como lo son _HTTPS Proxy Web_ (para filtrado HTTPS transparente), DNS filtrados a nivel interno por la empresa (de manera que solo pueden acceder a aquellos elementos que la empresa haya dado aprobación previa) y un enforce para usar los DNS de la empresa y prohibir el acceso a servicios que puedan traspasar esas medidas de seguridad (como el uso de Tor u otras herramientas de privacidad). 
5. **Otro uso de los Firewall es ser servidor de concentrador de acceso.** Por ejemplo, si queremos que todos los empleados de una empresa en un área remota dispuesta se conecten a servicios internos de la empresa, generalmente se enruta todo el tráfico de la red (a la que solo pueden acceder los empleados) a una VPN y el encargado de ese enrutamiento es el Firewall. De esta forma, toda conexión dentro de la red es llevada por el Firewall al VPN (del espacio remoto) y el VPN establece conexión con el VPN de la empresa (interno), dando acceso a los recursos y manteniendo la seguridad en todo momento. 
6. **En redes de múltiple nivel (por ejemplo, redes internas, DMZ y redes WiFi para empleados y públicas),** el firewall se hace esencial para manejar este tipo de arreglos. Por un lado, garantiza que solo aquellos autorizados por sus reglas tengan acceso a las redes internas (alejando toda conexión que no respete el origen esperado), a la vez que permite acceso público a los servicios que están en la DMZ (Zona Desmilitarizada o Zona de conexión pública a Internet). Al mismo tiempo, es capaz de delimitar el acceso WiFi para empleados (haciendo uso de MAC address) y crear un “walled garden” para uso de visitantes o cualquier persona que requiera un acceso discreto y controlado por algún motivo. 
7. **Soporte de alta disponibilidad.** Si la empresa ejecuta varios servidores y conexiones para mantener servicios disponibles en todo momento, entonces el Firewall es la herramienta para ello. Un Firewall junto con un watchdog (vigilante) pueden detectar, por ejemplo, la caída de una conexión o servidor y ejecutar de forma automática un switch de tráfico, redirigiendo el mismo a un servidor réplica para mantener el servicio. En caso de conexiones a Internet, un firewall puede hacer bonding, shapping o balancing con el fin de optimizar y maximizar el uso de esas conexiones brindando acceso a esos recursos en todo momento.

En el mundo empresarial existen varios Firewall, algunos de ellos son gratuitos y tienen un nivel de calidad y funcionalidad enorme. Pero también existen soluciones comerciales que facilitan enormemente el despliegue de este tipo de instalaciones.

Por ejemplo, **iptables** y **nft**, son dos Firewall muy conocidos en el mundo GNU/Linux porque ambos forman parte integral de toda distribución actual ya que vienen integrados al kernel Linux. Ambas soluciones son gratuitas y son en extremo potentes (pero complejas) permitiendo poner en práctica todo lo que hemos mencionado. 

Otro buen ejemplo es **pfSense** y **OPNSense**. Ambos están basados en una implementación de pf (el Firewall de OpenBSD) sobre el sistema operativo (FreeBSD), por lo que carece de algunas funciones que sí están disponibles en OpenBSD. Sin embargo, pf es considerado uno de los Firewall empresariales más completos, especialmente porque pf ofrece soporte para Layer 7 (en el sistema OSI, Layer 7 se refiere a protocolos de alto nivel o de aplicación, como por ejemplo HTTP/ HTTPS o protocolos como BitTorrent). 

Esto significa que pf permite filtrar direcciones URL, acceso a redes P2P o cualquier protocolo de aplicación sin tener que definir reglas en extremo complejas para ello, algo que iptables y NFT no pueden hacer (al menos no de forma directa). Adicional, pfSense y OPNSense ofrecen versiones comunitarias y pagas de su software, incluyendo soluciones especializadas en hardware listas para ser desplegadas en empresas.

![[409_B7_opn.png]]

##### Control de acceso a la red
Las soluciones NAC o _Network Access Control_ permiten definir políticas que deben cumplir todos los dispositivos antes de conectarse a la red corporativa.

Los dispositivos (fijos y móviles) que no cumplen las políticas establecidas no podrán interactuar con la red. De esta forma aislamos estos dispositivos de forma preventiva hasta la resolución del incumplimiento.

Las soluciones NAC son complementarias a los Firewall, debido a que, una vez traspasada la barrera de seguridad perimetral, el NAC actúa como un control de acceso propio del dispositivo a la red. De este modo se dispone de un control de todos los elementos que acceden a la red independientemente de su naturaleza y detección en tiempo real.

##### Prevención de fuga de datos (dATA lEAK pROTECTION – dlp)
Un DLP es una herramienta que tiene como finalidad prevenir las fugas de información cuyo origen está dentro de la propia organización, de una manera activa y sin perder productividad. 

Estas herramientas suelen incorporar inteligencia artificial que les permite aprender sobre el tipo de documentos confidenciales que se utilizan y qué acciones llevan a cabo los usuarios sobre los mismos, para volverse cada vez más efectivas en la prevención de fugas de información.

Los DLP monitorizan la red de la organización para evitar las fugas de información antes de que se lleguen a producir. Una vez que detectan una posible fuga, alertan al usuario para que sea consciente de que la acción que está realizando atenta contra la confidencialidad de la empresa o contra una política de seguridad que vela por ella. Estas acciones tienen como objetivo concienciar a los miembros de la organización.

La monitorización de recursos por parte de un DLP no se limita exclusivamente a la red interna de la organización, ya que estas herramientas son capaces de extender su supervisión a dispositivos móviles, tanto Android como iOS. Los DLP son capaces de comprobar a qué correos corporativos se ha accedido. Además, tienen capacidad de comprobar y detener la transmisión de datos confidenciales desde la organización a aplicaciones de almacenamiento en la nube o redes sociales. Para que la implantación de un DLP en la organización sea lo más sencilla posible, incorporan plantillas preconfiguradas según distintas normas o estándares como el RGPD, LPI, LSSI o PCI-DSS.

Otras funciones destacables de estas herramientas son:
1. **Las políticas creadas se pueden aplicar de diferente manera, como por ejemplo:** por segmento de red, puerta de enlace, grupo de usuarios, etc. Cada organización podrá utilizar la que mejor se adapte a sus necesidades.
2. **La administración de estas herramientas se encuentra centralizada,** lo que permite una gestión más sencilla y ágil.
3. **Inspección de múltiples tipos de ficheros y protocolos** independientemente de que la información se transmita cifrada o no.
4. **Añaden marcas de agua,** tanto visibles como invisibles a los ficheros para que en caso de fuga de información se pueda identificar a su responsable.

Los DLP son un tipo de herramientas que pueden prevenir muchas fugas de información en cualquier empresa y, por consiguiente, la pérdida de reputación o incluso ser objeto de sanciones.

### Medidas para protegernos del hacking
¿Qué medidas podemos tomar para protegernos de los hackeos, no solo a nivel personal sino también empresarial, con el fin de proteger a nuestra empresa, sus productos y servicios, y lo más importante, la información y privacidad de nuestros clientes?.

#### ¿Qué es la Seguridad Defensiva?
El primer paso para protegernos de los hackeos es pensar en construir buenas defensas para nuestros sistemas. 

Es la rama de la ciberseguridad que tiene como finalidad proteger la organización bajo cualquier concepto: Desde el estudio de la red actual, hasta el completo bastionado de la infraestructura de red de la organización diseñando un plan de seguridad que permita garantizar la efectividad de los controles de seguridad desplegados.

##### Seguridad defensiva en el diseño de software
La seguridad defensiva es un diseño que se aplica en proyectos de informática (software o infraestructuras) desde sus bases. 

Por ejemplo, durante el diseño de una aplicación, los desarrolladores que aplican lineamientos de seguridad defensiva, diseñan su software pensando en la seguridad desde su más bajo nivel. No solo eso, sino que durante la producción el software es sometido repetidamente a análisis de seguridad y todo tipo de pruebas para intentar romperlo. 

En este punto, algunos esquemas o metodología de desarrollo seguro más usados en la industria son: 
1. **S-SDLC (Secure Software Development Life Cycle).** Se basa en verificar los requisitos de seguridad a lo largo de las distintas fases de construcción del software: análisis, diseño, desarrollo, pruebas y mantenimiento. Sobre todo, durante las dos primeras, ya que gran parte de las debilidades de los sistemas se generan incluso antes de comenzar las tareas de programación. Las claves del S-SDLC son la atención al detalle, para favorecer la identificación inmediata de las vulnerabilidades y la mejora continua.
2. **CLASP (Comprehensive Lightweight Application Security Process).** Proyecto del OWASP que establece una serie de actividades, roles y buenas prácticas dirigidas a coordinar los procesos de desarrollo seguro de software. La organización OWASP CLASP se asienta en cinco perspectivas o vistas que abordan los conceptos generales de esta metodología, la distribución de funciones, la valoración de las actividades aplicables, la implementación de estas actividades y el listado de problemas que pueden dar lugar a la aparición de vulnerabilidades.
3. **SSDF (Secure Software Development Framework).** Iniciativa del NIST (National Institute of Standards and Technology de Estados Unidos), provee indicaciones para enseñar a la organización acerca de la importancia de la seguridad informática: proteger el software de uso habitual ante hipotéticos ataques, orquestar un desarrollo seguro de software y detectar y solucionar con rapidez cualquier vulnerabilidad.

##### Endpoint
Un Endpoint es un software especializado que permite asegurar una infraestructura empresarial contra nuevas amenazas, incluso aquellas que son completamente nuevas y no detectadas hasta entonces, las cuales son conocidas como Amenazas Persistentes Avanzadas (APTs). 

- Generalmente, los Endpoint son instalados en computadoras, portátiles o celulares empresariales, con el fin de rastrear la actividad de los mismos y mantenerlos seguros. 
- El término Endpoint también se usa para describir los equipos que serán finalmente usados por las personas dentro de una empresa, siendo el software que los protege (antivirus u otras soluciones) denominados _Endpoint Security Software_. Normalmente, las soluciones Endpoint empresariales se encuentran integradas, permitiendo la instalación del software en cada cliente dentro de la empresa y estando conectado a un servicio central usado para monitorizar todo lo que sucede en dicho equipo.
- Debido a su papel en la seguridad de los sistemas, los Endpoint suelen ser un punto de ataque que los hackers buscan explotar. Después de todo, hacer caer el Endpoint o traspasar su seguridad, le permite al atacante pasar desapercibido en sus ataques a las empresas y todos los equipos dentro de la misma. De hecho, según datos Ponemon Institute, el 68% de las vulneraciones de datos comienzan en los Endpoint, dejando claro que incluso el software de ciberseguridad más especializado puede fallar. 
- Pese a este alto número de vulnerabilidades que se inician en los Endpoint, son también estas protecciones las que permiten detectar la mayoría de los ataques que se registran en las empresas hasta un 77% de las ocasiones en las que se originan. 
- Si bien puede parecer un número no muy alto, teniendo en cuenta que la empresa FireEye, especialista en ciberseguridad maneja una cifra de unos 219.000.000 millones de ciberataques en promedio durante el año 2021, el 77% de los ataques equivale a 168.630.000 ataques detectados por soluciones Endpoint, dejando el resto pasar desapercibidos teniendo que ser detenidos por las siguientes barreras de seguridad de la empresa o de tu computador personal. 

##### Antivirus, Firewalls y Endpoint | Diferencias
Es necesario conocer las diferencias entre antivirus, _firewall_ y Endpoint. 

Generalmente, el software antivirus y _firewall_ son elementos de protección de los Endpoint (vistos como equipos clientes), porque estos softwares (antivirus y firewalls) ofrecen protección a los mismos, permitiendo. 

**Sin embargo, un Endpoint Security Software, generalmente es una suite completa de soluciones de seguridad que incluye:** Antivirus, anti-malware, sistema de gestión de permisos y programas, sistema de administración remota de equipos, sistema de logging avanzado, integración AD, LDAP, Exchange, o suites como GSuite y Office365, entre otras soluciones especializadas diseñadas por las empresas para casos de uso muy específicos a nivel empresarial. 

> Los Endpoint Security Software, son soluciones completas de seguridad, con capacidades avanzadas de detección y respuestas intuitivas que ayudan a las organizaciones a tener un control total de su seguridad.

###### Beneficios de los Endpoint
Algunos de los beneficios principales a implementar este tipo de software son:
1. Proporcionar un sistema integral para prevenir, detectar y corregir de forma proactiva los ataques de malware evasivos.
2. Crear funciones de puntos extremos maduros para protegerte contra ataques cibernéticos conocidos y desconocidos.
3. Utilizar las prácticas recomendadas de la industria que aumentan la seguridad de los puntos extremos para combatir los ataques dirigidos y evasivos.
4. Reconocer las altas tasas de captura y los bajos falsos positivos garantizan la eficacia en la seguridad eficiente y una prevención oportuna.
5. Tener un análisis automatizado de datos forenses ofrecerá información detallada sobre las próximas amenazas.
6. La contención total de los ataques y su remedio restauran rápidamente cualquier sistema infectado.
7. Tener una arquitectura que esté diseñada para resolver las complejidades de la creciente conectividad y la ineficiencia de la seguridad brindaría protección sin precedentes contra mega ciberataques de quinta generación en las redes, Endpoint, la nube y los dispositivos móviles.

### Principios de la ciberseguridad
![[411.B7_objetivos.png]]

Conocida como CIA (_Confidentiality, Integrity and Availability_ - Confidencialidad, Integridad y Disponibilidad) estos principios son las bases para la construcción de las políticas de ciberseguridad que protegerán los datos de tu empresa o negocio.

1. **Confidencialidad de la información:** También conocida como privacidad, hace referencia a que la información solo debe ser conocida por las personas que necesitan conocerla y que han sido autorizadas para ello. Este principio asegura que la información no va a ser divulgada de manera fortuita o intencionada.
2. **Integridad de la información:** Hace referencia a que la información que se encuentra almacenada en los dispositivos o la que se ha transmitido por cualquier canal de comunicación no ha sido manipulada por terceros de manera malintencionada. Esto garantiza que la información no será modificada por personas no autorizadas.
3. **Disponibilidad de la información:** Se refiere a que la información debe estar disponible siempre para las personas autorizadas para accederla y tratarla, y además puede recuperarse en caso de que ocurra un incidente de seguridad que cause su pérdida o corrupción. Es decir: permite que la información esté disponible cuando sea necesario.

 Algunas de las principales buenas prácticas que garantizan el cumplimiento de los tres principios fundamentales de la seguridad de la información son las que se comentan a continuación:
1. **Política de mínimos privilegios:** Las personas de una organización no deberían acceder a toda la información de esta, solo a aquella que sea de utilidad e importante para la ejecución de su trabajo. Aplicando efectivamente una política de gestión de privilegios de los usuarios, estamos minimizando los riesgos de fugas de información, manipulación no autorizada de la misma, etc. y minimizando la superficie de ataque de nuestra organización.
2. **Política de control de acceso cerrado por defecto:** Todos los accesos a la información y los sistemas que la tratan o almacenan deberían estar cerrados para todos los usuarios y se permitirá solo para aquellos que estén autorizados para acceder.
3. **Segregación de funciones:** Se debería definir e implementar una separación efectiva de las funciones y responsabilidades del personal de las organizaciones para evitar conflictos de intereses y minimizar los riesgos de seguridad de la información derivados de la acumulación de privilegios y conocimiento en las personas.
4. **Defensa en profundidad:** Ante la gran cantidad de riesgos para la seguridad de la información a la que están expuestas las organizaciones (derivadas de la utilización y dependencia de las TIC) cada vez la superficie de ataque de estas es mayor, por lo que sería necesario diseñar e implementar varios niveles de seguridad acorde a un análisis de riesgos riguroso de sus activos de TIC.
5. **Formación en ciberseguridad:** El eslabón más débil de la seguridad de la información de una compañía son las personas. La mayoría de los incidentes de seguridad que sufren las organizaciones están originados por personal interno de manera no intencionada o fortuita y derivados de su desconocimiento de las mejores prácticas de ciberseguridad o de las políticas y procedimientos a tal efecto de la organización. Por eso, es fundamental definir e implementar planes formativos en seguridad informática para todo el personal de la compañía y acorde a sus funciones y responsabilidades.
6. **Auditorías de seguridad informática:** Es recomendable realizar controles de auditoría donde se verifique la efectividad y el cumplimiento de las políticas, procedimientos, medidas técnicas y organizativas de la seguridad de la información de la organización y que permitan detectar debilidades y/o vulnerabilidades que puedan ser explotadas por potenciales atacantes. Basándonos en los resultados de las mismas, se deberían diseñar y poner en marcha planes de acción correctivos para solucionar los hallazgos detectados durante las mismas.  

#### ¿Qué es la Seguridad Ofensiva?
La ciberseguridad es un concepto muy amplio que engloba muchas disciplinas como pueden ser la Criptografía, Ciberinteligencia, el Análisis de Malware o el Reversing. Debido a la transformación digital y a la especialización de los ciberdelincuentes, la seguridad informática no deja de crecer y expandirse y por ello nacen nuevas técnicas como la Seguridad Ofensiva.

Debido a los múltiples ciberataques recibidos, las empresas han cambiado el chip en lo que se refiere a la forma de afrontar la seguridad de la información. Ese es el motivo por el que han pasado de una seguridad reactiva a procesos en los que la propia organización debe ser proactiva e implementar medidas activas para defenderse. La Seguridad Ofensiva analiza el nivel de preparación que se tiene ante un ataque, sin embargo, no hay que olvidar que la seguridad pasiva y la seguridad activa son complementarias

La Seguridad Ofensiva o Seguridad Activa es un conjunto de herramientas o soluciones que tienen como objetivo identificar en tiempo real el grado de exposición que tiene una organización y cómo afectaría en cualquier incidente que se produjera.

Uno de los retos a los que se enfrentan las organizaciones es la demanda de nuevos perfiles tecnológicos que lleven a cabo este tipo de medidas. Estos profesionales reúnen información para prevenir futuros ataques y para ello se sirven del conocimiento y la experiencia sobre el entorno externo y las redes internas.

#### Análisis de Vulnerabilidades
Este tipo de auditoría tiene como objetivo evaluar las debilidades que puedan existir en un determinado sistema, aplicación o software que pudiera afectar a su integridad durante su vida útil.

Con este servicio se determina el nivel de seguridad en el que se encuentra la empresa y cómo puede llegar a afectar estas vulnerabilidades a la continuidad de negocio.

El análisis variará dependiendo del entorno donde realicemos las pruebas.

1. **I****nterno:** El análisis de Vulnerabilidades interno, es el que se realiza desde la red interna del cliente, su propia intranet, en sus oficinas o mediante una VPN.
2. **Externo:** El análisis de Vulnerabilidades externo, es el que se realiza desde el exterior de la red, desde internet.

#### Pentesting
El Pentesting está enfocado a la realización de pruebas de penetración, atacando a los sistemas de información o a la propia organización. 

Estas pruebas tienen la finalidad de descubrir cualquier tipo de vulnerabilidad que pudiera afectar al entorno y tener las bases que permitan prevenir este tipo de ataques.

Para la realización de este tipo de auditorías, nos apoyamos en metodologías entre las que destacamos OWASP, OWASP Mobile, OWISAM, OpenSAMM, OSSTMM, OSINT, entre otras. Adicionalmente, nos basamos en el framework CVSS (_Common Vulnerability Scoring System_ – Sistema común de puntuación de vulnerabilidad) con el que establecemos las métricas de las características, impacto y severidad de las vulnerabilidades detectadas.

#### Bug Bounty y el hacking ético
Cuando hablamos de realizar un “Hacking ético” nos referimos a realizar un Pentesting que abarca absolutamente todo. 

Dicho de otro modo, no hay un objetivo determinado, todo es explotable y no hay limitación más allá de la pactada con el cliente para la realización de las pruebas, en la que se pueden excluir algún tipo de pruebas. 

- En ejercicios de este tipo se simula el comportamiento de un ataque real realizado por un grupo cibercriminal que tiene el objetivo de comprometer la organización en su totalidad haciendo uso de técnicas propias de bandas cibercriminales organizadas.
- Este tipo de pruebas son las que están más a la vanguardia en cuanto a seguridad ofensiva, haciendo uso de vectores de ataque poco conocidos o incluso diseñando nuevos vectores para poner a prueba las defensas de las mejores organizaciones.
- La duración de estos ejercicios suele variar entre unas pocas semanas y varios meses y son pactados en el alcance del proyecto. En resumidas cuentas: un Hacking ético aporta el mayor valor para el cliente en cuestiones de auditoría de seguridad técnica, teniendo como objetivo la toma del control de la organización bajo cualquier concepto e incluso persistiendo en la red hasta la finalización del ejercicio.
- Mientras, un programa de Bug Bounty es un “contrato” que una empresa u organización hace con una comunidad de hackers éticos con el fin de que estos detecten vulnerabilidades en los sistemas y redes de dicha empresa. Un hacker ético es una persona que usa sus conocimientos avanzados en informática para hacer el bien. Su trabajo consiste en realizar pruebas en sistemas y redes con el fin de detectar vulnerabilidades que, a su vez, son reportadas para que las empresas tomen las medidas necesarias y eviten futuros ataques.
- Estos programas generalmente se llevan a cabo para ejecutar los servicios de revisión de aplicaciones, pruebas de penetración, revisión de código, ingeniería inversa, entre otros y por lo general se llevan a cabo antes de que la versión final salga al público.

### Herramientas para Hacking y Pentesting
Existen una gran variedad de herramientas de hacking y Pentesting que pueden ayudarnos a tener una buena seguridad defensiva (probando que nuestras defensas realmente hagan su trabajo) y ofensiva (tratando de romper o detectar fallos en nuestros sistemas antes que terceros lo hagan).

El hacking en este punto es amplio, muy amplio. Las herramientas existentes se mejoran, forkean y generan nuevas herramientas más potentes todo el tiempo. 

Sin embargo, hay ciertas herramientas básicas que todo hacker y Pentesting debe tener en cuenta en sus labores de ciberseguridad y entre ellas podemos mencionar: 
1. OWASP ZAP (Zed Attack Proxy)
2. Fiddler
3. Burp Suite
4. Nmap
5. Nikto
6. OpenVAS
7. Metasploit

#### 1 | OWASP ZAP (Zed Attack Proxy)
Zed Attack Proxy (ZAP) es una herramienta de pruebas de penetración gratuita y de código abierto que se mantiene bajo el paraguas del Open Web Application Security Project (OWASP).

ZAP está diseñado específicamente para probar aplicaciones web y es flexible y extensible. 

En su esencia, ZAP es lo que se conoce como un "MITM proxy". Es decir, una herramienta que se interpone entre el navegador de la persona que realiza la prueba y la aplicación web, de modo que puede interceptar e inspeccionar los mensajes enviados entre el navegador y la aplicación web, modificar el contenido si es necesario, y luego reenviar esos paquetes al destino. De esta manera, ZAP abre la puerta para que podamos examinar la seguridad de una aplicación Web y en caso de detectar un fallo, explotarlo para saber su alcance e informar del mismo para repararlo. 

![[412.B7_owasp.png]]

Puedes descargar la herramienta y leer toda su documentación desde su sitio [web](https://www.zaproxy.org/). 

#### 2 | Fiddler
Fiddler es otra solución muy parecida a ZAP que es capaz de realizar un MITM para escuchar conexiones del tipo HTTP/HTTPS y todo el contenido de esa conexión, permitiendo el debug y prueba de aplicaciones Web (incluyendo aplicaciones de escritorio con conexión a Internet).

Fiddler es parte de Telerik una empresa con amplia trayectoria en el campo del desarrollo web que tiene a su disposición un enorme conjunto de herramientas de desarrollo y ciberseguridad para aplicaciones desktop (multiplataforma) y Web.

![[412.B7_Fiddler.png]]

#### 3 | Burp Suite
Burp Suite es otra conocida suite de análisis y Pentesting para aplicaciones web que viene tanto en versión paga como gratuita (con algunas opciones inhabilitadas).

Burp Suite es una poderosa herramienta, con una amplia diversidad de características, siendo ampliamente aceptada por la comunidad hacktivista.

![[412.B7_Burp.png]]

#### 4 | Nmap
Parte del trabajo de los hackers es escanear el objetivo para reconocer su sistema y los servicios que ejecuta, y una herramienta perfecta para eso es Nmap.

Nmap es un software capaz de analizar puertos, servicios, indicar posibles vulnerabilidades y el sistema operativo que ejecuta todos esos servicios, con el fin de proporcionar inteligencia al hacker para realizar su ataque. De allí, que Nmap se considere una “navaja suiza” para los hackers, especialmente por su enorme poder, su capacidad para traspasar defensas (como firewalls) y brindar información útil. 

![[412.B7_Nmap.png]]  

#### 5 | Nikto
Nikto es un escáner de vulnerabilidades en servidores web en busca de múltiples elementos, incluidos archivos y programas peligrosos y busca versiones desactualizadas del software del servidor web. 

También comprueba si hay errores de configuración del servidor y las posibles vulnerabilidades que puedan haber introducido.

![[412.B7_Nikto.png]]  

Entre las principales características de Nikto se pueden mencionar: 
1. **Es de uso gratuito,** de código abierto y se actualiza con frecuencia.
2. **Se puede utilizar para escanear cualquier servidor web** (Apache, Nginx, Lighttpd, Litespeed, etc.).
3. **Escanea una gran cantidad de vulnerabilidades conocidas** (más de 6700 vulnerabilidades conocidas) y realiza verificaciones de versión para más de 1250 servidores web (y contando).
4. **Analiza en busca de problemas relacionados con la configuración,** como directorios de índice abiertos.
5. **Escaneo de certificados SSL.**
6. **Capacidad para escanear varios puertos** en un servidor con varios servidores web en ejecución.
7. **Opción de escanear a través de un proxy** y con autenticación http.
8. **Capacidad para especificar el tiempo máximo de escaneo,** excluir ciertos tipos de escaneos y también se ven encabezados de informes inusuales.  

#### 6 | OpenVAS
OpenVAS es un escáner de vulnerabilidad con todas las funciones. Sus capacidades incluyen pruebas no autenticadas y autenticadas, varios protocolos industriales y de Internet de alto y bajo nivel, ajuste de rendimiento para escaneos a gran escala y un potente lenguaje de programación interno para implementar cualquier tipo de prueba de vulnerabilidad.

El escáner obtiene las pruebas para detectar vulnerabilidades de un feed que tiene un largo historial y actualizaciones diarias.

OpenVAS ha sido desarrollado e impulsado por la empresa Greenbone Networks desde 2006. Como parte de la familia de productos comerciales de gestión de vulnerabilidades Greenbone Enterprise Appliance, el escáner forma el Greenbone Vulnerability Management junto con otros módulos Open Source.

![[412.B7_OpenVAS.png]] 

#### 7 | Metasploit
Metasploit es un proyecto de seguridad informática que proporciona información sobre las vulnerabilidades de seguridad y ayuda en las pruebas de penetración y el desarrollo de firmas IDS.

Es propiedad de la empresa de seguridad Rapid7, con sede en Boston, Massachusetts. Su sub-proyecto más conocido es el Metasploit Framework de código abierto, una herramienta para desarrollar y ejecutar código de explotación contra una máquina remota. 

Otros sub-proyectos importantes son la base de datos de opcodes, el archivo de shellcodes y la investigación relacionada. El proyecto Metasploit incluye herramientas antiforenses y de evasión, algunas de las cuales están integradas en el Metasploit Framework. Metasploit está preinstalado en el sistema operativo Kali Linux y Parrot, como parte de sus herramientas de Pentesting y vulneración de sistemas. 

![[412.B7_Metasploit.png]]

### Tipos y Tecnologías de Hacking (Video)
![[413.B7_Tipos_y_Tecnologías_de_Hacking.mp4]]
[Tipos y Tecnologias de Hacking](https://app.web3mba.io?wvideo=5ssafyxnqx)

Las tecnologías, herramientas, productos y servicios impulsados por Internet han transformado la forma en que solíamos trabajar y vivir. Han simplificado nuestras vidas y aumentado la comodidad en todos los aspectos, ya sea en los negocios o en la vida personal. Sin embargo, la tecnología también ha presentado muchas preocupaciones y riesgos de ciberseguridad que pueden afectar ambas esferas de nuestras vidas. Muchas empresas han sufrido pérdidas millonarias, junto con la confianza de sus clientes y la reputación de la industria. Del mismo modo, las personas han estado bajo amenaza debido a delitos y amenazas como resultado de la exposición de datos personales.

Los hackers y los métodos de piratería están evolucionando, ya que muchos de ellos son profesionales calificados. Algunos utilizan sus habilidades para cometer delitos, mientras que otros son contratados por organizaciones para combatir a los malos piratas informáticos. Si deseas protegerte a ti mismo y a tu negocio de hackers, es pertinente saber qué está sucediendo en la industria de la ciberseguridad y los tipos de hackers. Existen diferentes tipos de ataques. Uno de ellos es el phishing, que es un intento de los ciberdelincuentes de robar tu identidad y dinero a través de correos electrónicos. Los piratas informáticos te obligan a proporcionar tu información personal, incluidas las credenciales bancarias, contraseñas y detalles de tarjetas, entre otros.

Hay varios tipos de ataques de phishing, como el phishing de correo electrónico, el phishing de lanza, la caza de ballenas, smishing, vishing y phishing de pescadores. Un ataque de denegación de servicio se enfoca en una red o máquina para cerrarla y hacerla inaccesible para los usuarios finales. En este caso, los atacantes cibernéticos interrumpen la funcionalidad de un dispositivo al inundar la red o la máquina con solicitudes ilimitadas, de modo que el tráfico normal no pueda acceder a ella. Este tipo de ataque se puede caracterizar de dos maneras: el ataque de desbordamiento de búfer, que tiene como objetivo el tiempo de la CPU, el espacio del disco duro y la memoria, consumiéndolos todos para bloquear el sistema y afectar el comportamiento del servidor; y los ataques de inundación, que se dirigen a los servidores con una gran cantidad de paquetes de datos. El atacante sobresatura la capacidad del servidor, lo que resulta en una denegación de servicio.

Para que los ataques de inundación de denegación de servicio sean exitosos, el atacante debe tener más ancho de banda que la máquina objetivo. En los ataques de denegación de servicio, la inundación de tráfico proviene de varias fuentes. Este ataque es más crítico que el tradicional de denegación de servicio, ya que no se puede cerrar varias fuentes a la vez. La técnica de "bait and switch" es utilizada por los estafadores para robar datos personales y credenciales de inicio de sesión a través de anuncios y vías confiables. Engañan a los usuarios para que visiten ciertos sitios maliciosos y obtienen todos los detalles bajo las narices de los usuarios. Estos ataques se forman principalmente a partir del espacio publicitario que venden los sitios web. Una vez que los atacantes compran el espacio publicitario, reemplazan inmediatamente el anuncio con un enlace malicioso, lo que provoca el bloqueo del navegador y el compromiso de los sistemas.

El marketing de contenidos basado en Internet es el canal principal de los atacantes, quienes engañan a los usuarios para que abran enlaces que luego resultan ser maliciosos. El "cookie thief" o robo de cookies es una táctica de secuestro en la que un atacante obtiene acceso a la información del usuario. Aquí, un tercero copia los datos de la sesión no segura y los utiliza para hacerse pasar por el usuario. Generalmente, esto ocurre cuando un usuario visita sitios confiables a través de Wi-Fi públicos o una red desprotegida. Una vez que esto sucede, el atacante puede usar la información de la cuenta para publicar mensajes falsos, transferir dinero o realizar otras actividades maliciosas. Se puede prevenir si un usuario utiliza conexiones SSL para iniciar sesión y evita usar redes desprotegidas para acceder a los sitios.

Un virus es un programa de computadora que se conecta a otra computadora o programa de software para dañar el sistema. Los piratas informáticos insertan código en el programa y esperan hasta que alguien lo ejecute. De esta manera, se puede evitar que el usuario infecte otros programas en una computadora. Un troyano ejecuta un programa que dice ser inofensivo y útil, pero en realidad realiza acciones maliciosas, al igual que los caballos de Troya que fueron utilizados por los griegos para atacar a los enemigos por la noche. En lugar de apuntar a un sistema de software, el troyano se enfoca en la instalación de otro malware en el sistema, lo que resulta en engañar a los usuarios. Un gusano es un malware similar a un virus que ejecuta un payload malicioso y se autorreplica en los sistemas informáticos. La única diferencia radica en su técnica de propagación. Un virus necesita un programa huésped, mientras que un gusano vive en su propio programa de manera independiente. A veces, los gusanos se propagan por sí mismos sin ninguna interferencia humana.

Además, existe una variedad de otras amenazas maliciosas, como ransomware, adware, spyware, rootkits, bootkits y muchas más. El "clickjacking", conocido como ataque de reparación de interfaz de usuario, se dirige a los usuarios a través de múltiples capas opacas o transparentes para engañarlos. Una vez que un usuario hace clic en un botón o enlace sin saber que está haciendo clic en el botón equivocado, pierde su información en manos equivocadas. Supongamos que estás visitando un sitio web y te desplazas para comprobar la página. De repente, cuando vas a hacer clic en algún enlace, es posible que veas otros anuncios que te permiten hacer clic en ese enlace. Así es como funcionan los ataques de clickjacking. Por ejemplo, cuando visitas el sitio web www.wzyz.com y ves hojas de estilo o cuadros de texto en las páginas, obtendrás ofertas gratuitas y otras promociones que te atraerán a abrir el enlace. De esta manera, perderás tus credenciales de inicio de sesión y tu información personal.

El "fake WAP", o punto de acceso inalámbrico falso, es una técnica utilizada para conectar a muchos usuarios a la vez a través de un canal público. "Fake WAP" significa hacer lo mismo, pero falsificando la técnica. Aquí, un hacker suele elegir un lugar público donde haya Wi-Fi, como el aeropuerto, los centros comerciales y las cafeterías locales. A veces, configuran Wi-Fi para los usuarios que permiten el acceso gratuito y actúan como un ninja. En este caso, los usuarios proporcionan libremente toda su información durante el inicio de sesión en la cuenta de Wi-Fi y otros sitios web populares. De esta forma, también hackean tus cuentas de Facebook, Instagram, Twitter y otras.

El "keylogger", también llamado captura de teclado o registrador de pulsaciones de teclas, es una técnica utilizada para registrar cada pulsación de tecla en un dispositivo. También existe software que puede usarse en teléfonos inteligentes. Los piratas informáticos a menudo utilizan un registrador de teclas para robar credenciales de inicio de sesión, datos empresariales y más. En realidad, es un software que registra cada actividad, incluidos los clics del mouse. También encontrarás keyloggers de hardware, donde hay un dispositivo insertado entre la CPU y el teclado, que proporciona muchas funciones para capturar los registros. Los piratas informáticos utilizan esta técnica para acceder a tus números de cuenta, códigos PIN, ID de correo electrónico, contraseñas y otros datos confidenciales.

La escucha clandestina es una antigua amenaza de seguridad en la que un atacante escucha atentamente las comunicaciones de la red para obtener información privada, como actualizaciones de enrutamiento, datos de aplicaciones, números de identificación de nodos y más. El pirata informático utiliza los datos para comprometer los nodos al interrumpir el enrutamiento y degradar el rendimiento de las aplicaciones y las redes. Sus vectores incluyen correo electrónico, redes celulares y líneas telefónicas.

Los "waterhole attacks" son ataques informáticos que utilizan la red de comunicación para determinar la posibilidad de que una aplicación se desarrolle. El pirata informático observa o adivina los sitios web que una organización o individuo utiliza con frecuencia. Luego, los atacantes infectan esos sitios web a través de malware, y por lo tanto, algunos miembros se ven infectados con este ataque. Esta técnica es más difícil de detectar, ya que los piratas informáticos buscan una dirección IP específica para atacar y obtener la información que desean. El objetivo es apuntar al sistema del usuario y obtener acceso a los sitios web del objetivo.

Una inyección SQL o SQLI es un ataque en el que un atacante utiliza un código malicioso para manipular la base de datos. De esta manera, accede a la información que se mantiene segura en la base de datos de una organización. Interfieren con las consultas de las aplicaciones para ver datos, incluidos datos de usuarios, datos comerciales y más. Una vez que tienen acceso, pueden eliminar o modificar los datos, provocando cambios en el comportamiento de las aplicaciones. En algunos casos, el pirata informático obtiene derechos administrativos, lo que es más perjudicial para una organización. SQLI se dirige a aplicaciones web o sitios web que utilizan bases de datos, generalmente Oracle, SQL Server, MySQL y más. Este es el ataque más antiguo y peligroso, ya que, una vez que tiene éxito, permite a los piratas informáticos acceder a secretos comerciales, datos personales y propiedad intelectual de una empresa.

Los ataques de fuerza bruta son una forma sencilla de pirateo que se enfoca en métodos de prueba y error para descifrar contraseñas, claves cifradas, credenciales de inicio de sesión y más. Los atacantes analizan todos los casos posibles para obtener el correcto. Aquí, la fuerza bruta significa que los piratas informáticos utilizan intentos contundentes para forzar su camino hacia cuentas privadas. Este es un antiguo método de ataque, pero aún es popular y efectivo entre los piratas informáticos. Los piratas informáticos obtienen ganancias de los anuncios, roban datos privados, propagan su malware, secuestran sistemas para actividades maliciosas y arruinan la reputación de un sitio web o de una empresa. Hay diferentes tipos de ataques de fuerza bruta que los atacantes utilizan para obtener acceso. Algunos son ataques de fuerza bruta simples, ataques de diccionario, ataques híbridos de fuerza bruta, ataques de fuerza bruta inversa y relleno de credenciales.

El "DNS spoofing" es un ataque en el que un atacante utiliza registros DNS alternativos para redirigir el tráfico a un sitio malicioso. Por ejemplo, si eres nuevo en tu universidad y los estudiantes de último año cambian los números de las aulas, podrías terminar en el aula equivocada. Esto continúa sucediendo hasta que obtienes el directorio del campus correcto. La suplantación de DNS funciona de la misma manera. El pirata informático ingresa datos falsos en el caché para que las consultas de DNS devuelvan una respuesta incorrecta, lo que resulta en acceder a sitios web incorrectos. Este ataque se considera una amenaza cibernética engañosa.

El "cracking password", o descifrado de contraseñas, es la forma que utilizan los piratas informáticos para obtener credenciales de inicio de sesión. Un ataque de fuerza bruta también es una técnica de descifrado de contraseñas. En este caso, todas las contraseñas deben almacenarse con la función de derivación de clave (KDF). Si se almacenan como texto plano, el atacante que pirateó la base de datos obtiene toda la información de la cuenta. Utilizan varias técnicas para descifrar contraseñas, como phishing, malware, ataques de arcoíris, adivinanzas, búsqueda de diccionarios y más.

Para concluir, es fundamental estar siempre al día de las últimas vulnerabilidades, de los últimos ataques y, sobre todo, mantenerse siempre vigilantes.

### Tipos y tecnologías de hacking
La tecnología, las herramientas y los productos y servicios impulsados por Internet han transformado la forma en que solíamos trabajar y vivir.

Han simplificado nuestras vidas y aumentado la comodidad en todos los aspectos, ya sea en los negocios o en la vida personal. Sin embargo, la tecnología también ha presentado muchas preocupaciones y riesgos de ciberseguridad que pueden devastar ambas esferas de nuestras vidas.

Las empresas han sufrido pérdidas millonarias junto con la confianza de los clientes y la reputación de la industria. Del mismo modo, las personas han estado bajo terror debido a delitos y amenazas como resultado de la exposición de datos personales. Hackers y sus métodos de piratería están evolucionando, ya que también son profesionales calificados. Algunos usan sus habilidades para cometer delitos, mientras que otros son contratados por organizaciones para combatir a los malos piratas informáticos. 

Y si quieres protegerte de hacks a tí  y a tu negocio, es pertinente saber qué está pasando en la industria de la ciberseguridad y los tipos de hacks.

#### Diferentes tipos de hacks
1. Phishing
2. DoS and DDoS
3. Bait and Switch
4. Cookie Theft
5. Virus, Trojan, Malware
6. ClickJacking Attacks
7. Fake WAP
8. Keylogger
9. Eavesdropping
10. Waterhole Attacks
11. SQL Injection
12. Brute Force Attacks
13. DNS Spoofing (DNS Cache Poisoning)
14. Cracking Passwords

#### 1 | Phishing
El phishing es un intento de los ciberdelincuentes de robar su identidad y dinero a través de correos electrónicos. 

Los piratas informáticos le obligan a proporcionar su información personal, incluidas las credenciales bancarias, contraseñas, Detalles de tarjeta, etc.

Hay varios tipos de ataques de phishing: phishing de correo electrónico, phishing de lanza, caza de ballenas, smishing, vishingy phishing de pescadores. 

#### 2 | DoS and DDoS
Un ataque de denegación de servicio (DoS) se enfoca en una red o máquina para cerrarla y hacerla inaccesible para los usuarios finales.

Aquí, los atacantes cibernéticos interrumpen la funcionalidad de un dispositivo al inundar la red o la máquina con solicitudes ilimitadas para que el tráfico normal no pueda acceder a él.

En este punto se pueden caracterizas de dos maneras:
1. **Ataques de desbordamiento de búfer:** Este ataque tiene como objetivo el tiempo de la CPU, el espacio del disco duro y la memoria; los consume todos para bloquear el sistema y afectar el comportamiento del servidor.
2. **Bloody Attacks:** Este ataque se dirige a los servidores con una gran cantidad de paquetes de datos. El atacante sobresatura la capacidad del servidor, lo que resulta en DoS. Para que los ataques de inundación DoS sean exitosos, el atacante debe tener más ancho de banda que la máquina objetivo.

En los ataques DDoS, la inundación del tráfico proviene de varias fuentes. Este ataque es más crítico que DoS, ya que no puede cerrar varias fuentes a la vez. 

#### 3 | Bait and Switch
Bait and Switch es una técnica utilizada por los estafadores para robar datos personales y credenciales de inicio de sesión a través de anuncios y vías confiables.

Engañan a los usuarios para que visiten sitios maliciosos y toman todos los detalles debajo de las narices de los usuarios.  Estos ataques se forman principalmente a partir del espacio publicitario que venden los sitios web. Una vez que los atacantes compran el espacio publicitario, reemplazan inmediatamente el anuncio con un enlace malicioso, lo que provoca el bloqueo del navegador y el compromiso de los sistemas.  

El marketing de contenidos basado en Internet es el canal principal de los ataques en los que se engaña a los usuarios para que abran enlaces, que luego resultan ser maliciosos.

#### 4 | Cookie Theft
Cookie Theft o robo de galletas es una táctica de secuestro en la que un atacante obtiene acceso a la información del usuario.

Aquí, un tercero copia los datos de la sesión no segura y los usa para hacerse pasar por el usuario. Generalmente, ocurre cuando un usuario visita sitios confiables a través de Wi-Fi público o una red desprotegida.  Una vez que esto sucede, el atacante puede usar la información o la cuenta para publicar mensajes falsos, transferir dinero o hacer otras cosas maliciosas. 

Se puede prevenir si un usuario usa conexiones SSL para iniciar sesión y evita usar redes desprotegidas para acceder a los sitios. 

#### 5 | Virus, Trojan, Malware
Un virus es un programa de computadora que se conecta a otra computadora o programa de software para dañar el sistema.

Los piratas informáticos insertan código en el programa y esperan hasta que alguien ejecute el programa. De esta manera, infectan otros programas en una computadora. 

Un troyano ejecuta un programa que dice que es inofensivo y útil. En realidad, hace cosas maliciosas, al igual que el caballo de Troya fué utilizado por los griegos para atacar a los enemigos por la noche.  En lugar de apuntar a un sistema de software, el troyano apunta a la instalación de otro malware en el sistema, lo que resulta en engañar a los usuarios.

Un gusano es un malware similar a un virus. Ejecuta payload malicioso y se autorreplica en los sistemas informáticos. La única diferencia está en su técnica de esparcimiento. Un virus quiere un programa anfitrión, pero un gusano vive en su propio programa independiente. A veces se propagan por sí mismos, sin ninguna interferencia humana. 

Además, existe una variedad de otras amenazas maliciosas como ransomware, adware, spyware, rootkits, bots y mucho más.

#### 6 | ClickJacking Attacks
ClickJacking, que se conoce como ataque de reparación de la interfaz de usuario, se dirige a los usuarios a través de múltiples capas opacas o transparentes para engañarlos.

Una vez que un usuario hace clic en el botón o enlace sin saber que está haciendo clic en el botón equivocado, pierde su información en las manos equivocadas.

Suponga que está visitando un sitio web y se desplaza para comprobar la página. De repente, cuando vas a hacer clic en algún enlace, es posible que veas otros anuncios que te permiten hacer clic en ese enlace. Por lo tanto, los atacantes lo dirigen a otra página. Así funcionan los atacantes ClickJacking.

Por ejemplo, cuando visita el sitio web www.wyz.com y ve hojas de estilo o cuadros de texto en la página, obtendrá ofertas gratuitas y otras ofertas adecuadas que lo atraerán para abrir el enlace. De esta manera, perderás tus credenciales de inicio de sesión y tu información personal.

#### 7 | Fake WAP
El punto de acceso inalámbrico (WAP) es una técnica utilizada para conectar muchos usuarios a la vez a través de un canal público.

Fake WAP significa hacer lo mismo falsificando la técnica.  Aquí, un hacker suele elegir un lugar público donde haya Wi-Fi gratuito, como el aeropuerto, los centros comerciales y las cafeterías locales.

A veces configuran Wi-Fi para los usuarios que permiten el acceso gratuito y juegan como un ninja. En este caso, proporciona libremente toda su información durante el inicio de sesión en la cuenta Wi-Fi y otros sitios web populares. De esta forma, también hackean tus cuentas de Facebook, Instagram, Twitter y otras. 

#### 8 | Keylogger
Keylogger, también llamado captura de teclado o registrador de pulsaciones de teclas, es una técnica utilizada para registrar cada pulsación de tecla en un dispositivo o computadora. 

También tiene un software que puede usar en los smart phones. 

Los piratas informáticos a menudo usan un registrador de teclas para robar credenciales de inicio de sesión, datos empresariales confidenciales y más. En realidad, es un software que registra cada actividad, incluidos los clics del mouse. También encontrará keyloggers de hardware donde hay un dispositivo insertado entre la CPU y el teclado que proporciona muchas funciones para capturar los registros.  Los piratas informáticos utilizan esta técnica para acceder a sus números de cuenta, códigos PIN, ID de correo electrónico, contraseñas y otros datos confidenciales.

#### 9 | Eavesdropping
La escucha clandestina es una antigua amenaza de seguridad en la que un atacante escucha atentamente las comunicaciones de la red para obtener información privada, como actualizaciones de enrutamiento, datos de aplicaciones, números de identificación de nodos y mucho más.

El pirata informático utiliza los datos para comprometer los nodos al interrumpir el enrutamiento, degradar el rendimiento de las aplicaciones y las redes. Sus vectores incluyen correo electrónico, redes celulares y líneas telefónicas. 

#### 10 | Waterhole Attacks
Un waterhole es un ataque informático en el que un pirata informático observa o adivina los sitios web que una organización o individuo utiliza con frecuencia. 

Luego, los atacantes infectan esos sitios web a través de malware y, por lo tanto, algunos miembros también se infectan con este ataque.

Esta técnica es más difícil de detectar, ya que los piratas informáticos buscan una dirección IP específica para atacar y obtener información específica. El objetivo es apuntar al sistema del usuario y obtener acceso a los sitios web en el objetivo.

#### 11 | SQL Injection
Una inyección SQL (SQLi) es un ataque en el que un atacante utiliza un código malicioso para manipular la base de datos. 

De esta manera, acceden a la información que se mantiene segura en la base de datos de una organización. Interfieren con las consultas de la aplicación para ver datos, incluidos datos de usuarios, datos comerciales y más.

Una vez que tienen acceso, pueden eliminar los datos o modificarlos, provocando cambios en el comportamiento de las aplicaciones. En algunos casos, el pirata informático obtiene derechos administrativos, que son muy perjudiciales para una organización. 

SQLi se dirige a aplicaciones web o sitios web que usan bases de datos SQL como Oracle, SQL Server, MySQL y más. Este es el ataque más antiguo y peligroso, que una vez que tiene éxito, permite a los piratas informáticos acceder a secretos comerciales, datos personales y propiedad intelectual de una empresa.

#### 12 | Brute Force Attacks
A ataque de fuerza bruta es una forma fácil de piratear que se enfoca en métodos de prueba y error para descifrar contraseñas, claves de cifrado, credenciales de inicio de sesión y más.

Los atacantes analizan todos los casos posibles para obtener el correcto.

Aquí, la fuerza bruta significa que los piratas informáticos utilizan intentos contundentes para forzar su camino hacia cuentas privadas. Este es un antiguo método de ataque, pero aún es popular y efectivo entre los piratas informáticos. Los piratas informáticos obtienen ganancias de los anuncios, roban datos privados, propagan malware, secuestran su sistema para actividades maliciosas, arruinan la reputación del sitio web y más.

Hay diferentes tipos de fuerza bruta que los atacantes utilizan para obtener acceso. Algunos son simples ataques de fuerza bruta, ataques de diccionario, ataques híbridos de fuerza bruta, ataques de fuerza bruta inversa y relleno de credenciales. 

#### 13 | DNS Spoofing (DNS Cache Poisoning)
En esto, un atacante utiliza registros DNS alternativos para redirigir el tráfico a un sitio malicioso. 

1. Por ejemplo: eres nuevo en tu universidad y los estudiantes del último año han cambiado los números de las aulas.
2. Como consecuencia, terminas en el aula equivocada. Esto continúa sucediendo hasta que obtengas el directorio correcto del campus. 

La suplantación de DNS funciona de la misma forma. 

El pirata informático ingresa datos falsos en el caché para que las consultas de DNS le den una respuesta incorrecta, lo que resulta en ingresar a sitios web incorrectos. Este ataque viene bajo una amenaza cibernética engañosa. 

#### 14 | Cracking Passwords
Descifrar contraseñas es la forma que usan los piratas informáticos para obtener credenciales de inicio de sesión.

Un ataque de fuerza bruta también es una técnica de descifrado de contraseñas. En esto, todas las contraseñas deben almacenarse con la función de derivación de clave (KDF). Si se almacena como texto sin formato, el atacante que piratea la base de datos obtiene toda la información de la cuenta. 

Utilizan varias técnicas para descifrar contraseñas, como _phishing_, _malware_, ataques de arco iris, adivinanzas, búsqueda de diccionario y más.

## U7. Seguridad Defensiva
### Seguridad Defensiva (Video)
![[415.B7_Seguridad_Defensiva.mp4]]
[Seguridad Defensiva](https://app.web3mba.io?wvideo=lq04epc5gf)

¿Qué es el Security Operations Center o SOC? El SOC es el lugar donde se centralizan las amenazas que pueden provenir de diferentes áreas de la organización, de la tecnología o de la infraestructura tecnológica, para que un equipo especializado pueda determinar cuáles de ellas requieren una mayor atención y gestionar potenciales incidentes.

¿Por qué es tan importante tener un SOC? Porque hoy en día las alertas y los problemas de seguridad pueden llegar desde múltiples fuentes y lugares en la infraestructura tecnológica, así como desde diversas aplicaciones. En este contexto, podemos estar hablando de infraestructuras blockchain, de los servidores que las alojan, de los cloud que albergan estos servidores, de las redes, etcétera. Todas estas amenazas deben estar centralizadas en algún lugar del mundo para que un equipo especializado pueda determinar cuáles de ellas implican un riesgo que debe ser gestionado o un potencial incidente que debe ser mitigado y también gestionado.

La problemática radica en que hoy en día estos centros de operaciones de seguridad enfrentan una gran saturación debido a la cantidad de eventos de seguridad que todas las tecnologías dedicadas a esta actividad están generando. De hecho, como estadística, el 56% de los analistas afirman haber recibido más de 10 millones de amenazas al día, de las cuales la mitad recibieron incluso más de un millón de amenazas diarias. Estas estadísticas son bastante alarmantes. Además, el 52% de los analistas siente que su SOC tiene problemas para identificar qué incidentes son críticos y cuáles son simplemente ruido. El 30% de los encuestados admite que ha ignorado por completo ciertas categorías de alertas debido al ruido que generaban, y el 4% desactivó por completo las alertas durante un día entero para poder gestionar todas aquellas que ya habían recibido.

Bueno, y todas estas alertas de las que estoy hablando, ¿de dónde provienen? Pueden proceder de múltiples tecnologías dedicadas a la protección o a la provisión de recursos, como los firewalls que protegen las redes o las aplicaciones que, a su vez, están brindando un servicio a los usuarios. Todas ellas generan una serie de logs que pueden dar lugar a determinadas alertas de seguridad. Estas alertas pueden ser simplemente un aviso de que algo está ocurriendo de una manera determinada, o pueden ser un evento de seguridad que requiere ser tratado y gestionado posteriormente como un incidente.

Además, dentro de toda esta información que estamos recibiendo en un SOC, tenemos diferentes tipos de casos de uso que debemos gestionar de acuerdo con el tipo de negocio y las tecnologías que estamos proveyendo. Por ejemplo, no sería lo mismo una tecnología que se dedique simplemente a servir información con fines descriptivos o explicativos, que una tecnología que esté realizando transacciones. En el caso de una tecnología tipo blockchain, por ejemplo, que está llevando a cabo determinadas transacciones, se requiere un nivel de seguridad mucho más alto. Asimismo, una tecnología o un código que esté automatizando una serie de procesos requiere una monitorización extremadamente alta, que necesitará que un especialista analice de manera relativamente continua.

De hecho, otra característica habitual de los SOC es que operan en un formato 24x7. Idealmente, un SOC podría tener equipos en diferentes continentes, con diferentes zonas horarias, de manera que cuando un equipo ya no está trabajando, o cuando en un determinado país o zona horaria ya no es un horario razonable para estudiar estas alertas, otro equipo en otra ubicación pueda continuar con este análisis y gestionar los incidentes que se estén presentando.

Por poner algunos ejemplos adicionales, ¿qué tipo de cosas podemos monitorizar dentro del SOC? Por un lado, deben ser monitorizadas todas las aplicaciones, así como la interacción de los usuarios con estas aplicaciones. Si tenemos una determinada aplicación web o una aplicación móvil que está realizando una serie de operaciones, tendríamos que analizar todas aquellas alertas que provengan de la misma. Después, por debajo de estas aplicaciones, habrá una infraestructura que puede ser servidores, una infraestructura cloud, una infraestructura blockchain o varias capas de las que ya he mencionado. Toda esta infraestructura puede tener una serie de potenciales riesgos que deben ser continuamente analizados o monitorizados.

Debajo de estas infraestructuras, tendríamos las diferentes redes. Incluso dentro de un mismo cloud, por ejemplo, puede haber comunicación con numerosos sistemas diferentes, algunos dedicados simplemente a la transmisión de datos entre clientes, nodos y otros nodos, o entre servidores. Otros sistemas están dedicados a la protección de lo que estamos sirviendo en esta infraestructura. Por ejemplo, podríamos tener firewalls, sistemas de prevención de intrusiones (IPS), sistemas de protección cloud o de monitorización cloud, como los CASB, y también podríamos tener otras capas de sistemas que monitoreen toda esta infraestructura a diferentes niveles.

Otra característica que los SOC pueden tener es la automatización de la respuesta a incidentes, de manera que cuando algo sucede ya exista una respuesta predeterminada. Si, por ejemplo, un ataque ya se ha recibido anteriormente o un tipo de amenaza ya se conoce por ocasiones previas en las que se ha producido, podría automatizarse mediante playbooks o mediante otro elemento que se llama SOAR el tipo de respuesta que queremos dar a esa amenaza, para que no requiera un análisis adicional por parte de un analista humano. De esta manera, también podemos evitar lo que llamamos fatiga de alertas, que es cuando los analistas reciben tantas alertas dentro del SOC que no son capaces de gestionarlas con la misma velocidad que está funcionando el negocio o la interacción de los usuarios.

En conclusión, un SOC es un equipo de analistas y tecnologías dedicados a monitorizar una infraestructura tecnológica, una aplicación o cualquier servicio tecnológico que se esté ofreciendo a usuarios finales. Su función es discriminar dentro de esa monitorización qué son verdaderas amenazas, qué son falsos positivos o alertas que están generando solamente ruido, y además poder dar una respuesta temprana a los incidentes que están sucediendo. Idealmente, esta respuesta podría incluso estar automatizada mediante diferentes mecanismos, como los playbooks y SOAR.

Por ejemplo, el tipo de empresas que podrían ser propensas a este tipo de monitorización mediante un SOC serían aquellas que realizan transacciones, como una empresa de e-commerce, una empresa de pagos online o una empresa de blockchain y smart contracts, entre otras. ¿Por qué? Porque, además de poder sufrir una pérdida de servicio o una potencial fuga de información, pueden experimentar un daño económico en tiempo real. Quiero decir que, si no hay una monitorización continua de qué tipo de problemas o incidentes están sucediendo, en el tiempo medio en el que un analista de seguridad puede visualizar la alerta y determinar si es o no una potencial amenaza, el problema económico ya habría ocurrido y podría haber tenido un impacto que incluso podría suponer el cierre de la empresa o problemas financieros graves.

### Seguridad Defensiva
#### SOC | Security Operations Center
El SOC o Security Operations Center es el lugar donde se centralizan las amenazas que pueden venir desde diferentes lugares de la organización, de la tecnología o de la infraestructura tecnológica, para que un equipo especializado pueda determinar cuáles de ellas requieren de una mayor atención y pueda gestionar potenciales incidentes.

##### ¿Por qué es tan importante tener un SOC?
Hoy en día los problemas de seguridad nos pueden llegar:
1. Desde múltiples fuentes.
2. Desde múltiples lugares en la infraestructura tecnológica.
3. Desde múltiples aplicaciones.

- En este caso y en este entorno podríamos estar hablando de infraestructuras Blockchain, de los servidores que las alojan, de los clouds que alojan estos mismos servidores en las redes, etc. 
- Todas estas amenazas tienen que estar centralizadas en algún lugar para que un equipo especialista pueda determinar cuáles de ellas implican un riesgo que debe de ser gestionado o un potencial incidente que debe ser mitigado y también gestionado.
- La problemática viene porque, hoy en día, estos centros de operaciones de seguridad tienen una gran saturación debido a la gran cantidad de eventos de seguridad que todas las tecnologías dedicadas a esta actividad están generando.

> El 56% de los analistas afirman haber recibido más de 10 millones de amenazas al día, de los cuales la mitad recibieron incluso más de 1 millón de amenazas al día.

Estas estadísticas son bastante alarmantes. 

- Además, el 52% de los analistas sienten que su software tiene problemas para identificar qué incidentes son críticos y cuáles de ellos son solamente ruido. 
- El 30% de los encuestados, además, admiten haber ignorado por completo ciertas categorías de alertas por el ruido que les estaba generando. 
- Un 4% desactivaron por completo las alertas por un día entero para poder gestionar todas aquellas que ya habían recibido. 

##### Todas estas alertas ¿cuál es su origen?
Pueden proceder de múltiples tecnologías.Pueden dedicarse a la protección, a servir recursos como, por ejemplo, los Firewall que protegen las redes o las aplicaciones que a su vez están dando un servicio a los usuarios.

Todas ellas están salvando una serie de _logs_ que después pueden generar determinadas alertas de seguridad. Estas alertas, a su vez, puede ser solamente un aviso de que algo está de una determinada manera o puede ser un evento de seguridad que requiere ser tratado y requiere ser gestionado posteriormente como un incidente.  
  
Además, dentro de toda esta información que estamos recibiendo en un SOC, tenemos diferentes tipos de casos de uso que deberemos gestionar acorde al tipo de negocio y tipo de tecnologías que estamos proveyendo. 

Por ejemplo, ¿no sería igual una tecnología que se dedique simplemente a servir información con fines descriptivos, explicativos, etc. que una tecnología que está realizando transacciones? 

- En el caso de la tecnología Blockchain, por ejemplo, que está realizando determinadas transacciones, requiere de un nivel de seguridad mucho más alto. 
- Asimismo, una tecnología o un código, por ejemplo, que esté automatizando toda una serie de procesos requiere una monitorización extra que va a necesitar que un especialista analice de una manera relativamente continua. 

De hecho, otra característica habitual de los SOC es que tienen un formato de 24/7. En un escenario ideal, un SOC podría tener equipos en diferentes continentes con diferentes _timeshows_ (diferentes zonas horarias) de manera que cuando un equipo ya no está trabajando o cuando en determinado país o determinada zona horaria ya no es un horario razonable para poder atender estas alertas, otro equipo en otra ubicación puede continuar con este análisis y puede continuar gestionando los incidentes que se estén produciendo.  

##### ¿Qué tipo de cosas podemos monitorizar de dentro del SOC?
Deben de ser monitorizadas todas las aplicaciones, así como la interacción de los usuarios con ellas. 

- Si tenemos una determinada aplicación web o aplicación para móvil que está realizando una serie de operaciones, tendríamos que analizar todas aquellas alertas que procedan de la misma. 
- Por debajo de estas aplicaciones habrá una infraestructura: puede ser servidores, puede ser una infraestructura cloud, puede ser infraestructura Blockchain o puede haber varias capas de las que ya he mencionado. 
- Toda esta infraestructura, a su vez, puede tener una serie de potenciales riesgos que tienen que ser continuamente analizados o monitorizados. 
- Debajo de estas infraestructuras tendríamos las diferentes redes e incluso dentro de un mismo cloud, por ejemplo, puede haber comunicación con muchísimos sistemas diferentes, algunos dedicados simplemente a la transmisión de datos entre unos nodos y otros nodos, o unos servidores y otros servidores y otros dedicados a la protección de lo que estamos sirviendo en esta infraestructura. Por ejemplo, podríamos tener firewalls, podríamos tener y PS podríamos tener sistemas de protección cloud o de monitorización cloud como CASSB.
- Asimismo, podríamos tener otras capas de sistemas que monitorizan toda esta infraestructura a diferentes niveles. 

> Otra característica que los SOC pueden tener, es la de automatizar la respuesta a incidentes de manera que, cuando algo sucede, ya existe una respuesta predeterminada.

Si, por ejemplo, un ataque ya se ha recibido anteriormente o un tipo de amenaza, ya se conoce por ocasiones anteriores donde se haya producido. Podría automatizarse mediante _playbooks_ o mediante otro elemento que se llama SOAR. 

El tipo de respuesta que queremos dar a esa amenaza para que no requiera un análisis adicional por parte de un analista humano. De esta manera podemos también evitar lo que llamamos fatiga de alertas, que es cuando los analistas reciben tantas alertas dentro del SOC que no son capaces de gestionarla con la misma velocidad que está funcionando el negocio o que está funcionando la interacción de los usuarios o la gestión del servicio que se está proveyendo. 

En conclusión: El SOC es un equipo de analistas y de tecnologías dedicados a monitorizar una infraestructura tecnológica, una aplicación o cualquier servicio tecnológico que se pueda estar proveyendo a usuarios finales.

Discriminar dentro de esa monitorización que son verdaderas amenazas de que son falsos positivos o alertas que están generando solamente ruido y además poder dar una respuesta temprana a los incidentes que están sucediendo. 

Idealmente, esta respuesta podría incluso estar automatizada mediante diferentes mecanismos, como puedan ser los _Playbooks_ y _SOAR._ 

Por ejemplo, el tipo de empresas que podrían ser propensas a este tipo de monitorización mediante un SOC serían las empresas que realizan transacciones, como podría ser una empresa de comercio, una empresa de pagos online o una empresa de Blockchain, Smart Contracts, etcétera. ¿Por qué? Porque además de poder sufrir una pérdida de servicio o poder sufrir una potencial fuga de información, puede sufrirse un daño económico en tiempo real. 

Es decir, si no hay una monitorización continua de qué tipo de problemas o incidentes están sucediendo en el momento medio o en el tiempo medio en el que un analista de seguridad puede visualizar la alerta y si es o no una potencial amenaza, el problema económico ya habría sucedido y habría tenido un impacto que quizás incluso pueda suponer el cierre o un problema mayor para la empresa, que quizás pueda suponer una bancarrota para la empresa o problemas financieros graves.

### Seguridad Defensiva (Video)
![[417.B7_Seguridad_Defensiva.mp4]]
[Seguridad Defensiva](https://app.web3mba.io?wvideo=8maquar89z)

Mucha gente pensará que la seguridad cripto proviene del protocolo blockchain, de la red. Sin embargo, no es así. Hemos visto que, nada más lejos de la realidad, encontramos, habitualmente, fallos en la parte que envuelve al smart contract, como podría ser el front-end o la infraestructura donde se están ejecutando las aplicaciones descentralizadas. Por lo tanto, creo que es necesario diferenciar en la seguridad cripto entre una parte que es on-chain, que se refiere al smart contract en la blockchain, y otra parte que es off-chain, que incluye el front-end y la infraestructura.

En esta última parte, podríamos mencionar las típicas vulnerabilidades de toda la vida, que pueden incluir servicios mal configurados, sin actualizar, así como inyecciones SQL o ejecución de código remoto. Por otra parte, tendríamos la seguridad relacionada con los smart contracts y la blockchain. Una forma de atacar un smart contract desde off-chain sería atacar una web que tenga permisos para interactuar con un contrato. De esta manera, aunque no se ataque directamente al contrato, se atacaría a esa web, lo que podría llevar a comprometer el contrato. Otra forma sería atacar infraestructuras que contengan datos sensibles, como claves privadas, y así acceder a esas cuentas o a los permisos que tienen en ciertos contratos.

Los ataques on-chain, que son directos a la blockchain y a los smart contracts, aunque en general suelen ser menos habituales, tienden a ser más críticos y a tener una repercusión más importante. Para hacernos una idea, hay que saber que la blockchain es pública; por lo tanto, cualquier persona puede tener acceso al código de los smart contracts, lo que facilita enormemente la identificación de vulnerabilidades que puedan comprometer la seguridad de un smart contract. Los atacantes no solo observan la mainnet, también analizan las testnets con el fin de adelantarse y encontrar, mediante pruebas, otras formas de acceder a los contratos antes de que estén publicados en la mainnet. De hecho, en ocasiones, debido a que los desarrolladores están probando en la testnet, descuidan parte de la seguridad y pueden dejar información que de otro modo no dejarían en la mainnet, de la cual los atacantes pueden aprovecharse.

En general, dependiendo del tipo de contrato, los atacantes buscan ciertos fallos de seguridad conocidos que pueden comprometer el contrato de la blockchain de diversas maneras. Por ejemplo, pueden acceder a los fondos de un contrato, a los fondos de las personas que interactúan con ese contrato, a funciones administrativas del contrato, intentar quedarse con la propiedad del propio contrato, hacer que el contrato funcione de manera defectuosa o, incluso, destruir el contrato. Creo que tanto en el ámbito de los tokens como en el de los NFTs hay vulnerabilidades. Es cierto que ha habido un boom de los NFTs, pero creo que actualmente hay más volumen y valor en los tokens que en los NFTs. Por lo tanto, considero que los hackers están más enfocados, o tienen la mirada puesta, sobre todo en los tokens.

Podemos mencionar el caso de Axie Infinity, en el cual, como he dicho antes, se trató de una vulnerabilidad off-chain que utilizó ingeniería social. Los hackers hicieron una oferta de trabajo y, a través de ella, lograron acceder a los servidores del proyecto y atacarlo desde dentro, sin necesidad de atacar el contrato en sí. Para poner en contexto toda la repercusión que estos hackeos suponen, durante el primer trimestre del año 2022 se registraron hackeos por un total de 1.300 millones de dólares. Esto representa un 136% más respecto al mismo periodo del año anterior. Como ejemplo, podemos mencionar el hackeo de Axie Infinity, que, como mencionaba anteriormente, fue un hackeo off-chain que se aprovechó de la ingeniería social para acceder a los servidores del proyecto y así poder hackear el contrato.

A nivel empresarial, los fallos generalmente ocurren porque se desea tener los proyectos desplegados en la mainnet sin un buen diseño inicial y sin haber pasado por todos los pasos previos antes de publicarlos. En este sentido, estamos notando que hay muchos contratos sin auditar y con muy pocas pruebas realizadas. Hay protocolos que solo auditan parte de los contratos, como podría ser un ERC20, pero dejan de lado toda la parte de DeFi, que podría incluir un market o cualquier otro contrato con el que interactúan. Muchas veces, no se consideran otros servicios a los que los contratos que se despliegan llaman para recibir cierta información, como podría ser un oráculo.

Creo que es importante seguir ciertos pasos antes de desplegar un contrato. Este debería pasar por un buen diseño que permita actualizarlo y tomar ciertas medidas en caso de que sea necesario realizar un cambio a nivel de estado del contrato o de la memoria del contrato. También es fundamental tener en cuenta la posibilidad de que se pueda hackear y que se puedan implementar ciertas medidas en este caso. Las plataformas que ofrecen la posibilidad de crear contratos, como los ERC20, directamente desde la línea de comando o desde alguna interfaz web, generalmente son bastante seguras porque, en el caso de Ethereum, esos contratos son desarrollados por empresas como OpenZeppelin, que son líderes en el sector y realizan auditorías, por lo que son bastante seguros.

Por lo tanto, teniendo en cuenta la adopción de estas tecnologías por parte de otros inversores institucionales, como podrían ser los bancos, no debemos dejar de lado ninguna parte de la que hemos comentado anteriormente, tanto de la seguridad on-chain como de la off-chain, así como seguir todo el flujo hasta tener un producto final bien desarrollado.

### Seguridad Ofensiva
Es común pensar que la seguridad cripto viene dada por el protocolo Blockchain y por la propia red. Sin embargo, esto está bastante alejado de la realidad.

Habitualmente, se han encontrado fallos en la parte que envuelve al Smart Contract, el front-end, o la infraestructura donde se están ejecutando las aplicaciones descentralizadas. 

Habría que diferenciar 2 partes en la seguridad cripto:
- **Off-chain:** Frontend (la parte de la infraestructura) con las típicas vulnerabilidades de toda la vida, como servicios mal configurados o sin actualizar. Podríamos encontrar inyecciones SQL o ejecución de código remoto. 
- **On-chain:** Seguridad de la Blockchain y Smart Contracts.

#### Off-chain
Es posible atacar un Smart Contract desde Off-chain: Consiste en atacar a una web que tenga permisos para intentar interaccionar con un Smart Contract. De esa forma, aunque no se ataque directamente al Smart Contract, se ataca a esa web para acceder a él y, finalmente, hackearlo.

**Otra forma de ataque común se suele producir sobre infraestructuras que contienen datos o claves privadas:** De esa forma puedes acceder a esas cuentas o bien acceder, con esos permisos que contiene esa cuenta, a otras cuentas diferentes. 

En ciertos Smart Contracts también se pueden dar otro tipo de ataques más típicos de la ciberseguridad, como el _phishing_ o cualquier otro. 

#### On-chain
Los ataques On-chain (que van dirigidos directamente a la Blockchain y a los Smart Contracts) aunque, en general, suelen ser menos habituales, son más críticos y tienen una mayor repercusión. 

- **Hay que tener en cuenta que la Blockchain es pública,** por lo tanto, cualquier persona puede tener acceso al código de los Smart Contracts y eso facilita muchísimo el encontrar esas vulnerabilidades que puedan comprometer su seguridad. 
- Los atacantes no solo miran la Mainnet, también miran las Testnet con el fin de adelantarse y encontrar, a base de hacer pruebas, otras formas de acceder a los Smart Contracts antes de que estén publicados en la MEINE.
- En ocasiones, por el hecho de que los desarrolladores están probando en la Mainnet, descuidan parte de la seguridad y pueden dejar información que de otra forma no la dejarían en manos de los atacantes. 

Los atacantes siempre buscarán ciertos fallos de seguridad conocidos y, dependiendo del tipo de Smart Contract, pueden comprometerlo de muchas formas. 

- Acceder a los fondos de un Smart Contract.
- Acceder a los fondos de las personas que interactúan con ese Smart Contract.
- Acceder a funciones administrativas del Smart Contract. 
- Puede intentar incluso quedarse con el _ownership_ del propio Smart Contract.
- Hacer que el Smart Contract funcione de una manera defectuosa.
- Incluso pueden ser capaces de destruir el Smart Contract. 

**Tanto en el ámbito de los tokens como de los NFTs existen vulnerabilidades.** 

Si que es cierto que ahora ha habido un boom de los NFTs,  a día de hoy sigue existiendo más volumen y más valor en los tokens que en los NFTs. Por lo tanto, la mayoría de los ataques tienen como objetivo, sobre todo, los tokens.  

##### El caso de Axie Infinity
Se trata de un claro ejemplo de la vulnerabilidad Off-chain, antes mencionada.

Para ello, los hackers han recurrido a la ingeniería social mediante una falsa oferta de trabajo. Gracias a esto, han conseguido entrar en los servidores del proyecto para atacarlo desde dentro sin tener que atacar el Smart Contract en sí. 

Para poner en contexto toda la repercusión que este tipo de hackeos suponen: 
- Durante el primer trimestre del año 2022 ha habido hackeos de 1.300.000.000 de dólares. Eso supone un 136% respecto al mismo periodo del año en el año anterior. 
- A nivel empresarial, los errores, generalmente, ocurren porque se quiere tener los proyectos desplegados en la Mainnet sin tener un buen diseño inicial y sin pasar por todas las fases previas antes de publicar el proyecto.

**Se han detectado muchos Smart Contract sin auditar y con muy pocos test hechos.** De hecho, hay protocolos que solamente auditan parte de los Smart Contract, como por ejemplo podría ser RC20, pero dejan de lado todo esto, la parte DeFi, que podría ser un market o cualquier otro Smart Contract con el que interacciona y muchas veces no se mira. 

Es importante, antes de desplegar un Smart Contract, seguir unos pasos para su diseño. 

1. Que permita actualizarlo sin incidencias. 
2. Que se pueda tomar ciertas medidas en caso de que sea necesario hacer un cambio en el estado del Smart Contract o de la memoria. 
3. Tener muy en cuenta que la posibilidad de que puede ser atacado y tomar ciertas medidas. 

Hay plataformas que ofrecen la posibilidad de crear Smart Contract (por ejemplo, RC20) directamente desde la línea de comando o desde alguna interfaz web. 

Generalmente, son bastante seguros. Por ejemplo, en el caso Ethereum, esos Smart Contract son desarrollados por empresas como OpenZeppelin, que auditan y son punteras en ese sector, por lo que son una opción bastante segura.

En conclusión: Teniendo en cuenta la adopción de esas tecnologías por parte de otros inversores institucionales (como pueden ser los bancos) no hay que dejar de lado ninguno de los puntos mencionados anteriormente, tanto de la seguridad On-chain como la Off-chain, así como seguir todos los pasos previos hasta tener un producto final bien desarrollado.


## U7. Práctica 
### Hacking a una DApp (Video)
![[419.B7_Hacking_a_una_DApp.mp4]]
[Hacking un DApp](https://app.web3mba.io?wvideo=4zmgcs89nz)

Mi nombre es Pablo y en este vídeo os voy a demostrar cómo un atacante, aprovechándose de una vulnerabilidad en la parte del cliente de un DEX, es decir, de un exchange descentralizado, podría hacer que la víctima, en lugar de realizar un simple swap de un token a otro, como se suele hacer en este tipo de aplicaciones, transfiera todos los fondos de su billetera a la billetera del atacante.

Para ver cómo funciona este tipo de vulnerabilidad y qué tendría que hacer el atacante para explotarla, hemos preparado un pequeño ejemplo. Supongamos que un DEX tiene un sistema de referidos en el que se aplica un 0,5% de descuento en cualquier tipo de swap a aquellas personas que compartan el enlace de referidos con diferentes usuarios. Cada usuario tiene asignado un código de referido que se imprime en la página web junto a un mensaje que indica que tienen un descuento. Este código de referido se obtiene de los parámetros de la URL.

El problema aquí es que un atacante podría enviar esa URL, pero en la variable "referer" incluir un script que podría ejecutar lo que desee. Al introducir un script, cuando se añada el HTML para imprimir esto en pantalla, no se añadirá una simple variable como es el código de referido, sino que se ejecutará el script que haya introducido el atacante.

Para que veáis un poco el entorno que hemos preparado, nosotros hemos montado un DEX de pruebas para que podáis observar cómo funciona. Si un usuario quisiera entrar a esta página y hacer un swap de un token a otro, lo primero que tendría que hacer es desbloquear su billetera. Nosotros hemos creado una billetera de Metamask de prueba. Entonces, conectamos. Hasta aquí no pasaría nada; simplemente, lo que quiere el exchange es poder ver tus direcciones.

Una vez que nos hayamos conectado con nuestra billetera, lo que podría hacer un usuario aquí sería, por ejemplo, intercambiar algún token por otro diferente. Imaginemos que el usuario introduce un token. Lo que estaríamos haciendo es tomar de nuestros fondos un USDT e intercambiarlo por su equivalente en BUSD. Si pulsamos en "swap", lo primero que nos va a pedir el exchange es que le otorguemos permisos para acceder a nuestros fondos y poder intercambiar cualquier cantidad de nuestro USDT a BUSD. Antes de nada, tenemos que confirmar esto.

Una vez que hemos confirmado que el exchange puede acceder a nuestros fondos, también nos pedirá que confirmemos la transacción. Debemos entender que esto es una interacción con un contrato, en este caso, con el contrato de PancakeSwap, que permite cambiar de un token a otro. Confirmamos la transacción y, como vemos aquí, se nos ha descontado la cantidad que hemos indicado de USDT. Antes estaba a 27 porque hice unas pruebas antes de grabar esto, así que ahora tenemos 2 menos. Si nos dirigimos aquí, vemos que hemos interactuado con esta dirección, que es la dirección de un contrato. Si la abrimos en el explorador de bloques, en Etherscan, veremos que hemos interactuado con este contrato.

Si observamos la función que se ha ejecutado, es "swapExactTokensForTokens", es decir, está cambiando una cantidad exacta de tokens por otra cantidad de tokens. Si abrimos este contrato, podemos ver que es el contrato oficial de PancakeSwap que se utiliza en su DEX para intercambiar tokens. Hasta aquí todo correcto, no hay nada raro, todo funciona perfectamente.

Ahora vamos a ver qué pasaría si el atacante nos enviara una dirección con este sistema de referidos del que estábamos hablando antes. El atacante lo único que tendría que hacer es pasarle a la víctima esta URL, que como veis es un poco diferente a la URL que había antes. Aquí, el atacante se está aprovechando de que la variable "referer" se inyecta en el código HTML de la página del cliente, de manera que le está pasando un script. Este script lo que hace es cambiar la dirección del contrato del router de PancakeSwap.

Es decir, el contrato de PancakeSwap interactúa con nuestra billetera para poder hacer el intercambio de tokens, pero lo que está haciendo el atacante es cambiarlo por un contrato que, como podemos suponer, es malicioso. Ahora veremos qué código tiene. Entonces, el usuario vendría aquí y haría lo mismo que antes: cambiar USDT por BUSD. Como veis, aquí ya aparecería el código diciéndonos que estamos en una línea de referidos y que se nos aplica un 0,5% de descuento en cualquier tipo de swap.

Vamos a hacer el cambio, pinchamos y ahora se nos abre esta ventana. Esta ventana, como veis, nos dice el mismo mensaje que antes, es decir, le estamos dando acceso al exchange a todos nuestros fondos, pero si nos fijamos, esta dirección no es la misma que antes; es la dirección que nos ha inyectado el atacante mediante este script. Vamos a ver lo que pasaría. Confirmamos y ahora tenemos que esperar. Se nos abriría otra ventana confirmando nuestra transacción, es decir, confirmando el swap entre estos dos tokens.

Ya tenemos por aquí. En principio, no hay nada raro. En ningún sitio pone que se te vaya a quitar toda la cantidad de tokens que tienes en tu billetera. Simplemente indica que vas a hacer una interacción con un contrato, igual que lo haces con el contrato de PancakeSwap. Si confirmamos la transacción... Ahora aquí, en algún momento, si... porque esta transacción tarda un poco, igual que la de antes, vemos que tenemos cero USDT, es decir, nos han vaciado la cuenta simplemente haciendo lo mismo que hacíamos con el exchange, pero sin la URL y sin el script inyectado.

Vamos a irnos a la dirección que tengo preparada, que es donde he enviado los fondos, y efectivamente aquí están los 25 USDT. Como vemos, esto lo veríamos en la cuenta de aquí. Vamos a ver qué ha pasado. Bien, aquí lo que ha sucedido es que hemos interactuado con este contrato ejecutando esta función, que realmente tiene el mismo nombre que la función del contrato de PancakeSwap, pero vamos a ver qué hace esta función del contrato malicioso.

Lo primero que tenemos que fijarnos es que a este contrato, al desplegarse, se le asigna un "receiver", que será la misma cuenta que haya desplegado este contrato. Luego, este contrato lo hemos escrito nosotros, así que para facilitarnos las pruebas y asignar una billetera de atacante donde irán todos los fondos de la víctima, hemos creado esta función "setReceiver", que permite cambiar la dirección de la cuenta que recibirá todos los fondos. Obviamente, esta función no tendría sentido que un atacante la escribiera, porque permitiría a cualquier persona cambiar la billetera donde irán todos los fondos del ataque.

Lo que sí nos interesa de verdad es esta función, "swapExactTokensForTokens", que es la misma función que tenía el contrato original de PancakeSwap, pero en este caso lo que hace es tomar el balance de todos los tokens de la cuenta de esta dirección, que es la cuenta que interactúa con este contrato, es decir, nuestra billetera víctima, y transferir todo su balance al "receiver", que recordemos que es el atacante, es decir, la persona que despliega este contrato. Por lo tanto, solo con estas dos líneas ya estaríamos enviando todo el balance de esta cuenta a la cuenta del atacante, que como vemos aquí, se ha llevado todo el balance, todo el USDT de la cuenta de la víctima.

Hemos visto cómo un atacante, aprovechando una vulnerabilidad de XSS, ha podido robar todos los balances de una cuenta de la víctima. Lo que quiero que se entienda con este vídeo es que no todo en el mundo de Web3, en cuanto a seguridad, tiene que ver con los smart contracts y la blockchain. Un DeFi, un DEX, cualquier aplicación en Web3, tiene que tener un enfoque de seguridad. Al fin y al cabo, tiene una parte de cliente y una parte de servidor, además de interactuar con la blockchain e interactuar con smart contracts.

Debemos tener en cuenta que este cliente y este servidor pueden tener vulnerabilidades, igual que cualquier otra página web o aplicación. Por lo tanto, esto es importante porque, al desarrollar este tipo de aplicaciones, no solo hay que considerar la seguridad de los smart contracts, que también tienen vulnerabilidades, incluso estando desplegados en la blockchain, sino que también debemos hacer hincapié en la seguridad de las aplicaciones, tanto en la parte del cliente como en la parte del servidor.

Por ejemplo, en este caso, una vulnerabilidad de este tipo, un XSS, podría afectar mucho más a un cliente en una aplicación Web3 que en una aplicación Web2, por el simple hecho de que los usuarios están interactuando con sus billeteras dentro de nuestra aplicación, y sus billeteras solo contienen dinero. Para finalizar, quiero que reflexionéis un poco sobre lo que os acabo de comentar y que tengáis siempre presente la seguridad de las aplicaciones, y que blockchain no implica seguridad. Siguen existiendo vulnerabilidades tanto en Web3 como en smart contracts. Espero que os haya gustado el vídeo y que os haya servido de ejemplo para entender lo que os acabo de explicar. Un saludo.

### Hacking a a un Smart Contract (Video)
![[420.B7_Hacking_a_a_un_Smart_Contract.mp4]]
[Hacking un Smart Contract](https://app.web3mba.io?wvideo=v3ngnt4n1x)

En este video vamos a hacer una demostración de un hackeo a un contrato inteligente que contiene una vulnerabilidad. Para ello, hemos elegido el mismo tipo de ataque que provocó en 2016 la separación de la red Ethereum en dos redes: Ethereum y Ethereum Classic, en el que el atacante logró robar 60 millones de dólares. Este ataque se denomina "entrance attack" y es muy peligroso, ya que permite robar todos los Ethereum del contrato víctima.

Para esta demostración, vamos a usar el entorno de desarrollo Remix, el cual nos proporciona una red blockchain local para poder desplegar los contratos e interactuar con ellos. El contrato que vamos a atacar es un contrato sencillo que representa un banco y que implementa la misma vulnerabilidad que el contrato DAO del ataque de 2016. Este contrato contiene un mapping para guardar las direcciones de los usuarios y el balance de sus cuentas. También implementa un método para hacer depósitos, que simplemente incrementa el balance del usuario con el valor que ha enviado, y tiene una función de retiro, la cual comprueba que el usuario tiene saldo positivo en su cuenta, imprime por pantalla el balance del banco y el balance del usuario, y después hace el envío del total del balance del usuario a su cuenta, a su wallet. Después de esto, actualiza el saldo de su cuenta a cero, ya que ha enviado todo el saldo que tenía. Además, hay un método para comprobar el balance total del banco.

Vamos a desplegar el contrato y comprobar cómo funciona. Aquí lo tenemos. Vamos a hacer algún depósito. Vamos a depositar y efectivamente tenemos 10 ETH en la cuenta del banco, y el usuario tiene 10 ETH. Aquí se ven los decimales de ETH y son 10 ETH. Vamos a hacer otro depósito con otra cuenta. Aquí tenemos 25 ETH en la cuenta del banco, y el balance total del banco, y el usuario tiene en su cuenta 15 ETH. Vamos a hacer un retiro de esos 15 ETH. Podemos comprobar que el banco tenía 25 ETH y el usuario tenía 15 ETH, y después de la ejecución, el balance del banco está en 10 ETH. Vamos a intentar hacer otro retiro, a ver si nos deja. Y efectivamente, no ha pasado el check de aquí, el require, ya que el usuario ya no tenía saldo. El usuario actualmente tiene 0 saldo, por lo que no ha funcionado.

Aparentemente, el contrato funciona correctamente. Pero como sabemos, con un contrato podemos interactuar a través de una cuenta de un usuario privado o a través de otro smart contract, lo que nos da una forma de poder hackear este contrato. Aquí tenemos un contrato atacante que usaremos para atacarlo, el cual define una interfaz que representa el contrato del banco. Este contrato contiene la dirección del contrato a atacar y la dirección del owner del contrato atacante, que se establece en el constructor. Aquí tenemos un método para poder establecer el contrato que vamos a atacar. El método para atacar será un depósito y, acto seguido, un retiro.

Como sabemos, para que un contrato pueda recibir Ethereum, necesita implementar un método que sea payable. Esta parte sería mejor explicarla con una imagen, así que de esa manera se entiende mejor. El ataque funciona de la siguiente manera: se llama a este método y se haría un depósito, se llamaría al método de depósito del contrato del banco, se incrementaría el valor del balance del usuario y después se haría un retiro. Se llamaría a la función de retiro, donde se comprueba que el balance del usuario es positivo, por lo que se procede a enviar el dinero al usuario. En el momento de hacer el envío al contrato, se ejecutaría el método Reset del contrato que es Payment. Este método lo que hace es comprobar que el banco todavía tiene dinero y, en este caso, volvería a llamar, haría una llamada recursiva a la función de retiro.

Hay que tener en cuenta que todavía no hemos llegado a esta línea de código, que es la que actualiza el estado del balance del usuario a cero. Por lo tanto, cuando lleguemos aquí, el usuario todavía tiene el mismo saldo que antes, un saldo positivo, por lo que esta aprobación se cumpliría y se volvería a hacer la llamada para enviarle fondos otra vez al usuario, que en este caso es el contrato. Esto se haría de forma recursiva hasta que esta condición deje de cumplirse, es decir, que el banco ya no tenga ningún saldo en su cuenta. En ese momento, entraría en el else y se haría una transferencia de la cuenta del contrato atacante a la cuenta del wallet del atacante.

Podemos comprobar cómo funciona desplegando el contrato. Vamos a desplegar el contrato. Seleccionamos una cuenta diferente para el atacante y vamos a desplegar el contrato atacante. Por aquí tenemos el contrato atacante. En el banco todavía tenemos 10 ETH. Vamos a establecer el contrato al que vamos a atacar. Ya lo tenemos establecido y ahora lo único que nos queda es atacar. Vamos a hacer un depósito de 2 ETH en el contrato a través del método ATTACK. Lo retiramos y ya vamos de forma recursiva hasta que se vacíe la cuenta del contrato. Vamos a verlo en acción. Ampliamos un poco.

Como podemos comprobar, el contrato anteriormente tenía 10 ETH. Se han depositado los 2 ETH del atacante desde el contrato atacante. Por lo tanto, el usuario que representa el contrato atacante tiene 2 ETH en balance, y se devuelven al contrato esos dos ETH, por lo cual el contrato del banco solamente tiene 10 ETH. Se le vuelve a enviar dos de forma recursiva hasta que el banco se queda sin fondos. Como podemos comprobar, el banco tiene cero ETH, por lo que se le vació la cuenta.

Para poder solucionar esta vulnerabilidad, lo podemos hacer de dos formas. Una de ellas es simplemente, aquí en el contrato del banco, actualizar el estado de la cuenta del banco antes de hacer el envío del valor al usuario o al contrato. En este caso, lo tenemos aquí cambiado. Aquí lo único que cambia es lo que hemos dicho: subir esta línea arriba para actualizar antes de hacer la llamada. Esto es usar el patrón "checks-effects-interactions". Este patrón lo que dice es que primero se hagan las comprobaciones, luego se actualiza el estado y después se interactúa con un contrato que no conocemos, un contrato inseguro.

Podemos desplegar este contrato y ver que realmente soluciona el ataque. Vamos a seleccionarlo, contrato A, desplegamos y aquí tenemos el contrato A, el contrato anterior, el vulnerable. Vamos a hacer algún depósito en este contrato. Vamos a depositar 40 ETH desde otra cuenta. Hemos dicho, vale, depositamos. Efectivamente, tenemos, creo que he marcado otra cosa. Vamos a probar otra vez, vamos a depositar 40 aquí y depositamos 40, 40, efectivamente. Vale, ahora el banco tiene 40. Perdón, la cuenta del usuario tiene 40 ETH en su cuenta, que es lo mismo que la cuenta del banco. Vamos a intentar atacarlo, por lo que vamos a establecer el contrato a atacar y vamos a atacarlo haciendo un depósito, un depósito de 5 ETH. El contrato que vamos a atacar es 8CA8C6A, es el mismo. Genial, pues vamos a proceder a pagarlo.

Efectivamente, podemos comprobar que el banco tenía 40 ETH. Se ha intentado depositar 5 ETH, por lo que el banco tendría 45 ETH y 5 ETH el usuario. Pero al intentar hacer la segunda llamada para poder retirar más fondos, el banco ha decidido que no se puede hacer. Por lo tanto, el banco ha decidido que no se puede hacer. Como el estado ya se había actualizado en la segunda llamada, ya no se pasaba este require, por lo que ya no se podía hackear.

La segunda forma de solucionar esta vulnerabilidad es haciendo uso de esta librería de OpenZeppelin. Esta librería nos proporciona un modificador de acceso que se llama "nonReentrant", el cual funciona de la misma forma que un candado. Tiene un booleano que se establece en true antes de que se ejecute el código. Como podemos ver aquí, es el mismo código de antes, del mismo código vulnerable. Pero al usar este "nonReentrant", que es un candado, antes de ejecutar todo este código, se establece ese valor a true. Y se comprueba, cada vez que se ejecuta ese método, que ese valor esté en false. Inicialmente está en false, cuando se ejecuta, antes de ejecutar el código, se establece en true y al final de la ejecución se establece en false otra vez, por lo que mientras se esté ejecutando ese código, no se podría volver a llamar a este método.

Vamos a desplegar este contrato y comprobar que realmente funciona. Aquí lo tenemos, vamos a hacer algún depósito desde una cuenta. Vamos a poner 50 ETH y hacemos un depósito. Efectivamente, el banco ahora tiene 50 ETH, por lo que vamos a intentar hackearlo. Vamos a la cuenta del atacante, vamos a establecer el contrato que vamos a atacar, que es este, lo he copiado, ya está establecido y ahora vamos a atacarlo con 5 ETH, depositamos 5 ETH y lo retiramos de forma iterativa hasta que se vacíe. Vamos a intentarlo. Lo normal es que no funcione y ya está.

Y efectivamente, se ha revertido la transacción. Se ha intentado depositar los 5 ETH, por lo que el banco tendría 55, pero en la segunda ya se ha revertido. Por lo cual, esta solución también funciona. Espero que os haya gustado el video y que haya ayudado a entender cómo funciona esta vulnerabilidad. ¡Muchas gracias!

## Xperts 
### Metamask (Video)
![[421.B7_Metamask.mp4]]
[Metamask](https://app.web3mba.io?wvideo=kuutefi8pp)

MetaMask es una empresa reconocida por ofrecer un software que funciona como una cartera de criptomonedas, haciendo uso de la blockchain de Ethereum. Permite a los usuarios interactuar con su ecosistema y sus DApps, sin tener que descargar la red completa en sus dispositivos, siendo una de las mejores alternativas a la hora de acceder a criptoactivos, plataformas de juegos y aplicaciones descentralizadas. Nació en 2016 y desde entonces no ha dejado de crecer, contando en la actualidad con más de 30 millones de usuarios activos mensuales y con una previsión de expansión constante de cara al futuro. Además, el pasado enero presentó Snaps, un sistema que facilita ampliar las capacidades y funcionalidades en la fase de desarrollo con aportaciones de código, impulsando enormemente la innovación. En octubre de 2022 lanzó el portafolio The Apps, que permite el visionado simultáneo de criptodivisas, colecciones de NFTs y la información relevante de los precios del mercado para todos estos artículos. Con cada vez mayor relevancia, no solo en el sector cripto, sino también en el tecnológico especializado, MetaMask aspira a convertirse en uno de los actores principales en esta nueva revolución imparable de la Web3.

Consensys es una empresa de software constituida en los Estados Unidos. Consensys engloba una gran variedad de productos y MetaMask es uno de ellos. También tenemos otro producto llamado Infura, que funciona prácticamente con el ecosistema de Ethereum. Además, contamos con otros productos como Diligence y Truffle. También realizamos trabajo de protocolo relacionado con Besu, Quorum, etc. MetaMask es probablemente el primer paso a la hora de hacer todo lo que desees en un mundo cripto o Web3. Es una simple wallet de usuario. Es una wallet basada en software que puedes instalar en tu teléfono o en tu navegador para empezar a crear tus wallets y acumular Ethereum. Así que, en este momento, la wallet soporta Ethereum y cualquier cosa que esté relacionada con Ethereum, como tokens. De este modo, MetaMask es todo lo que abre puertas hacia los proyectos descentralizados. Una vez que se activa una wallet y se empieza a usar, puedes realizar transacciones en cualquiera de las blockchains compatibles con Ethereum. Creo que tenemos alrededor de 17,000 o más habilidades de protocolo con usos derivados. Puedes hacer transferencias de cuenta a cuenta de manera sencilla. Puedes hacer swaps, cambiar un token por otro usando MetaMask. Recientemente, hemos introducido algunas herramientas de integración llamadas Snaps y Flask, que permitirán a los usuarios una integración personalizada utilizando Snaps y Flasks de MetaMask, de modo que puedan ser aprovechadas para construir productos únicos o más personalizados. MetaMask, como he mencionado, es una wallet basada en software. Es una wallet que se adapta a las necesidades individuales. Así, te instalas el monedero en tu dispositivo móvil o navegador. Lo haces todo por tu cuenta. Creas la cuenta, mantienes tu cuenta, foldeas y almacenas criptodivisas en la cuenta. Lo gestionas todo tú solo. Si usas un tercero, un custodio o un proveedor de carteras de criptomonedas, estás dependiendo del proveedor para mantener todas tus criptomonedas y hacerlo todo por ti. Solo estás subcontratando lo que podrías hacer localmente con tu teléfono móvil o con tu cartera de criptomonedas. Así que con MetaMask haces tu propio KYC, con acierto consumidor. No requiere un KYC porque tú eres la persona que está usando la cartera. Ese es el beneficio, si me preguntas. Porque no tienes que depender de ningún tercero para hacer el onboarding. Básicamente, porque estás haciéndotelo a ti mismo en el mundo de las criptomonedas y blockchain. Como he mencionado, MetaMask es la puerta de entrada a la mayoría de los juegos y otras aplicaciones. Creo que hemos hablado de Decentraland. Con MetaMask puedes entrar a Decentraland usando el ID de MetaMask. Una de las cosas más geniales que he visto es que ahora con el FT hay Swags y cosas así que se pueden dejar caer en la cartera de MetaMask directamente porque es tu dirección de Ethereum y puedes escoger y elegir estos Swags para usarlos y luego ir a Decentraland y empezar a conocer allí gente nueva. Básicamente, MetaMask es tu identidad aquí, en el mundo virtual o el metaverso.

La tecnología siempre es un reto cuando es nueva.

Con respecto a nuestra gestión de wallets, no solo MetaMask, siempre se trata de la cuestión de la seguridad. Podemos hablar de muchos retos sobre los monederos y las criptomonedas siendo robadas, utilizando la tecnología de phishing u otros métodos.

Así que también depende de la educación. Siempre que se trata de tecnología, hay algo nuevo. ¿Cómo se educan los usuarios? Esa es otra pieza que nos resulta muy difícil de mantener en el mercado, porque cada vez que inventamos algo nuevo, la gente necesita entenderlo y empezar a utilizar ese producto de forma que se sienta cómoda y segura. El phishing es una de las técnicas más sencillas que la gente utiliza para robar criptomonedas mediante wallets. Así que tenemos que tener mucho cuidado cuando están utilizando wallets y por eso hay un montón de vídeos promocionales de MetaMask sobre cómo evitar el phishing y cómo utilizar otras herramientas para protegerse de esta amenaza. Pero, de nuevo, realmente depende de los conocimientos del usuario individual sobre cómo pueden manejar la wallet y luego empezar a utilizarla cómodamente. Básicamente, se debe a la comprensión de lo que sucede en la Web3 y el mundo blockchain. No es muy diferente. Por ejemplo, estoy desplegando un contrato inteligente y he encontrado un problema. Puedo actualizar el código y luego volver a aplicar el contrato inteligente. Es más o menos la misma forma de hacerlo en el mundo de la Web 2. Una cosa es que si está en una infraestructura pública, entonces el contrato inteligente se despliega y luego se sincroniza con todos los nodos en los que está activo, lo que puede tomar un poco más de tiempo de lo que normalmente se utiliza en el mundo de la Web 2. Por lo demás, es un proceso bastante simple y directo. Así que una vez que has construido la automatización para los despliegues, una vez que tomas el control del pipeline, se puede hacer realmente muy fluido. Estamos hablando de una clase de activos diferentes. La clase de activos digitales ha llevado al mundo a utilizar los casos de uso de una manera muy diferente. Los NFT son una clase de activos diferente de la que hablábamos. Se trata de la tokenización de un activo del mundo real a la tokenización de un activo del mundo digital. Así que, de nuevo, los NFT son un modelo diferente. Hay objetos de colección, desde tarjetas hasta música, pasando por cuadros, arte digital y todo eso. Los NFT relacionados con el deporte están dirigidos a las personalidades del mismo, así como los NFT relacionados con la música y todo eso. Todo esto es una categoría general. Está enfocado a imitar algo del mundo real al que todos estamos acostumbrados y que va a estar en un mundo digital. También hay NFTs que se usan para buenas causas. Por ejemplo, recientemente hicimos el drop de MacGlam, los lápices labiales únicos que lanzamos junto a MAC. Eso es, en realidad, una toma de consciencia de la comunidad sobre el VIH y cómo prevenir el SIDA mediante una educación más abierta llevada a cabo en un evento de recaudación de fondos mediante NFT. Es otro tipo de NFT que vemos en el mercado. También tenemos otros tipos de NFT, como los NFT de colaboración, por ejemplo, un híbrido entre el mundo digital y el mundo normal de objetos que se juntan. Puedes tener NFT para espectáculos, NFTs para tickets, para películas, para teatro... Por ejemplo, si quieres ofrecer un recuerdo o un souvenir de una obra de teatro, el NFT puede ser un souvenir. Si quieres un souvenir, el NFT puede ser un souvenir.

Hay muchas otras áreas de aplicación donde realmente los NFTs pueden aportar algo desde la perspectiva del estudiante. Piensa en el NFT como tu certificado de notas, lo cual es muy viable, porque es la forma en que estamos viendo que se van a emitir los certificados en el futuro.

Cuando empecé a trabajar hace seis años en la blockchain, la emisión de certificados era uno de los principales casos de uso de la cadena de bloques. Pero ahora tenemos un NFT que puede ser un verdadero activo digital que resuelve ese complejo problema a la hora de usar certificados. Y también los NFTs pueden transferirse a uno mismo, dependiendo del tipo de NFT que se trate. Es emocionante ver cómo están cambiando los activos digitales a los que estamos acostumbrados. Es realmente emocionante.

Soy una persona orientada al cliente. Mi papel en Consensys es ser los ojos del cliente para los equipos de producto, así que hablo con muchos de ellos.

Entender lo que los clientes están buscando, las diferentes dificultades, cómo se pueden resolver los problemas y cómo se puede mejorar el producto. Por ejemplo, todos los consumidores o clientes que se quejan de si hacer el movimiento de deslizar es más fácil hacia la derecha o hacia la izquierda. Incluso un pequeño feedback puede cambiar el producto dependiendo de la experiencia de usuario. O también los múltiples casos de uso, sobre cómo el mercado reacciona cada vez que lanzamos algunos cambios, cuáles son las características que tenemos que incorporar, en qué momento tenemos que incorporar y qué es lo que realmente hicieron los clientes. Deberíamos construir menos, deberíamos centrarnos en las interfaces de usuario, deberíamos centrarnos en la tecnología, deberíamos centrarnos en la escalabilidad y en la seguridad, y en otras cosas que realmente requieren que el producto funcione muy bien. Es algo que se aplica a todos los productos, no solo a MetaMask. Y esto es lo que hago, hablo con muchos clientes, traigo ese feedback y lo paso a los equipos de producto y viceversa. A veces, hay clientes que dan muy buenos comentarios, hay clientes muy difíciles de manejar, y por eso me siento ahí con los equipos de producto, los equipos técnicos y con el cliente. Me centro en la transición de la educación y ayudar al éxito de los clientes, así como al éxito de nuestra empresa. Creo que MetaMask como producto tiene una hoja de ruta muy sólida. Creo que la creciente innovación que se ha producido con MetaMask es bastante fascinante. Si no estás muy familiarizado, te diré que hemos introducido una función llamada MetaMask Snaps junto con Flask, que es un complemento del navegador. Con Snaps puedes habilitar la integración personalizada con tus propios productos usando MetaMask. Y sobre la documentación del producto, habrá una buena cantidad de vídeos de YouTube explicando lo que realmente hace Snaps. Creo que es un buen avance porque muchos de los clientes quieren utilizar MetaMask como su wallet para integrar los productos. Creo que Snaps les ayuda a hacer eso ahora. Creo que va a haber un cambio muy grande en la forma en la que vemos MetaMask, así como el uso que le van a dar los clientes. Para comenzar, el mejor sitio es un lugar como YouTube, donde realmente se puede ir a aprender sobre lo que es blockchain. De nuevo, hay diferentes tipos de blockchain, blockchains privadas, blockchains públicas, así que trata de elegir una. Y tampoco confundir entre criptomonedas y blockchain. Las criptomonedas son un activo digital diferente que funciona en la blockchain. Así que la blockchain es la tecnología central detrás de las criptomonedas. Las confusiones entre criptomonedas y blockchain son siempre las mismas. De modo que siempre hay que empezar por lo más básico. Y una vez que sepas sobre blockchain, elige una blockchain y haz un pequeño trabajo de investigación. Empieza a aprender sobre los contratos inteligentes, porque sin contratos inteligentes no existiría ni la Web3 ni la descentralización. El potencial de blockchain está realmente en los contratos inteligentes. Aprende sobre la tecnología del smart contract. La más popular que conocemos ahora mismo para usar y escribir contratos inteligentes es el lenguaje de Solidity. Así que una vez que empieces a usar contratos inteligentes, entonces apreciarás lo fácil que es solucionar los problemas de confianza que tenemos en el mundo real. Una vez que aprendas sobre los contratos inteligentes, entonces empieza a hacer un proyecto en tiempo real. Más bien una prueba de concepto, una especie de trabajo en el que tienes una wallet, tienes tecnología blockchain, tienes contratos inteligentes, lo unes todo y lo pones bajo una aplicación móvil bonita o una interfaz aplicada a la perspectiva del usuario. Empieza a hacer una simple transacción usando la red de Ethereum como prueba. Todo esto te permitirá experimentar lo que ocurre en el mundo real de las criptomonedas y la blockchain. Así que depende de ti hasta dónde quieras llegar. Hay muchos caminos que puedes elegir tras conocer lo básico. Puedes entrar directamente a investigar wallets, la integración basada en wallets, tecnología de wallets. Puedes, por ejemplo, centrarte en los protocolos esenciales. Lo que está sucediendo ahora mismo en la industria es la fusión de Ethereum. Ethereum 2.0 está a punto de ser lanzada, así que puedes contribuir a ello. Si eres experto en blockchain, realmente te interesa seguir de cerca la tecnología del protocolo. O si no, puedes hacer algo más orientado a la innovación y crear productos basándote en esas tecnologías. Toma, por ejemplo, algunos casos de uso sencillos basados en el día a día, que podrían ayudar a la vida de las personas. Por ejemplo, eso podría ser un caso de uso muy válido. O si quieres, puedes hacer algo fascinante con los NFTs. Actualmente, los NFTs están cambiando el mundo. Eso es algo emocionante que está sucediendo ahora mismo mientras hablamos. Quiero decir, hay un montón de casos de uso, muchísimos, pero al mismo tiempo no puedo compartir gran parte de esa información, ya que podría ser información sensible del cliente. Pero en mi opinión, creo que el proyecto de NFTs de MAC es sencillamente genial. Creo que transmite un mensaje social muy fuerte, y eso es algo muy bueno para la comunidad. Es uno de los proyectos que te podría mencionar. Hay muchos otros proyectos en los que estamos trabajando, pero no creo que pueda compartir muchos detalles.

## Dtalks
### Ciberseguridad en Blockchain (Video)
![[422.B7_Ciberseguridad_en_Blockchain.mp4]]
[Ciberseguridad en Blockchain](https://app.web3mba.io?wvideo=q4efrd93rb)

Bienvenidos a una nueva DTalk. Hoy tenemos la suerte de contar con Ángel y Julián. Vamos a hablar sobre ciberseguridad y, en particular, sobre la ciberseguridad aplicada a la comunidad, al universo Web3 y a las tecnologías Blockchain. Primero, introduzcamos un poco qué hacéis en Sophistic.

Nos dedicamos principalmente a monitorizar todo tipo de amenazas de ciberseguridad que puedan afectar a nuestros clientes, específicamente aquellos que manejan algún tipo de información sensible, que realizan transacciones dentro de su modelo de negocio o que cuentan con alguna infraestructura crítica que tendría un gran impacto si alguien llegara a vulnerarla.

Me imagino, Julián, que habrás visto de todo como analista de smart contracts y blockchain. Has visto vulnerabilidades inmensas, ¿qué dirías? ¿Cómo pudo ser?

Lo curioso es que hay fallos tan triviales como olvidar poner un "only owner" y dejar una función administrativa al acceso de cualquier persona, de cualquier usuario. O, por ejemplo, algo tan sencillo como hacer que los tokens que se crean en ERC20 cumplan con los tokenomics del proyecto. Sin embargo, al mintearlo, se envía a una cuenta de una única persona, lo que implica que se debe confiar en esa persona para toda la gestión del capital del proyecto.

Ahora estáis apostando por el mundo Web3, pero venís de un background en banca. ¿Qué habéis visto en Web3 que os ha fascinado tanto?

Sin duda, creo que Blockchain y la tecnología de muchas de las criptomonedas que estamos viendo hoy en día son el futuro de las transacciones en el mundo financiero, pero prácticamente en cualquier tipo de proyecto. Nosotros llevamos mucho tiempo trabajando con sistemas transaccionales de diferentes tipos; actualmente trabajamos con unos 53 bancos. Nos dimos cuenta, ya éramos aficionados al ecosistema cripto desde mucho antes, pero nos percatamos de que muchos de los problemas que estábamos resolviendo en el sector bancario también podían aplicarse a este tipo de sistemas que se crean en torno al ambiente cripto. Entonces, lo vimos como una oportunidad y, además, como una forma de seguir nuestra afición y pasión hacia este mundillo.

¿Hay muchas diferencias entre estos mundos, a pesar de tener una capa muy común? ¿A nivel de seguridad, compliance y legislación, difieren mucho?

Difieren mucho a nivel de legislación, aunque cada vez más el tipo de licencias que están implementando los reguladores para los exchanges podrían parecerse a las licencias bancarias que puedes encontrar en muchos países. Pero a nivel de seguridad, las diferencias no son tan grandes. Al final, una blockchain es una estructura para la gestión y almacenamiento de intercambio de datos, como podría ser un sistema de gestión de bases de datos. Esa capa es muy importante, y es bueno tener a alguien en el equipo como Julián, que entienda cómo funciona exactamente, para poder auditar y encontrar las vulnerabilidades relativas a esa capa. Pero después, es una aplicación web o una aplicación móvil convencional la que está interactuando con esto. Y lo mismo ocurre con un smart contract. Imagina una pieza de software X, como podría ser antiguamente una API o un web service; hoy es un smart contract que realiza muchas funciones con una serie de procesos, pero el resto del ecosistema en torno a ese smart contract es una aplicación convencional. Por lo tanto, muchos de los problemas de seguridad que tienen las aplicaciones convencionales también se aplican a un proyecto cripto.

Lo que quizás sí es una diferencia notable es lo que podéis llegar a aprender. El mundo blockchain y el mundo Web3 son totalmente abiertos y públicos; podéis ingestar todo tipo de datos sin ningún tipo de problema. Sin embargo, en el sector bancario hay mucha privacidad en juego; no se puede usar la información así como así. ¿Estáis aprendiendo mucho más de proyectos Web3 que de proyectos en banca, por ejemplo?

Sin duda, ahí hay otro tipo de seguridad del que hablamos, porque muchas veces la seguridad bancaria se basa en que hay una caja negra que nadie puede ver. Pero quizás es un sistema de los 80 que no ha sido vulnerado porque nadie sabe dónde está exactamente o cómo llegar a él. Sin embargo, una vez que sabes dónde está, o una vez que se elimina esa parte de la seguridad, que en el entorno llamamos "seguridad por oscuridad", el sistema es extremadamente vulnerable, a pesar de manejar las transacciones de todo un banco. En cambio, en los sistemas blockchain, la seguridad se basa en un sistema más robusto. Dado que todo es transparente, como tú mencionabas, y dado que todo es público, si hay vulnerabilidades muy sencillas de atacar, ya habrán sido atacadas y, por ende, ya habrán sido resueltas. Entonces, el tipo de retos a los que nos enfrentamos en estos sistemas suelen ser más interesantes.

Claro, a nivel de análisis, me imagino que esto será como una tienda de caramelos para ti, ¿no, Julián? Porque tienes una información inmensa con la que ahora puedes jugar y probar nuevas ideas. ¿Cambia mucho el volumen de datos y el tipo de datos?

Sí, por supuesto. De hecho, hay un montón de contratos que se publican prácticamente cada segundo, y la parte buena es que, aunque sean transparentes, no se llegan a analizar todos esos contratos. Desde el punto de vista de un atacante, no puede revisar todos los contratos para buscar esas vulnerabilidades, por lo que pueden estar mucho tiempo ahí. Sin embargo, también es un punto negativo el hecho de que, como los contratos son más difíciles de actualizar, si no se encuentra en un principio esa vulnerabilidad y un proyecto crece y llega a tener un volumen de capital muy alto, en el momento en que se encuentra esa vulnerabilidad y ha pasado un tiempo, el impacto será mucho mayor.

Quiero agregar, Pablo, a lo que está mencionando Julián, y especialmente dirigido a los compañeros que nos están viendo y que tienen su propio proyecto cripto, que hay que tener mucho cuidado con hacer un copy-paste de un proyecto existente, adaptarlo a tu modelo de negocio y publicarlo, especialmente en la Mainnet, sin los procedimientos de auditoría intermedios, de pentesting, de stress testing, los que sean necesarios. Nos estamos encontrando que hay muchos atacantes que están haciendo un rastreo masivo de contratos inteligentes que se vulneraron hace un tiempo y que tienen estas características. Ese tipo de contratos que han tomado como base son muy fáciles de encontrar. Entonces, como dice Julián, es cierto que hoy en día no ocurren más problemas de seguridad porque los atacantes no tienen tiempo de revisar tantos contratos como se crean, pero si estamos tomando como base un contrato existente, facilitamos al atacante la labor de encontrar aquellos que ya hayan sufrido una vulnerabilidad.

¿Y cómo podemos ayudar a mitigar este enorme riesgo? ¿La inteligencia artificial, a lo mejor?

Bueno, ese es un campo muy interesante que puede ayudarnos desde diferentes perspectivas. Nosotros empezamos haciendo pentesting, que se basa en realizar un ethical hacking sobre algún tipo de aplicación, infraestructura, smart contract o cualquier tecnología. Con esto, teníamos la posibilidad de saber qué vulnerabilidades tenía el smart contract en el momento en que se creaba. Sin embargo, si hay alguna vulnerabilidad que no es tan clara o evidente en el momento de su creación, un elemento muy interesante es monitorizar de manera continua qué tipo de transacciones está teniendo ese smart contract. Estamos aplicando inteligencia artificial de manera que podamos detectar anomalías en las transacciones que deberían tener una determinada característica y poder identificar que una situación de riesgo está siendo producida porque hay un posible ataque.

Además, ahora el mundo de la inteligencia artificial ha avanzado tanto que existe el automachine learning. Hay datasets públicos, las redes de blockchain son públicas y puedes ingestar todos esos datos para entrenar tus propios algoritmos. Me imagino que habrá gente que, por curiosidad o por amor al arte, se ponga a crear sus propios algoritmos para mejorar la detección de problemas. ¿Creéis que eso puede ayudar más que resultar en una nueva vulnerabilidad, ya que ellos habrían descubierto formas que vosotros aún no habríais visto, quizás?

En el campo cripto, yo todavía no he detectado muchas aplicaciones de seguridad ofensiva basadas en inteligencia artificial. Quizás simplemente porque no he buscado lo suficiente; quizás las haya. Pero en el campo convencional, por ejemplo, en el sector bancario y otros sectores, sí que hemos detectado muchísima aplicación de seguridad ofensiva hecha por atacantes para tratar de vulnerar mediante mecanismos de machine learning, de manera masiva, determinadas infraestructuras. Esto complica bastante la labor en el lado de la defensa, porque si no tienes un mecanismo que también se base en inteligencia artificial para soportar este tipo de ataques masivos, en detalles que quizás un humano no estaba teniendo en cuenta, se vuelve mucho más complicado hacer esa labor completamente manual o soportada por herramientas convencionales. Entonces, sí que lo veo como un potencial riesgo. A la vez que lo podemos tener en el lado defensivo, debemos ser conscientes de que, igual que lo utilizamos en la defensa, usualmente surge primero el lado del ataque de esa misma tecnología.

Tú con esto, Julián, a lo mejor debes estar cargado de trabajo, por lo que puede estar pasando ahí fuera.

Sí, de hecho, hay ciertos tipos de contratos actualizables que tienen ciertas vulnerabilidades. Si, por ejemplo, no se actualizan en el momento de publicarlos, y si hay atacantes que buscan la publicación de ese tipo de contratos, también se puede monitorizar la red y buscar todo tipo de anomalías, tanto desde el lado de los hackers como del otro lado. Entonces, ahí es un poco la lucha de a ver quién llega primero. La cuestión es tener un paquete de seguridad activa y pasiva junto con un servicio de respuesta a incidencias, con el cual podamos conseguir anticiparnos al propio ataque en determinadas condiciones. No siempre es posible, o al menos poder mitigar e interceptar esa anomalía, esa transacción anómala, lo antes posible, para poder tomar medidas y reducir el impacto que pueda tener en el propio control. Inclusive se está moviendo hacia la creación de contratos y aplicaciones que puedan permitir que esas respuestas a incidencias sean automatizadas. Pero hay mucho trabajo ahí, y se debe trabajar tanto en un estándar de los smart contracts como en un tipo de aplicación en concreto que pueda gestionar y tener precisión en esto, especialmente teniendo en cuenta qué tipo de contrato es. Porque hay contratos que son más críticos y contratos que quizás no tienen mucho valor, o por no decir mucho valor, mucho capital económico. Entonces, hay que sopesar eso y, además, el impacto que pueda tener, por ejemplo, tomar una medida automática en una falsa alarma, si es muy negativo para el contrato o para el protocolo. Parar el servicio o reducir ciertas características de ese protocolo puede ser problemático. Entonces, hay que sopesar si es beneficioso o no hacer todo eso de manera automatizada. O hacer una cosa intermedia, que sea pausarlo en un corto periodo de tiempo, hasta que una persona, un humano, pueda revisarlo y ver si es una falsa alarma. En ese caso, lo volvemos a activar, por decirlo de alguna manera, o lo dejamos así porque puede ser un problema grave.

Para finalizar, Julián y Ángel, me gustaría pediros un consejo clave que le daríais a un usuario a nivel de seguridad en el mundo Web3. Bueno, eso es una pregunta bastante difícil, pero si se trata de un usuario que está tratando de publicar su proyecto, mi recomendación es que tenga en cuenta siempre los procesos estándar a nivel de seguridad. Por supuesto, también a nivel de calidad, pero la parte de seguridad es la que nos compete hoy. Esto incluye llevar el smart contract a la red de testnet, hacer las pruebas de seguridad en esta red y no publicar hasta que esto no haya ocurrido, así como implementar los mecanismos que mencionaba antes Julián, de tener el procedimiento de actualización ya implementado, para poder tomar medidas en caso de que algo se encuentre posteriormente. En el lado de los usuarios finales, creo que entender muy bien cada uno de los proyectos y quién hay detrás, y no invertir o apostar por proyectos desde el lado del desconocimiento, podría ser una de las principales recomendaciones.

Tu consejo, Julián, aunque me imagino que tendría mucho que ver con esto.

Sí, obviamente. Yo, por la parte de los usuarios, sí que quizás noto que podría haber un poco más de implicación por parte de los proyectos para facilitar esa interacción. Sabemos que la Web3 es un paso más de cara al usuario, que tiene que gestionar, y también un reparo por el hecho de gestionar dinero. Pero se podrían hacer ciertos avisos a los usuarios, como por ejemplo, cuando se conecta a un protocolo, como podría ser un swap o cualquier tipo de protocolo, en el momento en que acaba la sesión de escritura. Conectar el wallet de ese protocolo y, si por ejemplo ha dado permisos a que ese protocolo gaste una cierta cantidad de los tokens que tiene en el wallet, se podría negar al final de la sesión ese permiso. Generalmente, Uniswap o esos protocolos, cuando tú quieres interactuar, te piden que autorices el gasto de tus propios tokens y te ponen una cifra máxima, que puede ser el máximo número que pueda entrar en el cálculo matemático. Después de que tú hayas operado con un determinado número de tokens, se puede gastar el resto de tokens que te quedan. Entonces, eso ocurre mucho.

Ángel, Julián, muchísimas gracias por haber estado hoy. Muchas gracias.

## E1. Gestión Avanzada de Seguridaden Windows y Linux
### Gestión Avanzada de Seguridad (Video)
![[425.B7E1_Gestión_Avanzada_de_Seguridad.mp4]]
[Gestion Avanzada de Seguridad](https://app.web3mba.io?wvideo=wbef19sbmp)

Lo que se siente delictivo sobre el delito de violencia tiene distintos cometidos. Por ejemplo, podemos destacar las normas ISO, que permiten, a través de la certificación, validar que tenemos un sistema de gestión de seguridad de la información, así como una correcta gestión de los riesgos, de nuestra gobernanza y de todo lo que se refiere a políticas, procedimientos y planes, para garantizar así una adecuada gestión de la seguridad de la información.

Así como tenemos las normas ISO, también han aparecido otros tipos de normativas y frameworks de ciberseguridad que cumplen el objetivo de demostrar de forma fehaciente, a través de una certificación, que la empresa está madura en la gestión de la ciberseguridad y en la gestión de los procesos que hacen a la seguridad de la información. Para esto, ¿cómo se desarrollan y logran estas certificaciones? Bueno, estas certificaciones se obtienen pasando por un proceso de auditoría.

¿Qué es un proceso de auditoría o cómo se concibe una auditoría? Una auditoría puede tener distintos enfoques. El enfoque principal de una auditoría es validar, frente a un conjunto de requisitos, que generalmente están dados por una norma, cuál es el grado de madurez que tiene la empresa en relación con esos requisitos. A modo de ejemplo, podemos mencionar la norma ISO 27001 y PCI DSS, que es la normativa que nos permite gestionar y transaccionar con datos de tarjetas de crédito. Estas normativas tienen distintas formas de validarse, pero ambas comparten algo en común: se llevan a cabo a través de auditores.

En el caso de PCI DSS, los auditores son llamados QSI o QSR, y en el caso de ISO 27001, se les denomina auditores de seguridad. La función de ambos es exactamente la misma: a partir de los requerimientos de una norma, validar si la empresa realmente está cumpliendo con cada uno de los requisitos con el fin de garantizar la seguridad de la información. Las auditorías suelen ser anuales, tanto en el caso de ISO 27001 como de PCI DSS, pero también suelen ser externas. Es decir, generalmente uno no puede auditarse a sí mismo, sino que tiene que contratar una empresa totalmente independiente, que no puede ser la misma que haya asesorado a la empresa antes de la auditoría.

Esto es importante para las organizaciones al momento de decidir trabajar con un proveedor. Es fundamental validar que la empresa sea independiente y que tenga todos los mecanismos de seguridad para poder confiar en nuestra información e incluso en nuestros servicios. Para esto, es muy importante que las empresas puedan demostrar el grado de compromiso que tienen con la seguridad. La forma de hacer esto es certificándose en varias normas de seguridad, lo que les permite, a través de las mismas, demostrar su compromiso con la seguridad de la información y con las buenas prácticas que llevan a una correcta gestión de la información.

Es por esto que es importante el papel del auditor en este tipo de empresas y en este tipo de situaciones. Es esencial que el auditor sea una persona independiente que pueda gestionar durante todo el ciclo de la auditoría, desde la reunión de inicio hasta la reunión de cierre, todos los requisitos, para validar exactamente que la empresa esté cumpliendo con todos los requisitos que exige la auditoría y que también esté cumpliendo con todos los requisitos legales que, a veces, también nos establecen distintas certificaciones o reconocimientos cuando trabajamos, por ejemplo, con entes estatales o con entes públicos.

Para contratar una empresa o un proveedor, es muy importante que el proveedor o la empresa cuente con certificaciones en seguridad de la información. Esto nos permite tener cierto grado de tranquilidad al momento de trabajar con ese proveedor, porque sabemos que ha pasado por un proceso de certificación, ha sido auditado y nos da la confianza de que, al obtener la certificación, esa empresa ha cumplido de forma satisfactoria con todos los requisitos que la normativa exige. Por lo tanto, es una garantía poder trabajar siempre con empresas que estén certificadas y que cuenten con certificación en seguridad de la información, porque de esta forma nos aseguramos de que esa empresa podrá gestionar de forma adecuada nuestra información y podrá trabajar con los datos que nosotros les brindemos, teniendo siempre en cuenta y siendo consciente de lo que requiere la protección de esos datos.

Esto es importante destacar porque muchas empresas, a veces, frente a dos proveedores que ofrecen lo mismo, siempre la recomendación es optar por el proveedor que tenga alguna certificación o el que más certificaciones tenga en el ámbito de la ciberseguridad. Principalmente si se trata de un proveedor que va a gestionar nuestros datos personales o información sensible que le vamos a compartir de nuestra organización.

¿En qué nos ayudan las auditorías? Las auditorías nos ayudan a mejorar. Generalmente, las auditorías son puntos de control en la organización que, con una mirada externa de un auditor, nos permiten identificar nuestras debilidades a nivel de procesos y procedimientos, y de esta forma poder mejorar, en pro de optimizar también los procesos, la documentación y la calidad de la seguridad de la información.

Las auditorías tienen etapas bien definidas. Hay una etapa que se llama el inicio de la auditoría, que es cuando se realiza la reunión inicial, en la cual se busca explicar la metodología que se va a utilizar por parte del auditor, generar conciencia sobre quiénes deberían estar presentes durante esos días de auditoría y también presentar el roadmap a seguir.

El paso siguiente, que se suele realizar en todas las auditorías, es una revisión documental en la cual se envía información a la empresa que nos está auditando. Esta empresa hace una revisión exhaustiva de todos los documentos que les compartimos y, con esta información, se lleva a cabo la tercera etapa de la auditoría, que es la auditoría presencial, donde se auditan todos los procesos que ya han sido leídos y de los cuales se tiene información sobre cómo estamos operando dentro de la organización.

Por último, se realiza una reunión de cierre, en la cual se presentan algunos hallazgos o no conformidades de la auditoría y el nivel de criticidad de estos hallazgos o no conformidades. Muchas veces, una vez que se cierra la auditoría, se vuelve a programar una revisión, dando un espacio de tiempo de entre 15 y 20 días, en el cual se vuelve a realizar la auditoría sobre los hallazgos que se han encontrado para ver si, en ese lapso de tiempo, la empresa pudo cambiar y corregir esas malas prácticas o mejorar algún procedimiento o proceso que no estaba del todo bien o que no tenía el nivel de detalle que pudiera garantizar al auditor que se estaban realizando de forma segura.

Una vez que el proceso de QA interno de la empresa auditora finaliza, se lleva a cabo lo que se llama una reunión final con el cliente, en la cual se le dan los resultados, que en este caso sería que todo el proceso de auditoría fue positivo y que la empresa va a adquirir la certificación correspondiente. Este tipo de auditorías son muy importantes porque, como comentaba anteriormente, permiten validar la madurez y los procesos internos de las organizaciones en temas de seguridad de la información.

### Auditoría de Sistemas
La auditoría de sistemas supone la revisión y evaluación de los controles y sistemas de informática, así como su utilización, eficiencia y seguridad en la empresa, la cual procesa la información.

Gracias a la Auditoría de Sistemas como alternativa de control, seguimiento y revisión, el proceso informático y las tecnologías se emplean de manera más eficiente y segura, garantizando una adecuada toma de decisiones.

La Auditoría de Sistemas consiste en:
1. La verificación de controles en el procesamiento de la información e instalación de sistemas, con el objetivo de evaluar su efectividad y presentar también alguna recomendación y consejo.
2. Verificar y juzgar de manera objetiva la información.
3. Examen y evaluación de los procesos en cuanto a informatización y trato de datos se refiere. Además, se evalúa la cantidad de recursos invertidos, la rentabilidad de cada proceso y su eficacia y eficiencia.
4. El análisis y evaluación realizados a través de la auditoría de sistemas debe ser objetivo, crítico, sistemático e imparcial. El informe de auditoría final deberá ser un claro ejemplo de la realidad de la empresa en cuanto a los procesos y la informatización se refiere, para tomar mejores decisiones y mejorar en el negocio.

#### Objetivos de la auditoría de sistemas
La presencia de la tecnología cada vez en más ámbitos empresariales, hace necesario un sistema de control, seguimiento y análisis, tal como la auditoría de sistemas.

- En primer lugar, se precisa garantizar la seguridad a la hora de tratar los datos, dotándolos de privacidad y buen uso. 
- En segundo lugar, para hacer del sistema informático, un proceso mucho más eficiente y rentable, permitiendo detectar errores y tomando decisiones de manera inmediata.

Así, podemos decir que los objetivos de la auditoría de sistemas son:
1. Mejorar la relación coste-beneficio de los sistemas de información.
2. Incrementar la satisfacción y seguridad de los usuarios de dichos sistemas informatizados.
3. Garantizar la confidencialidad e integridad a través de sistemas de seguridad y control profesionales.  
    Minimizar la existencia de riesgos, tales como virus o hackers, por ejemplo.
4. Optimizar y agilizar la toma de decisiones.
5. Educar sobre el control de los sistemas de información, puesto que se trata de un sector muy cambiante y relativamente nuevo, por lo que es preciso educar a los usuarios de estos procesos informatizados.

Por tanto, la auditoría de sistemas es un modo de control y evaluación no solo de los equipos informáticos en sí. Su ámbito de actuación gira también en torno al control de los sistemas de entrada a dichos equipos (claves y códigos de acceso), archivos y seguridad de los mismos, etc. 

> La auditoría de sistemas es fundamental para garantizar el desempeño y seguridad de los sistemas informáticos de una empresa, que sean confiables a la hora de usarlos y garanticen la máxima privacidad posible.

### Tipos de Auditoria
Entre los tipos de auditoria que existen podemos mencionar:
1. Auditoría en sistemas
2. Auditoría Informática
3. Auditoría de Información
4. Auditoría en Sistemas de Información

#### 1 | Auditoría en Sistemas
Es la rama que se encarga de llevar a cabo la evaluación de normas, controles, técnicas y procedimientos que se tienen establecidos en una empresa para lograr confiabilidad, oportunidad, seguridad y confidencialidad de la información que se procesa a través de los sistemas de información. 

La auditoría de sistemas es una rama especializada de la auditoría que promueve y aplica conceptos de auditoría en el área de sistemas de información.

##### Objetivos de la Auditoría en Sistemas
1. Mejor relación costo – beneficio de los sistemas automáticos diseñados e implementados por el área de Procesamiento de datos.
2. Incrementa la satisfacción de los usuarios de los Sistemas computarizados.
3. Asegura una mayor Integridad, Confidencialidad y Confiabilidad (La Tríada de la Ciberseguridad) de la información mediante la recomendación de seguridad y control.
4. Conocer la situación actual del área informática y las actividades, esfuerzos necesarios para lograr los objetivos propuestos.
5. Brindar seguridad al personal, Datos, Hardware, Software e instalaciones.
6. Minimizar existencia de riesgo usando la tecnología de información.
7. Decisiones de inversión, evitar gastos innecesarios.
8. Capacitación y educación sobre controles en los sistemas informáticos.

#### 2 | Auditoría Informática
La auditoría en informática es la revisión y la evaluación de los controles, sistemas, procedimientos de informática; de los equipos de cómputo, su utilización, eficiencia y seguridad, de la organización que participan en el procesamiento de la información, a fin de que por medio del señalamiento de cursos alternativos se logre una utilización más eficiente y segura de la información que servirá para una adecuada toma de decisiones.

##### Características de la auditoría informática
Al ser una modalidad de auditoría concerniente a un ámbito tan específico, cuenta con una serie de características propias respecto a otros tipos de mediciones o análisis:
1. Los profesionales auditores no solamente deben tener capacitación para la realización de trabajos de auditoría, sino que también formación específica relacionada con un contexto tecnológico o informático. Una correcta auditoría de este tipo debe servir para mostrar una imagen fiel sobre la adaptación al entorno digital y tecnológica de una compañía.
2. La evaluación no solamente requiere de estudio de los activos informáticos físicos de una compañía, sino que debe ir más allá abarcando la práctica y el uso de las plantillas. Los trabajadores deben estar cualificados y preparados para el máximo aprovechamiento de estas herramientas.
3. Debe existir un constante seguimiento a las actualizaciones informáticas del mercado y su aplicación empresarial.

Es importante destacar que, con la proliferación de nuevas metodologías y aplicaciones tecnológicas en la empresa, los informes de auditoría de tipo informático son cada vez más frecuentemente requeridos.  

##### Evolución de la auditoría informática
Debido al potencial crecimiento tecnológico experimentado en las últimas décadas y la rápida expansión de la red en prácticamente la totalidad de los negocios, la vigilancia de los sistemas informáticos empleados resulta inevitable. Gracias a la globalización existe cada vez una mayor adaptación por parte de empresas a estándares de software comunes. Esto ocurre, por ejemplo, en el ámbito de la ofimática.

#### 3 | Auditoría de Información
La auditoría de la información es una rama especializada de la auditoría que promueve y aplica conceptos de auditoría en el área de sistemas de información. 

El objetivo final que tiene el auditor es dar recomendaciones a la alta gerencia para mejorar o lograr un adecuado control interno en ambientes de tecnología informática con el fin de lograr mayor eficiencia operacional y administrativa.

La naturaleza especializada de la auditoría de los Sistemas de Información y las habilidades necesarias para llevar a cabo este tipo de auditorías, requieren el desarrollo y la promulgación de normas generales para la auditoría de los Sistemas de Información.

##### Objetivos de la Auditoría de la Información
El objetivo es asegurar que la información que circulará por el sistema sea la más apropiada para la organización. Mediante la Auditoría de la Información se pretende que la organización solamente reciba aquella información que sea relevante para sus intereses, reduciendo de esta manera el silencio (no obtención de información relevante) y el ruido (obtención de información no relevante) y los requerimientos de información de la organización (o sea, de la información que precisa para poder funcionar correctamente).

1. Identificar recursos de información (RI) dentro de la organización.
2. Identificar requerimientos de información de la organización.
3. Identificar, crear y ajustar los flujos y procesos, donde se maneja la información de la organización.
4. Identificar costes, beneficios y oportunidades de los RI.
5. Integrar los RI con los objetivos de la organización.
6. Evaluar la conformidad con las normativas existentes sobre información y su uso.

Todo esto con el fin de:
1. **Duplicidades:** Dentro de una misma organización en ocasiones se crea y almacena la misma información de manera independiente.
2. **Carencias:** No compartir información produce vacíos que atentan contra el correcto funcionamiento de determinadas unidades de negocio dentro de la organización.
3. **Inconsistencias:** Mantener la misma información de modo independiente puede dar lugar a informaciones contradictorias.

##### Metodología
En la actualidad no existe una metodología estándar para realizar una auditoría de información, sin embargo, se pueden desarrollar una serie de actividades y técnicas que pueden ayudar a realizarlas:
1. **Inventario físico:**  
    Es el proceso de identificación y categorización de los recursos de información de una forma sistemática. De esta forma, se proporciona una fotografía de lo que la organización posee en términos de recursos de información en un momento determinado.
2. **Mapificación de la información (Infomap):**   
    Constituye una forma gráfica de representar los recursos de información que hay en la organización y las interrelaciones entre estos. El mapa de recursos indica hasta qué punto los recursos de información son básicos, de qué modo se encuentran posicionados (geográficamente, departamentalmente, desde un punto de vista técnico), cómo interactúan, quién los utiliza, quién es el responsable, etc.
3. **Análisis de las necesidades de información:**  
    Tiene como finalidad principal determinar qué información requieren los empleados y la dirección de la organización para desarrollar sus papeles y alcanzar los objetivos.
4. **Gráficos de procesos y flujos de trabajo:**  
    Los gráficos de procesos junto con los flujos de trabajo pueden constituir una buena herramienta de trabajo en el ámbito de las auditorías de la información.
5. **Procesos de control y verificación:**  
    En una auditoría de la información, se deben establecer también los procesos de control y verificación.

El resultado de estos procesos puede consistir en un informe o incluso, un certificado que confirme que todo es correcto o que incluya recomendaciones de mejora. Hay que tener presente que el mapa de recursos de información, o mapa documental, puede constituir uno de los principales resultados del proceso de la auditoría de información.

En el caso del mapa documental, este detalla qué documentos se encuentran dentro de la organización, a qué tipo de funciones se encuentran vinculados y dan respuesta, quién tiene la responsabilidad y el acceso a esos documentos, en qué soporte están disponibles, dónde y cómo se encuentran accesibles y qué relación o nivel de integración tienen con el resto de los sistemas de información de la organización. También se establece la localización de todos los documentos dentro de los estándares y los procedimientos de la organización, así como su valor para el conocimiento corporativo.

#### 4 | Auditoría en Sistemas de Información
La auditoría de los sistemas de información se define como cualquier auditoría que abarca la revisión y evaluación de todos los aspectos (o de cualquier porción de ellos) de los sistemas automáticos de procesamiento de la   información, incluidos los procedimientos no automáticos relacionados con ellos y las interfaces correspondientes.

En general una auditoría de sistemas de información incluye todo el ciclo de vida de la tecnología e información que está bajo investigación. Quien esté interesado en llevar a cabo una auditoría puede ser el dueño de unos activos, un agente regulador, los administradores del sistema o cualquiera otro que esté interesado en la operación del entorno del sistema.

##### Objetivo de la Auditoría en Sistemas de Información
Los objetivos de la auditoría también pueden ser distintos. Por ejemplo, puede buscar evaluar la integridad operativa o confirmar que los datos privados de clientes de un banco no estén expuestos a personas no autorizadas.

En realidad, el alcance va a depender del objetivo que persiga la auditoría.

Lo importante es que el alcance de la auditoría debe estar definido desde el inicio, así como también, las personas, los recursos, los procesos y la tecnología necesaria para cumplir el objetivo propuesto. Si alguno de estos falla, es muy probable que se generen errores en el proceso, en consecuencia se pierden recursos y tiempo.

Cuando el alcance se define, las organizaciones hacen un enlace entre el auditor y el representante de seguridad de la información. Este último es el encargado de detallar la información que necesita el auditor sobre los sistemas, los manuales de los sistemas, los diagramas de arquitectura, las políticas y otros documentos que suelen solicitar los auditores antes de la evaluación.

##### Prácticas de gestión y entorno de control
La recopilación previa de los datos y documentos le permite al auditor verificar que el alcance establecido es correcto.

Asimismo, establece las prácticas de gestión o los objetivos de control como base de las pruebas en su auditoría.

Las prácticas de gestión sirven como indicadores para determinar que el alcance fue logrado con éxito. A cada práctica de gestión se le asocia un conjunto de actividades, éstas son la evidencia de que se cumple con el objetivo de control propuesto. El auditor debe probar las actividades para saber si arrojan evidencia confiable. Las prácticas de gestión junto con los planes de prueba se conocen como programa de auditoría.

Para llevar a cabo el programa de auditoría, el auditor debe contactar al representante de seguridad de la empresa para solicitar que programe la reunión de apertura. Lo ideal es que el representante reciba al auditor y le facilite la comunicación con el personal TI de la empresa en caso de que se requieran sus servicios durante las pruebas de auditoría.

##### Trabajo de campo, hallazgos y controles compensatorios
En una auditoria el proceso en el que se identifican a las personas, los procesos y la tecnología dentro de un entorno de sistemas se conoce como trabajo de campo.

La comunicación entre el auditor y el experto del área en evaluación debe ser expedita.

El término control compensatorio se usa cuando la práctica de gestión se cumple, aunque la actividad de control que se esperaba no existe, ya que la actividad recién encontrada compensa la falta de la esperada. Esto suele usarse cuando los representantes de seguridad no informan adecuadamente al auditor, ya sea por desconocimiento o inexperiencia.

Si el auditor no encuentra la evidencia de una de las prácticas de gestión, se trata de un hallazgo. En auditoría un hallazgo tiene las siguientes partes:
1. **Condición:** Es la descripción objetiva de la evidencia.
2. **Criterios:** Se menciona el estándar que da indicios de por qué la condición afecta la capacidad de gestión para lograr la práctica de gestión.
3. **Causa:** Lo que originó la debilidad dentro de la práctica.
4. **Efecto:** Indica el riesgo que la condición presenta a la organización auditada con respecto a lo comercial.
5. **Recomendación.**

El auditor tendrá una lista de hallazgos mientras realice el trabajo de campo. Por ello es fundamental el contacto permanente del representante de la empresa con el auditor, para preguntarle por los hallazgos. La función del contacto es buscar evidencias que proporcionen seguridad de que el objetivo de control se está cumpliendo y así se elimine el o los hallazgos.

#### Informe de evaluación
Cualquier auditoría siempre culmina con un informe de evaluación. En él se plasman las observaciones y la opinión del auditor.

La estructura es la siguiente: en primer lugar, se presenta el objetivo, después se describe brevemente la metodología, luego una declaración del auditor y finalmente presenta recomendaciones para reducir el impacto de los hallazgos.

### Auditoría de Sistemas en GNU / Linux
La auditoría de sistemas en GNU/Linux cuenta con varias herramientas para poder realizarla de forma completa. 

Esto facilita enormemente el trabajo de un auditor y al mismo tiempo transforma a este sistema en un espacio donde las auditorias pueden ser mucho más completas, transparentes y legibles. 

Esto es posible gracias a su política de software libre y al hecho de que la información puede ser consultada en bruto mediante herramientas especializadas o las mismas herramientas nativas del sistema.

#### Systemd-journald, transformando la auditoria integrada de GNU/Linux
GNU/Linux ha cambiado mucho en los últimos años, hasta el punto en que muchas de las herramientas de auditoría se han centralizado en un nuevo servicio (o _daemon_, como se conocen en GNU/Linux) llamado _systemd_. 

**systemd**, es un programa con múltiples servicios, siendo el principal de ellos el de inicio del sistema (o init, la parte más importante para iniciar un SO) y sobre este init se construyen una serie de herramientas complementarias, entre ellas la que nos permite obtener información de auditoría de sistema, _systemd-journald_.

_systemd-journald_ es un servicio del sistema que recoge y almacena datos de registro. Crea y mantiene diarios estructurados e indexados basados en la información de registro que se recibe de diversas fuentes:
1. Mensajes de registro del núcleo, a través de _kmsg_ (kernel messeges, una interfaz que nos permite ver los mensajes manejados por el kernel.
2. Mensajes de registro del sistema simples, a través de la llamada _libc_, _syslog_ (una función estándar de libc, que les permite a las aplicaciones enviar información al log de sistema).
3. Mensajes estructurados de registro del sistema a través de la API nativa de Journal. Esto facilita la creación de programas para el análisis minucioso de la información que está en el log.
4. Salida estándar y error estándar de las unidades de servicio. Ya que systemd maneja el inicio (init) del sistema, todos los servicios dependen del mismo para su puesta en marcha, de esta forma, todo mensaje tanto de los servicios/Daemon y programas dependen de enviar su información de logging a systemd y estos son pasados a _systemd-journald_ quien gestiona su almacenamiento y control.
5. Permite crear por defecto registros de auditoría, originados por el subsistema de auditoría del núcleo.

_systemd-journald_ permite mejorar las capacidades de auditoría de los sistemas GNU/Lniux, sin embargo, resulta complejo de manejar y carece de ciertas funciones avanzadas que otras herramientas pueden brindar.

Para usar _systemd-journald_ debes tener un GNU/Linux actual y con soporte para este sistema, algo que la mayoría de distribuciones GNU/Linux ya ofrecen.  

##### Ejemplo de uso de _systemd-journald_
- Supongamos deseamos realizar una auditoría de seguridad y queremos saber que usuarios han usado el computador bajo análisis desde su instalación hasta el actual momento. 
- En este caso _systemd-journald_ tiene herramientas que nos permiten revisar esto de forma muy sencilla usando el comando:
- journalctl --full --unit systemd-logind.service

Esta línea se explica de forma muy rápida:
- **journalctl** es el programa que nos permite controlar y acceder al log del sistema manejado por _systemd-journald_.
- **La opción --full** nos indica que debemos obtener todo el registro, mientras que la opción --unit nos permite indicar el servicio/unidad que analizaremos.

En este caso, como queremos saber los inicios registrados por nuestro computador desde su instalación hasta la actualidad, debemos apuntar a la unidad/servicio systemd-logind.service que es la encargada de esto.

Todo este comando al ser ejecutada en una consola nos permite obtener la siguiente información:

![[428.B7E1_boot.png]]

En la captura se puede ver toda la información de inicios de sesión y booteo (encender desde 0 el computador) desde su instalación hasta la actualidad.

#### Lynis, auditorias de seguridad completa sobre GNU/Linux
- Otra herramienta potente para realizar auditorías de seguridad sobre GNU/Linux, especialmente para endpoints (computadores de nuestros trabajadores) o servidores básicos es Lynis.
- Lynis es una herramienta de auditoría de sistemas de software libre y código abierto, desarrollada y ofrecida por Cisofy. 
- Puede correr en la gran mayoría de sistemas operativos basados en Unix, como GNU/Linux, macOS, OpenBSD, AIX, Solaris y FreeBSD, entre otros. 
- Aunque dispone de muchas opciones de análisis (incluso se puede complementar con plugins), el funcionamiento base es el de analizar una serie de aspectos del sistema y comprobar si la configuración es la correcta.

Antes que nada, es importante aclarar que se trata de un análisis general, que se encarga de analizar parámetros muy dispares entre sí. De hecho, es interesante porqué te permite entender muy bien como la seguridad en GNU/Linux (y en cualquier sistema), no depende en absoluto de una sola herramienta ni configuración, sino que es una suma de muchísimos factores.

Al final, en base a los resultados obtenidos, te ofrecerá una puntuación orientativa sobre 100, lo que ellos denominan el “hardening index”, junto con un buen registro de todos los warnings y las medidas correctivas que te sugiere aplicar. Pero de esto ya hablamos luego al final del examen.

Dependiendo del contexto en el que te encuentres, habrá una serie de puntos que, o directamente no aplicarán, o bien no serán suficientemente importantes como para tenerlos en cuenta, por lo que el propio Lynis ya te recomiende que deshabilites los exámenes que no apliquen en tu caso, para que la puntuación sea más acertada.

Lynis tiene dos opciones: 
1. **Lynis Community:** Una versión gratuita que puedes instalar desde su repositorio de GitHub.
2. **Lynis Enterprise:** Una completa suite de auditoría y hardening para empresas que incluye capacidad de únicas y soluciones que puedes aplicar para alcanzar baselines (Compliance) de seguridad como PCI-DSS, HIPAA, ISO 27001, ISO 27002 y GPDR.

En la siguiente imagen podrás ver parte de la información que Lynis ofrece como parte de su sistema de auditoría para sistemas (usando Ubuntu 22.04 LTS y Lynis Community para la prueba).

![[428.B7E1_lynis.png]]

 #### Otras opciones para auditoria dentro de GNU/Linux
Por supuesto, también existen otras opciones de software para auditoria dentro de ambientes GNU/Linux y entre esas opciones podemos mencionar:
1. **Nessus:** Suite completa de auditoría de sistemas.
2. **Auditd:** Un Daemon/servicio para GNU/Linux que permite mantener un registro de auditoría completa de los sistemas, muy usado en conjunto con AppArmor (un sistema de seguridad avanzado – MAC – dentro de GNU/Linux).
3. **SailPoint:** Una suite comercial de soluciones de auditoría y ciberseguridad para empresas, considerada como una de las más completas del mercado y con soporte tanto para sistemas GNU/Linux como para Windows, MacOS, Android e iOS, lo que le hace perfecta para ambientes heterogéneos.
4. **Tripwire:** es otra solución de auditoría y ciberseguridad que está disponible tanto para sistemas GNU/Linux y Windows.
5. **OpenVAS:** Un analizador de vulnerabilidades y herramienta de auditoría de ciberseguridad que también puedes usar para este tipo de tareas.

### Auditoría de Sistemas en Windows
Al igual que GNU/Linux, Windows también cuenta con potentes capacidades de auditoría y revisión de eventos incluidos en el sistema operativo.

Estas opciones pueden revisarse de forma nativa usando dos ejecutables:
1. Directivas de seguridad local
2. Visor de eventos

#### 1 | Directivas de seguridad local
Es un ejecutable que nos permite controlar la forma en como Windows maneja toda la seguridad básica, por defecto, del sistema operativo y todo ello gracias a una ventana desde la que podemos acceder y configurar cada una de las partes.

- Desde aquí, el administrador del sistema, puede configurar las opciones de seguridad que se aplicarán a la instalación de Windows. 
- Un punto positivo de este sistema es que, si forma parte de un Directorio Activo (es decir, está integrado a un servidor Windows empresarial dentro de un grupo AD definido) todas estas tareas pueden ser realizadas en el servidor y aplicarse a cada una de las computadoras que forman parte de la organización de forma automática (conocido como aprovisionamiento AD). 
- Esto también es posible en GNU/Linux, pero no forma parte de esos SO por defecto (a excepción de sus versiones de pago y dirigidas a empresas como Red Hat Linux).
- En todo caso, **Directivas de Seguridad Local** es el espacio donde puedes configurar el nivel de seguridad de Windows, el cual, por defecto, suele ser bastante débil.

  ![[429.B7E1_config.png]]

Puedes configurar, por ejemplo, las directivas de seguridad de las contraseñas de Windows, tal como se puede apreciar en la siguiente imagen:

![[429.B7E1_directivas.png]]

Rápidamente, podemos ver que:
1. Las contraseñas no se almacenan usando criptografía reversible, por lo que no se podrá saber la clave del mismo, si en algún momento se obtiene acceso al archivo donde se almacenan.
2. Se hace auditoría a las contraseñas para que estas tengan como mínimo 8 caracteres de longitud.
3. Se exige un historial de 3 contraseñas (evitando la repetición de contraseñas)
4. La contraseña debe cumplir con requisitos de complejidad (uso de mayúsculas, minúsculas, número y símbolos).
5. Cada contraseña será válida solo por 180 días, luego de eso deberá cambiarse durante un inicio de sistema.

En definitiva, hablamos de una herramienta con capacidad para alterar por completo la funcionalidad de Windows. 

Podemos indicar al sistema que evite que las cuentas de "Administrador" (incluyendo la integrada en el propio Windows) puedan instalar aplicaciones en el sistema o, incluso, bloquearnos el acceso al mismo. Este mismo caso sucede en GNU/Linux si hacemos un bloqueo de cuentas sin tener en cuenta las consecuencias.  
  
**Hay otra opción parecida a la anterior, pero menos agresiva:** 

1. Deshabilitar las cuentas de Administración que vienen por defecto en Windows. 
2. Crear nuestro propio usuario Administrador con otro nombre y contraseña.
3. Hacer que cada usuario no administrador, sin ese rol activo, no pueda hacer elevación de privilegios, impidiéndole instalar software con permisos administrativos.

- Paraleleamente a esto, podemos crear una regla de auditoría que nos avise en caso de que una persona haya querido tener acceso a dichos permisos, lo que nos permitiría detectar el intento y hacer las correcciones pertinentes.  
- El resultado de una política de seguridad de este tipo, es que se reducen los problemas de seguridad de Windows y, al mismo tiempo, se mantiene un alto nivel de seguridad en la organización.

En la siguiente imagen, un ejemplo de la configuración necesaria para este tipo de comportamiento:

![[429.E7B1_comportamiento.png]]

Como puedes ver, las capacidades de Windows en este sentido son enormes, y toda esa información es controlada a nivel interno del sistema, pudiendo ser examinada con la siguiente herramienta:

#### 2 | Visor de eventos
Todo lo que sucede en el sistema queda grabado como un evento que puede ser analizado en el Visor de Eventos de Windows.

![[429.E7U1_visor.png]]

Si el ejecutable de Directivas de seguridad local, te permite ajustar la seguridad y el nivel de auditoría de Windows, el visor de eventos, te permite revisar de forma minuciosa toda la actividad del sistema. Desde las aplicaciones que se inician y el acceso a los privilegios del sistema, hasta los errores y advertencias del kernel y de todos los servicios que tienen lugar en Windows (incluyendo las directivas de seguridad aplicadas).

De esa forma, estos dos ejecutables se transforman en la parte más importante de la seguridad de Windows y de su auditoría a nivel de sistema operativo, algo básico para mantener no solo tus endpoint protegidos, sino también los servidores Windows que puedas tener en tu organización, ya que la seguridad tanto en Server como Desktop de Windows, se puede manejar con las mismas herramientas.

#### Otras herramientas de auditoria para Windows
1. **ADAudit Plus:**  
    Se trata de una potente herramienta de auditoría y análisis para ambientes Windows, con capacidad para integrarse en ambientes de Directorios Activos, Análisis de políticas de grupo para Directorio Activo (GPO AD), chequeo de software y actividad en la redEventLog Analyzer, es otra gran herramienta de auditoría y análisis de eventos y sistema para Windows.
2. **HardeningKitty:**  
    Es una herramienta de doble uso, por un lado, sirve para auditar ciertas configuraciones de seguridad dentro de Windows, por el otro, sirve para desplegar dichas opciones de seguridad y realizar enforce de medidas de seguridad en Windows con vista a cumplir los baselines de seguridad empresarial de Microsoft.

Estas herramientas son básicas para conocer nuestros sistemas y sus capacidades de auditoría (tanto en Windows y GNU/Linux), pero aún queda camino por recorrer, especialmente para hacer enforce o hardening de seguridad, el cual veremos en las siguientes unidades.

### Separación de privilegios
En informática, la separación de privilegios es una técnica que se usa para atenuar el daño potencial de un ataque a la seguridad de una computadora.

Básicamente, consiste en evitar que los usuarios tengan acceso a permisos innecesarios para sus funciones, evitando de esta forma que puedan obtener acceso a partes sensibles de la organización. 

En sistemas operativos como GNU/Linux, Windows o en plataformas Web propias, la separación de privilegios es, y debe ser, parte fundamental de las medidas de seguridad que se toman para proteger la infraestructura, los datos y toda la organización. 

Tomemos el siguiente caso como ejemplo:
- La usuaria "A", es una visitante de SoftTech Inc, una empresa que le ha invitado a probar un nuevo software para dar su _feedback_ desde una web especializada en ciberseguridad. 
- A es una visitante desde el punto de vista del administrador de sistema, por lo que sus permisos deben ser limitados para que solo pueda ver información básica de la empresa. 
- En tal sentido, el acceso a los recursos de la empresa por parte de "A" serán limitados por la estrategia de "separación de privilegios" aplicada por la empresa, garantizando que "A" pueda contactar con las personas autorizadas, acceder al software que probará y su documentación. El resto de los recursos de la empresa están estrictamente prohibidos y, de necesitar algún acceso más elevado, tendrá que pedir autorización explicita al administrador del sistema para que este acceso le sea otorgado (ej: acceso a recursos de impresión, escáner o cualquier otro que requiera). 

En este sencillo ejemplo, podemos ver como "A" es puesta en una especie de zona de seguridad, con límites bien establecidos en cuanto a los recursos que puede usar y cómo puede usarlos. Desde un principio "A" tiene el menor privilegio posible para que realice su trabajo y solo podrá obtener más privilegios si realiza la petición de los mismos y el análisis del administrador de sistema le da acceso. 

El ejemplo se puede llevar a niveles de total y práctica paranoia, especialmente si el ambiente al que se está entrando es de extrema seguridad y confidencialidad. Por ejemplo, hay empresas donde ingresar un pendrive está totalmente prohibido y tener uno en tu poder puede llevarte a tener graves problemas, incluso legales. En otras empresas, está prohibido que los empleados, incluso los de alto nivel (ej: un directivo), puedan acceder a determinados espacios y de hacerlo también se corre el riesgo de tener problemas legales o directamente enfrentar una sanción laboral (llegando a niveles de despido si la falta es grave). 

**Este ejemplo anterior nos dice una cosa:** La separación de privilegios no solo se da a nivel digital (en equipos, sistemas informáticos y más) sino también a nivel físico, todo ello de acuerdo a las medidas de seguridad que se deseen aplicar en la organización. Dicho esto, nos centraremos en la separación de privilegios digitales y hablaremos de cómo se realiza la misma.

#### Principio de menor privilegio
En su forma más básica, un programa de computadora se bifurca en dos procesos. El programa principal descarta sus privilegios más altos y el programa más pequeño mantiene privilegios altos, con el fin de realizar tareas muy determinadas, por medio de una comunicación interproceso segura.

De esta manera, cualquier ataque exitoso contra el programa principal ganará un acceso mínimo, a pesar de que el par de programas será aún capaz de realizar operaciones privilegiadas.

Básicamente el principio se reduce a:
> "Garantiza a todas las partes de un sistema, solo los privilegios necesarios para que puedan realizar su trabajo, el resto prohíbelo."

Este principio lo podemos encontrar en cualquier sistema operativo actual y es la base fundamental con el que se inicia la seguridad en dichos sistemas. Por supuesto, este esquema se ha hecho más complejo a medida que las necesidades de seguridad en informática se han hecho más complejas. 

Por supuesto, este drop o abandono de privilegios funciona a varios niveles que examinaremos a continuación: 

1. Sistema Operativo
2. Aplicaciones

##### A nivel de sistema operativo
Con la llegada de los sistemas multi-usuario, se generaron estructuras de permisos que incluyen la creación de usuarios y grupos.

De esta manera, se pueden crear usuarios con permisos distintos y específicos, y grupos que pueden compartir un conjunto de permisos global, con lo que se lograr tener una gran granularidad a la hora de ofrecer acceso a ciertos recursos computacionales o informáticos.

Este sistema lo vimos primero en sistemas UNIX donde su ambiente multiusaurio llevó a la creación de este sistema de permisos, que hoy en día se conoce como DAC (Discretionary Access Control o Control de Acceso Discrecional). Este sistema es básico en sistemas operativos como GNU/Linux, OpenBSD, NetBSD, Solaris, FreeBSD y básicamente cualquier UNIX-like. 

Por supuesto, este sistema ha sido mejorado a lo largo de los años con el fin de ofrecer controles de acceso mucho más finos y seguros, como lo es la inclusión de ACL (Access Control List o Listas de Control de Acceso), funciones especiales como los namespace y capabilities (estas son funciones especiales a nivel de kernel que garantizan acceso a funciones privilegiadas a su nivel). En todo caso, los programas pueden hacer uso de estas funciones de forma individual o en conjunto, con el fin de garantizar acceso a los permisos que necesitan en momentos específicos y el resto simplemente los desechan cuando ya no son necesarios. De esta manera, los desarrolladores crean software que es seguro en su más bajo nivel. 

Sin embargo, incluso con este nivel de seguridad, la informática necesita de niveles más altos de seguridad y es allí donde llegan aproximaciones como MAC (Mandatory Access Control o Control de Acceso Mandatory). En este caso, los sistemas más conocidos con SELinux (creado por la NSA para el sistema operativo Linux e integrado de forma predeterminada al kernel), AppArmor (desarrollado por Novell para Linux e integrado al kernel de forma predeterminada), Tomoyo (creado por NTT Data para Linux, forma parte del kernel), Capsicum (creado por la Universidad de Cambridge para FreeBSD) y MAC (creado para FreeBSD por el equipo de desarrollo). 

Seguramente te llama la atención que una herramienta de la NSA (cuyo trabajo es romper sistema y espiarte) esté dentro de una lista de sistema de seguridad y, que además forme parte de Linux siendo este un proyecto libre. Pero la realidad del código es innegable, SELinux es seguro, de hecho, de toda la lista es el sistema más seguro en su tipo (hablando de MAC). 

Ahora bien ¿qué diferencias hay entre estos sistemas (DAC y MAC)? Un ejemplo rápido puede darte una idea clara de cómo se puede aplicar el principio de menor privilegio usando estos sistemas:

- **Supongamos que ejecutamos Firefox en un sistema Ubuntu.** Resulta que hemos visitado una Web y hay un código malicioso que intenta obtener información de nuestro sistema específicamente de la carpeta /home/usuario/.ssh, con el fin de robar nuestras claves SSH y vulnerar cualquier sistema en el que hayamos registrado la misma. 

Así tenemos dos posibles resultados:
1. En una instalación por defecto de Ubuntu (AppArmor instalado, pero desactivado, solo funciona el sistema DAC), la Web maliciosa que ha comprometido el proceso de Firefox podrá leer la carpeta /home/usuario/.ssh y cualquier dato en nuestra carpeta de usuarios, porque siendo un proceso iniciado por nosotros, Firefox tiene esa capacidad y permiso. En pocas palabras, hemos sido vulnerados incluso contando con una instalación "segura" por defecto y toda la separación de privilegios que Firefox y el sistema DAC nos ofrece. 
2. En una instalación fortalecida de Ubuntu (AppArmor instalado y activo), este evento podría evitarse con una regla explicita para AppArmor que evite el acceso a la carpeta /home/usuario/.ssh. Incluso aunque Firefox es ejecutado con nuestros permisos (DAC por defecto), la protección de MAC (dada por AppArmor) evitaría y registraría para su posterior auditoria el acceso a dicha información porque el administrador de sistema ha especificado que dicha carpeta no puede ser accedido por Firefox (o cualquier otro programa que se configure como tal). 

Básicamente, la seguridad de MAC evitaría que el programa lea esos archivos, y no se puede traspasar esa seguridad a menos que se comprometa el kernel del sistema (algo mucho más complejo y difícil) lo que agrega más seguridad. 

Los sistemas MAC pueden incluso prohibir a los programas acceso privilegiado a las capabalities o capacidades a nivel del kernel, restringiendo aún más sus permisos, incluso más allá de las restricciones creadas por sus desarrolladores, por lo que se convierten en una herramienta poderosa para cumplir con el principio del menor privilegio. 

En Windows, esta capacidad también es posible y con un nivel de granularidad mucho mayor debido a que Windows usa un sistema híbrido. Por un lado, es capaz de usar un sistema DAC (con usuarios, grupos y ACLs) al que se les añade soporte a descriptores de seguridad (SIDs) que son aplicados a nivel de sistema de archivo (una estructura que te permite almacenar información de forma legible para la computadora). 

Además, Windows también es capaz de crear una estructura de seguridad basada en RBAC (Role Based Access Control - Control de Acceso Basado en Roles) que completa su seguridad no solo a nivel de sistema operativo, sino de organización (nuevamente, gracias a los servicios de Directorio Activo). 

Finalmente, Windows también aplica sistemas de permisos MAC conocido como (Mandatory Integrity Control), el cual podemos ver aplicado en la siguiente imagen:

![[430.B7E1_mandatory.png]]

Todo esto deja muy en claro que el principio de menor privilegio, no solo es una buena practica de seguridad, sino que es el principio de una serie de medidas que se encaminan a proteger el sistema operativo y las aplicaciones que se ejecutan sobre el mismo.

##### A nivel de aplicaciones
Ahora bien, todo lo anterior enmarca una serie de protecciones que es posible habilitar y usar en nuestro sistema operativo y que, por tanto, también pueden ser usadas en las aplicaciones que se desarrollen para el mismo. 

Por supuesto, en el caso de que esas aplicaciones sean Web, la aplicación de estas medidas directamente no es posible, pero también aplica el hecho de separar las funciones relevantes de esa aplicación para que solo sean accesible por aquellos con el nivel de privilegio necesario para acceder a dichas funciones. 

¿Pero cómo se aplica este principio de menor privilegio en aplicaciones?. Veamos dos ejemplos:

###### 1 | El caso de Firefox como aplicación de escritorio 
Los desarrolladores de Firefox usan funciones especiales a nivel de kernel y de herramientas del sistema operativo, para garantizar que la aplicación solo use los privilegios necesarios para su funcionamiento. 

En tal caso, los devs se aseguran de tomar esos privilegios, crear estructuras de seguridad (como un sandbox) para aislar las partes delicadas y delimitar lo que pueden hacer. De esa manera se aseguran que el navegador solo use los recursos que necesita (ej: para mostrarte un vídeo en pantalla y reproducir el sonido, Firefox debe ser capaz de acceder a la gráfica de tu computador y la tarjeta de sonido, escribir los datos necesarios para que el controlador de esos dispositivos muestre la imagen y reproduzca el sonido que estás viendo). 

Esto, por supuesto, es una buena practica de seguridad y en condiciones normales puede ofrecer un alto nivel de seguridad, pero en muchos casos, incluso estas medidas de seguridad pueden no ser suficientes para garantizar el principio de mínimo privilegio. Esto se debe a que las funciones para lograrlo no están bien mantenidas o bien porque se ha de usar un alto nivel de acceso para asegurar su funcionamiento y luego dropear ese nivel de acceso a su mínimo. 

En ambos casos, existe una ventana de oportunidad para explotar el sistema y por ello los administradores deben conocer y estudiar el software que se usa en una organización para pensar en forma de evitar tales casos, incluso si son improbables que sucedan. 

###### 2 | El caso de Firefox para GNU/Linux.
En este caso, los desarrolladores hacen uso de tres _capabilities_ a nivel del kernel. Estas _capabilities_ son funciones de alto nivel de acceso por medio del kernel que, si bien son "seguras", han sido el punto de origen de muchos problemas de seguridad (y seguirán siéndolo). 

Esas _capabilities_ usadas por Firefox son:
1. **CAP_SYS_CHROOT,** que le permite crear un entorno de "root falso", útil para hacer un sandbox.
2. **CAP_SYS_ADMIN,** que le permite al proceso de Firefox obtener permisos administrativos (durante el inicio del proceso para configurar el acceso necesario a los recursos del sistema). 
3. **CAP_SYS_PTRACE,** le permite acceder a funciones de _debug_ de procesos.
4. **CAP_SYS_SETGID y CAP_SYS_SETUID,** funciones especiales a nivel del kernel para manipular descriptores de usuarios y grupos. 
5. **Acceso a user_namespace (userns),** para crear espacios de ejecución separados y seguros. 

**Un análisis de seguridad rápido, ya nos da una advertencia rápida:** Firefox no debería tener acceso a tales funciones, porque es un riesgo de seguridad. El simple hecho de que incluso la documentación oficial del kernel Linux ya indiqué que no debes usar CAP_SYS_ADMIN, salvo casos muy especiales, es un llamado de atención, porque el acceso administrativo no debería ser tan fácilmente usado (nuevamente, el principio es usar la menor cantidad de permisos para un programa). 

Esta situación ha llevado a que las organizaciones preocupadas por la ciberseguridad se usen sistemas MAC para prohibir que Firefox acceda a esas funciones especiales, y al mismo tiempo, para evitar que pueda acceder e interactuar con elementos que no son necesarios para su funcionamiento. Un buen ejemplo de esto, lo vemos aplicado en el proyecto Chromium quien lleva bastante tiempo desarrollando nuevas formas de sandboxing dejando de lado estas capabilities y al mismo tiempo ofreciendo niveles de seguridad parecidos o superiores. 

Ahora bien, este principio de menor privilegio también puede aplicarse a nivel de aplicaciones Web, y para ello se sigue el mismo proceso: se crea un núcleo administrativo al que solo pueden acceder completamente ciertos usuarios configurados para tal fin, y el resto solo podrán acceder a los niveles permitidos, usando para ello todos los elementos de seguridad y autenticación que los frameworks usados nos permitan. 

![[430.B7E1_linux.png]]

#### Segregación de funciones de usuarios y del personal de IT.
Acciones que deben llevar a cabo los administradores de sistemas para proteger los sistemas informáticos de la compañía y evitar la elevación de privilegios entre roles y sistemas:
1. **Separación de roles.**  
    En este caso, se debe tener en cuenta que los usuarios deben usar cuentas distintas para actividades cotidianas y para labores de administración (Ej: DOMAIN\luser y DOMAIN\adm.luser). La cuenta de administrador no tendrá buzón de correo, permisos de navegación, entre otros, que pueden poner en riesgo dicha cuenta.
2. **Compartimentalizar el acceso a recursos.**  
    Esto significa que las labores de administración estarán compartimentalizadas, de tal forma un único administrador no debe tener acceso a la plataforma, el almacenamiento y backups al mismo tiempo. También se pueden usar estrategias de aislamiento en base a distribución geográfica.
3. **Separación de entornos.**  
    Las cuentas de administradores no deberán loguearse en los mismos escritorios donde se utiliza la navegación y el correo. Por tanto, deberán utilizarse "máquinas de salto" dedicadas y aisladas para las labores de administración.
4. **Aislamiento VLAN de administración.**  
    Los equipos de escritorio no deben tener conectividad directa con los servidores y DMZ (Zona Desmilitarizada). Solo deben alcanzar a las "máquinas de salto" situadas en la VLAN (LAN Virtuales) de administración, serán estas las que puedan conectar a los servidores. Deberán crearse las máquinas de salto necesarias para compartimentalizar la administración en distintos segmentos.
5. **Principio del mínimo privilegio para cuentas de servicio.**  
    Las cuentas de servicio deberán poder iniciar sesión únicamente en el parque de servidores destinado a ese servicio. Se establecerán las medidas de monitorización que alerten cuando estas son usadas desde / hacia otras ubicaciones o cuando el tipo de inicio de sesión no coincide con el esperado.
6. Utilización de herramientas de monitorización hostids o EDR, seguridad endpoints y elementos de red para la detección de patrones de escalada de privilegios y explotación hacia otros sistemas.
7. El uso de máquinas virtuales, contenedores o jaulas (jails) para llevar a cabo las tareas no privilegiadas, como la navegación o la creación de servicios, esta es una buena práctica de seguridad y facilita la puesta en marcha de los mismos y su mantenimiento.

#### Bloqueos y controles de seguridad a nivel de red
Acciones a nivel de red con las que bloquear tráfico malicioso.

1. **Segmentación.**  
    Segmentar la red en VLANs y aplicar reglas de filtrado a nivel de red y de puestos de trabajo y servidores, limitando por ejemplo las conexiones RDP y SMB. 
2. **Servicios de reputación IP.**  
    Bloquear tráfico de navegación a TOR o a sistemas no clasificados. Se puede hacer uso de servicios gratuitos como https://check.torproject.org/cgi-bin/TorBulkExitList.py o https://www.dan.me.uk/torlist/, así como de feeds comerciales que identifiquen VPNs o IPs de dudosa reputación.
3. **Bloqueo de tráfico a Internet.**  
    Los sistemas internos (tanto servidores como puestos de trabajo) no deberían tener acceso directo a internet. El tráfico DNS, HTTP y HTTPs debe estar restringido al proxy de navegación, que incluya ACLs restrictivas.
4. **Estudio de rutas de compromiso.**  
    Realización de tests de intrusión periódicos o de ejercicios de red team para descubrir rutas de compromiso y mejorar los procedimientos de respuesta ante incidentes.
5. **Monitorizar accesos remotos.**  
    Monitorizar y controlar las conexiones VPN, Citrix, RDP o VDI entrantes. Es recomendable agregar doble factor de autenticación a todos los grupos autorizados para establecer conexiones remotas y notificar al usuario de la conexión.

#### Medidas de seguridad a nivel de sistemas
Acciones que se pueden llevar a cabo para lograr la protección del puesto de trabajo.

1. **Firewall del sistema operativo.**  
    Bloqueo de tráfico y comunicaciones a servicios de SMB, tanto a nivel de firewall como de aislamiento de estaciones de trabajo dentro de su mismo segmento de red.
2. **Actualizaciones de seguridad.**  
    Controlar de forma centralizada las actualizaciones de seguridad de estaciones de trabajo y servidores haciendo uso de soluciones de control de actualizaciones como WSUS.
3. **Contraseñas.**  
    La gestión de contraseñas es otro de esos aspectos que puede suponer un artículo en mismo. A grandes rasgos, no permitir la compartición de contraseñas de administrador local ni de usuarios administrativos entre grupos de servidores y de estaciones de trabajo. Además, las directivas de contraseñas deben evitar patrones predecibles (meses, años, nombre de la empresa). Esto se puede complementar con el reseteo periódico de tickets de kerberos para prevenir ataques de persistencia.
4. **Bloqueos de ejecución.**  
    Bloqueo de herramientas de volcado de contraseñas de memoria, protecciones y endurecimiento de entornos de ejecución. 
5. **Hardening.**  
    Creación y mantenimiento de guías de _hardening_ o _bastionado_ para garantizar cifrado de comunicaciones, protecciones frente a ataques de MITM (Man-in-the-Middle) es fundamental. En el caso puntual de un servidor de ficheros, se pueden prevenir las acciones maliciosas llevas a cabo por un _ransomware_ o por un atacante y definir una estrategia de prevención en servidores de ficheros con la implantación de FSRM. FSRM es un rol de los servidores de ficheros de Microsoft que permite definir acciones y ejecutar scripts frente a la escritura de ciertos tipos de ficheros.

### Separación de privilegios
En informática, la separación de privilegios es una técnica que se usa para atenuar el daño potencial de un ataque a la seguridad de una computadora.

Básicamente, consiste en evitar que los usuarios tengan acceso a permisos innecesarios para sus funciones, evitando de esta forma que puedan obtener acceso a partes sensibles de la organización. 

En sistemas operativos como GNU/Linux, Windows o en plataformas Web propias, la separación de privilegios es, y debe ser, parte fundamental de las medidas de seguridad que se toman para proteger la infraestructura, los datos y toda la organización. 

Tomemos el siguiente caso como ejemplo:
- La usuaria "A", es una visitante de SoftTech Inc, una empresa que le ha invitado a probar un nuevo software para dar su _feedback_ desde una web especializada en ciberseguridad. 
- A es una visitante desde el punto de vista del administrador de sistema, por lo que sus permisos deben ser limitados para que solo pueda ver información básica de la empresa. 
- En tal sentido, el acceso a los recursos de la empresa por parte de "A" serán limitados por la estrategia de "separación de privilegios" aplicada por la empresa, garantizando que "A" pueda contactar con las personas autorizadas, acceder al software que probará y su documentación. El resto de los recursos de la empresa están estrictamente prohibidos y, de necesitar algún acceso más elevado, tendrá que pedir autorización explicita al administrador del sistema para que este acceso le sea otorgado (ej: acceso a recursos de impresión, escáner o cualquier otro que requiera). 

En este sencillo ejemplo, podemos ver como "A" es puesta en una especie de zona de seguridad, con límites bien establecidos en cuanto a los recursos que puede usar y cómo puede usarlos. Desde un principio "A" tiene el menor privilegio posible para que realice su trabajo y solo podrá obtener más privilegios si realiza la petición de los mismos y el análisis del administrador de sistema le da acceso. 

El ejemplo se puede llevar a niveles de total y práctica paranoia, especialmente si el ambiente al que se está entrando es de extrema seguridad y confidencialidad. Por ejemplo, hay empresas donde ingresar un pendrive está totalmente prohibido y tener uno en tu poder puede llevarte a tener graves problemas, incluso legales. En otras empresas, está prohibido que los empleados, incluso los de alto nivel (ej: un directivo), puedan acceder a determinados espacios y de hacerlo también se corre el riesgo de tener problemas legales o directamente enfrentar una sanción laboral (llegando a niveles de despido si la falta es grave). 

**Este ejemplo anterior nos dice una cosa:** La separación de privilegios no solo se da a nivel digital (en equipos, sistemas informáticos y más) sino también a nivel físico, todo ello de acuerdo a las medidas de seguridad que se deseen aplicar en la organización. Dicho esto, nos centraremos en la separación de privilegios digitales y hablaremos de cómo se realiza la misma.

#### Principio de menor privilegio
En su forma más básica, un programa de computadora se bifurca en dos procesos. El programa principal descarta sus privilegios más altos y el programa más pequeño mantiene privilegios altos, con el fin de realizar tareas muy determinadas, por medio de una comunicación interproceso segura.

De esta manera, cualquier ataque exitoso contra el programa principal ganará un acceso mínimo, a pesar de que el par de programas será aún capaz de realizar operaciones privilegiadas.

Básicamente el principio se reduce a:
> "Garantiza a todas las partes de un sistema, solo los privilegios necesarios para que puedan realizar su trabajo, el resto prohíbelo."

Este principio lo podemos encontrar en cualquier sistema operativo actual y es la base fundamental con el que se inicia la seguridad en dichos sistemas. Por supuesto, este esquema se ha hecho más complejo a medida que las necesidades de seguridad en informática se han hecho más complejas. 

Por supuesto, este drop o abandono de privilegios funciona a varios niveles que examinaremos a continuación: 

1. Sistema Operativo
2. Aplicaciones

##### A nivel de sistema operativo
Con la llegada de los sistemas multi-usuario, se generaron estructuras de permisos que incluyen la creación de usuarios y grupos.

De esta manera, se pueden crear usuarios con permisos distintos y específicos, y grupos que pueden compartir un conjunto de permisos global, con lo que se lograr tener una gran granularidad a la hora de ofrecer acceso a ciertos recursos computacionales o informáticos.

Este sistema lo vimos primero en sistemas UNIX donde su ambiente multiusaurio llevó a la creación de este sistema de permisos, que hoy en día se conoce como DAC (Discretionary Access Control o Control de Acceso Discrecional). Este sistema es básico en sistemas operativos como GNU/Linux, OpenBSD, NetBSD, Solaris, FreeBSD y básicamente cualquier UNIX-like. 

Por supuesto, este sistema ha sido mejorado a lo largo de los años con el fin de ofrecer controles de acceso mucho más finos y seguros, como lo es la inclusión de ACL (Access Control List o Listas de Control de Acceso), funciones especiales como los namespace y capabilities (estas son funciones especiales a nivel de kernel que garantizan acceso a funciones privilegiadas a su nivel). En todo caso, los programas pueden hacer uso de estas funciones de forma individual o en conjunto, con el fin de garantizar acceso a los permisos que necesitan en momentos específicos y el resto simplemente los desechan cuando ya no son necesarios. De esta manera, los desarrolladores crean software que es seguro en su más bajo nivel. 

Sin embargo, incluso con este nivel de seguridad, la informática necesita de niveles más altos de seguridad y es allí donde llegan aproximaciones como MAC (Mandatory Access Control o Control de Acceso Mandatory). En este caso, los sistemas más conocidos con SELinux (creado por la NSA para el sistema operativo Linux e integrado de forma predeterminada al kernel), AppArmor (desarrollado por Novell para Linux e integrado al kernel de forma predeterminada), Tomoyo (creado por NTT Data para Linux, forma parte del kernel), Capsicum (creado por la Universidad de Cambridge para FreeBSD) y MAC (creado para FreeBSD por el equipo de desarrollo). 

Seguramente te llama la atención que una herramienta de la NSA (cuyo trabajo es romper sistema y espiarte) esté dentro de una lista de sistema de seguridad y, que además forme parte de Linux siendo este un proyecto libre. Pero la realidad del código es innegable, SELinux es seguro, de hecho, de toda la lista es el sistema más seguro en su tipo (hablando de MAC). 

Ahora bien ¿qué diferencias hay entre estos sistemas (DAC y MAC)? Un ejemplo rápido puede darte una idea clara de cómo se puede aplicar el principio de menor privilegio usando estos sistemas:

- **Supongamos que ejecutamos Firefox en un sistema Ubuntu.** Resulta que hemos visitado una Web y hay un código malicioso que intenta obtener información de nuestro sistema específicamente de la carpeta /home/usuario/.ssh, con el fin de robar nuestras claves SSH y vulnerar cualquier sistema en el que hayamos registrado la misma. 

Así tenemos dos posibles resultados:
1. En una instalación por defecto de Ubuntu (AppArmor instalado, pero desactivado, solo funciona el sistema DAC), la Web maliciosa que ha comprometido el proceso de Firefox podrá leer la carpeta /home/usuario/.ssh y cualquier dato en nuestra carpeta de usuarios, porque siendo un proceso iniciado por nosotros, Firefox tiene esa capacidad y permiso. En pocas palabras, hemos sido vulnerados incluso contando con una instalación "segura" por defecto y toda la separación de privilegios que Firefox y el sistema DAC nos ofrece. 
2. En una instalación fortalecida de Ubuntu (AppArmor instalado y activo), este evento podría evitarse con una regla explicita para AppArmor que evite el acceso a la carpeta /home/usuario/.ssh. Incluso aunque Firefox es ejecutado con nuestros permisos (DAC por defecto), la protección de MAC (dada por AppArmor) evitaría y registraría para su posterior auditoria el acceso a dicha información porque el administrador de sistema ha especificado que dicha carpeta no puede ser accedido por Firefox (o cualquier otro programa que se configure como tal). 

Básicamente, la seguridad de MAC evitaría que el programa lea esos archivos, y no se puede traspasar esa seguridad a menos que se comprometa el kernel del sistema (algo mucho más complejo y difícil) lo que agrega más seguridad. 

Los sistemas MAC pueden incluso prohibir a los programas acceso privilegiado a las capabalities o capacidades a nivel del kernel, restringiendo aún más sus permisos, incluso más allá de las restricciones creadas por sus desarrolladores, por lo que se convierten en una herramienta poderosa para cumplir con el principio del menor privilegio. 

En Windows, esta capacidad también es posible y con un nivel de granularidad mucho mayor debido a que Windows usa un sistema híbrido. Por un lado, es capaz de usar un sistema DAC (con usuarios, grupos y ACLs) al que se les añade soporte a descriptores de seguridad (SIDs) que son aplicados a nivel de sistema de archivo (una estructura que te permite almacenar información de forma legible para la computadora). 

Además, Windows también es capaz de crear una estructura de seguridad basada en RBAC (Role Based Access Control - Control de Acceso Basado en Roles) que completa su seguridad no solo a nivel de sistema operativo, sino de organización (nuevamente, gracias a los servicios de Directorio Activo). 

Finalmente, Windows también aplica sistemas de permisos MAC conocido como (Mandatory Integrity Control), el cual podemos ver aplicado en la siguiente imagen:

![[430.B7E1_mandatory.png]]

Todo esto deja muy en claro que el principio de menor privilegio, no solo es una buena practica de seguridad, sino que es el principio de una serie de medidas que se encaminan a proteger el sistema operativo y las aplicaciones que se ejecutan sobre el mismo.

##### A nivel de aplicaciones
Ahora bien, todo lo anterior enmarca una serie de protecciones que es posible habilitar y usar en nuestro sistema operativo y que, por tanto, también pueden ser usadas en las aplicaciones que se desarrollen para el mismo. 

Por supuesto, en el caso de que esas aplicaciones sean Web, la aplicación de estas medidas directamente no es posible, pero también aplica el hecho de separar las funciones relevantes de esa aplicación para que solo sean accesible por aquellos con el nivel de privilegio necesario para acceder a dichas funciones. 

¿Pero cómo se aplica este principio de menor privilegio en aplicaciones?. Veamos dos ejemplos:

###### 1 | El caso de Firefox como aplicación de escritorio 
Los desarrolladores de Firefox usan funciones especiales a nivel de kernel y de herramientas del sistema operativo, para garantizar que la aplicación solo use los privilegios necesarios para su funcionamiento. 

En tal caso, los devs se aseguran de tomar esos privilegios, crear estructuras de seguridad (como un sandbox) para aislar las partes delicadas y delimitar lo que pueden hacer. De esa manera se aseguran que el navegador solo use los recursos que necesita (ej: para mostrarte un vídeo en pantalla y reproducir el sonido, Firefox debe ser capaz de acceder a la gráfica de tu computador y la tarjeta de sonido, escribir los datos necesarios para que el controlador de esos dispositivos muestre la imagen y reproduzca el sonido que estás viendo). 

Esto, por supuesto, es una buena practica de seguridad y en condiciones normales puede ofrecer un alto nivel de seguridad, pero en muchos casos, incluso estas medidas de seguridad pueden no ser suficientes para garantizar el principio de mínimo privilegio. Esto se debe a que las funciones para lograrlo no están bien mantenidas o bien porque se ha de usar un alto nivel de acceso para asegurar su funcionamiento y luego dropear ese nivel de acceso a su mínimo. 

En ambos casos, existe una ventana de oportunidad para explotar el sistema y por ello los administradores deben conocer y estudiar el software que se usa en una organización para pensar en forma de evitar tales casos, incluso si son improbables que sucedan. 

###### 2 | El caso de Firefox para GNU/Linux.
En este caso, los desarrolladores hacen uso de tres _capabilities_ a nivel del kernel. Estas _capabilities_ son funciones de alto nivel de acceso por medio del kernel que, si bien son "seguras", han sido el punto de origen de muchos problemas de seguridad (y seguirán siéndolo). 

Esas _capabilities_ usadas por Firefox son:
1. **CAP_SYS_CHROOT,** que le permite crear un entorno de "root falso", útil para hacer un sandbox.
2. **CAP_SYS_ADMIN,** que le permite al proceso de Firefox obtener permisos administrativos (durante el inicio del proceso para configurar el acceso necesario a los recursos del sistema). 
3. **CAP_SYS_PTRACE,** le permite acceder a funciones de _debug_ de procesos.
4. **CAP_SYS_SETGID y CAP_SYS_SETUID,** funciones especiales a nivel del kernel para manipular descriptores de usuarios y grupos. 
5. **Acceso a user_namespace (userns),** para crear espacios de ejecución separados y seguros. 

**Un análisis de seguridad rápido, ya nos da una advertencia rápida:** Firefox no debería tener acceso a tales funciones, porque es un riesgo de seguridad. El simple hecho de que incluso la documentación oficial del kernel Linux ya indiqué que no debes usar CAP_SYS_ADMIN, salvo casos muy especiales, es un llamado de atención, porque el acceso administrativo no debería ser tan fácilmente usado (nuevamente, el principio es usar la menor cantidad de permisos para un programa). 

Esta situación ha llevado a que las organizaciones preocupadas por la ciberseguridad se usen sistemas MAC para prohibir que Firefox acceda a esas funciones especiales, y al mismo tiempo, para evitar que pueda acceder e interactuar con elementos que no son necesarios para su funcionamiento. Un buen ejemplo de esto, lo vemos aplicado en el proyecto Chromium quien lleva bastante tiempo desarrollando nuevas formas de sandboxing dejando de lado estas capabilities y al mismo tiempo ofreciendo niveles de seguridad parecidos o superiores. 

Ahora bien, este principio de menor privilegio también puede aplicarse a nivel de aplicaciones Web, y para ello se sigue el mismo proceso: se crea un núcleo administrativo al que solo pueden acceder completamente ciertos usuarios configurados para tal fin, y el resto solo podrán acceder a los niveles permitidos, usando para ello todos los elementos de seguridad y autenticación que los frameworks usados nos permitan. 

![[430.B7E1_linux.png]]

##### Segregación de funciones de usuarios y del personal de IT.
Acciones que deben llevar a cabo los administradores de sistemas para proteger los sistemas informáticos de la compañía y evitar la elevación de privilegios entre roles y sistemas:
1. **Separación de roles.**  
    En este caso, se debe tener en cuenta que los usuarios deben usar cuentas distintas para actividades cotidianas y para labores de administración (Ej: DOMAIN\luser y DOMAIN\adm.luser). La cuenta de administrador no tendrá buzón de correo, permisos de navegación, entre otros, que pueden poner en riesgo dicha cuenta.
2. **Compartimentalizar el acceso a recursos.**  
    Esto significa que las labores de administración estarán compartimentalizadas, de tal forma un único administrador no debe tener acceso a la plataforma, el almacenamiento y backups al mismo tiempo. También se pueden usar estrategias de aislamiento en base a distribución geográfica.
3. **Separación de entornos.**  
    Las cuentas de administradores no deberán loguearse en los mismos escritorios donde se utiliza la navegación y el correo. Por tanto, deberán utilizarse "máquinas de salto" dedicadas y aisladas para las labores de administración.
4. **Aislamiento VLAN de administración.**  
    Los equipos de escritorio no deben tener conectividad directa con los servidores y DMZ (Zona Desmilitarizada). Solo deben alcanzar a las "máquinas de salto" situadas en la VLAN (LAN Virtuales) de administración, serán estas las que puedan conectar a los servidores. Deberán crearse las máquinas de salto necesarias para compartimentalizar la administración en distintos segmentos.
5. **Principio del mínimo privilegio para cuentas de servicio.**  
    Las cuentas de servicio deberán poder iniciar sesión únicamente en el parque de servidores destinado a ese servicio. Se establecerán las medidas de monitorización que alerten cuando estas son usadas desde / hacia otras ubicaciones o cuando el tipo de inicio de sesión no coincide con el esperado.
6. Utilización de herramientas de monitorización hostids o EDR, seguridad endpoints y elementos de red para la detección de patrones de escalada de privilegios y explotación hacia otros sistemas.
7. El uso de máquinas virtuales, contenedores o jaulas (jails) para llevar a cabo las tareas no privilegiadas, como la navegación o la creación de servicios, esta es una buena práctica de seguridad y facilita la puesta en marcha de los mismos y su mantenimiento.

##### Bloqueos y controles de seguridad a nivel de red
Acciones a nivel de red con las que bloquear tráfico malicioso.

1. **Segmentación.**  
    Segmentar la red en VLANs y aplicar reglas de filtrado a nivel de red y de puestos de trabajo y servidores, limitando por ejemplo las conexiones RDP y SMB. 
2. **Servicios de reputación IP.**  
    Bloquear tráfico de navegación a TOR o a sistemas no clasificados. Se puede hacer uso de servicios gratuitos como https://check.torproject.org/cgi-bin/TorBulkExitList.py o https://www.dan.me.uk/torlist/, así como de feeds comerciales que identifiquen VPNs o IPs de dudosa reputación.
3. **Bloqueo de tráfico a Internet.**  
    Los sistemas internos (tanto servidores como puestos de trabajo) no deberían tener acceso directo a internet. El tráfico DNS, HTTP y HTTPs debe estar restringido al proxy de navegación, que incluya ACLs restrictivas.
4. **Estudio de rutas de compromiso.**  
    Realización de tests de intrusión periódicos o de ejercicios de red team para descubrir rutas de compromiso y mejorar los procedimientos de respuesta ante incidentes.
5. **Monitorizar accesos remotos.**  
    Monitorizar y controlar las conexiones VPN, Citrix, RDP o VDI entrantes. Es recomendable agregar doble factor de autenticación a todos los grupos autorizados para establecer conexiones remotas y notificar al usuario de la conexión.

##### Medidas de seguridad a nivel de sistemas
Acciones que se pueden llevar a cabo para lograr la protección del puesto de trabajo.

1. **Firewall del sistema operativo.**  
    Bloqueo de tráfico y comunicaciones a servicios de SMB, tanto a nivel de firewall como de aislamiento de estaciones de trabajo dentro de su mismo segmento de red.
2. **Actualizaciones de seguridad.**  
    Controlar de forma centralizada las actualizaciones de seguridad de estaciones de trabajo y servidores haciendo uso de soluciones de control de actualizaciones como WSUS.
3. **Contraseñas.**  
    La gestión de contraseñas es otro de esos aspectos que puede suponer un artículo en mismo. A grandes rasgos, no permitir la compartición de contraseñas de administrador local ni de usuarios administrativos entre grupos de servidores y de estaciones de trabajo. Además, las directivas de contraseñas deben evitar patrones predecibles (meses, años, nombre de la empresa). Esto se puede complementar con el reseteo periódico de tickets de kerberos para prevenir ataques de persistencia.
4. **Bloqueos de ejecución.**  
    Bloqueo de herramientas de volcado de contraseñas de memoria, protecciones y endurecimiento de entornos de ejecución. 
5. **Hardening.**  
    Creación y mantenimiento de guías de _hardening_ o _bastionado_ para garantizar cifrado de comunicaciones, protecciones frente a ataques de MITM (Man-in-the-Middle) es fundamental. En el caso puntual de un servidor de ficheros, se pueden prevenir las acciones maliciosas llevas a cabo por un _ransomware_ o por un atacante y definir una estrategia de prevención en servidores de ficheros con la implantación de FSRM. FSRM es un rol de los servidores de ficheros de Microsoft que permite definir acciones y ejecutar scripts frente a la escritura de ciertos tipos de ficheros.

## E2. Hardening de Sistemas y Servicios
### Hardening de Sistemas y Servicios (Video)
![[431.B7E2_Hardening_de_Sistemas_y_Servicios.mp4]]
[Hardening de Sistemas y Servicios](https://app.web3mba.io?wvideo=gkhltba83q)

Lo que siente el activador sobre Hardening. Hoy en día, existen metodologías para fortificar los sistemas. Estas metodologías, tradicionalmente conocidas como Hardening, son las que se utilizan en el sistema de control de la luz. Lo que nos permiten es seguir determinadas guías que ya están disponibles públicamente. Las más conocidas suelen ser las guías de C-Security, que es una empresa dedicada a generar guías de hardening. Se conocen como benchmarks también en inglés. Estas guías nos permiten generarlas, seguirlas y poder hardenizar o mejorar la seguridad de nuestros sistemas.

Las guías de hardening, a diferencia de otras guías, no son únicas, sino que suelen estar asociadas a distintas tecnologías o a diferentes equipamientos informáticos. Por ejemplo, podemos encontrar guías de hardening para Switch Cisco, para Switch Fortinet, así como guías de hardening para Firewall Checkpoint y para firewalls de distintas marcas. También podemos encontrar guías de hardening por sistemas operativos, como Linux, Windows y Mac. Además, contamos con guías de hardening a nivel de aplicaciones o aplicativos. Por ejemplo, en el ámbito de los servidores de aplicación, podemos encontrar guías de hardening para Tomcat, para JBoss y para otros servidores de aplicación, así como para una gran cantidad de distintos aplicativos, como Nginx, Apache y muchas otras aplicaciones que solemos usar día a día.

¿Qué son básicamente las guías de hardening? Las guías de hardening son documentos de buenas prácticas que nos permiten, a partir de distintas configuraciones en estos equipos, sistemas operativos o aplicaciones, aumentar el nivel de seguridad de los mismos. Un caso práctico de lo que es el hardening, o de la ausencia de este, lo podemos observar, por ejemplo, al ingresar a un sitio web, escribir una dirección errónea y lo primero que nos devuelve nuestro navegador es un error en el cual, debajo, se puede leer la versión que se está utilizando y qué aplicativo se está empleando. El más común es encontrar mensajes de error que indican, por ejemplo, "Apache, WebServer, versión 2.1.4" o "Tomcat", entre otros. Esto sucede porque ese servidor o aplicativo no ha recibido la aplicación de guías de hardening, lo que puede suponer un riesgo para la organización.

¿Por qué? Porque estamos ante lo que se llama Information Disclosure. Estamos proporcionando información a un posible atacante sobre qué sistemas estamos utilizando. Por ejemplo, si nuestro sitio web está instalado, por llamarlo de alguna manera, en un servidor que ejecuta Apache y que está en la versión 2.1.4, esto permite que un atacante busque en Internet posibles formas de explotar vulnerabilidades relacionadas con ese aplicativo y esa versión. Así, al buscar vulnerabilidades para explotar Apache versión 2.1.4, puedo encontrar una lista considerable de exploits que me permitirán intentar vulnerar la seguridad de ese sitio web.

La guía de hardening lo que hace es garantizarnos que todas las configuraciones por defecto que vienen en las aplicaciones, sistemas o equipos sean debidamente tratadas, mejorando así la postura de seguridad de nuestros sistemas y equipos. Por ejemplo, otro caso práctico son los firewalls. Los firewalls o equipos de comunicaciones suelen venir con usuarios predeterminados, como "admin" y "admin" como contraseña. Muchas veces, aunque en organizaciones es más difícil, a nivel doméstico solemos dejar las claves predeterminadas que vienen en los equipos, en los routers y en los firewalls de Internet. También dejamos usuarios predeterminados creados, los cuales deberíamos deshabilitar si aplicamos unas correctas guías de hardening, para evitar posibles intrusiones.

Todos sabemos que Microsoft, hace unos años, tenía el usuario invitado activo, que no requería credenciales y que permitía a cualquier persona ingresar al sistema utilizando esta cuenta. Con el tiempo, se ha dado cuenta de que no es una buena práctica; incluso en versiones posteriores, ya traían ese usuario deshabilitado, y hoy en día, en algunas versiones más recientes, ni siquiera existe la posibilidad de tener un usuario invitado. La ventaja del hardening es que, al aplicar esta guía, nos garantizamos que, por ejemplo, los servicios que no utilicemos en nuestros sistemas no estén activos. Servicios que, por ejemplo, se instalan de forma predeterminada y que vienen con una configuración por defecto, pueden ser personalizados, evitando que muestren las versiones y permitiendo que los usuarios que vienen por defecto no sean utilizados, creando nosotros nuestros propios usuarios.

Generalmente, cuando uno realiza una instalación de estos aplicativos, suelen venir los features o ítems de seguridad deshabilitados. Estas guías de hardening nos proporcionan todas las buenas prácticas para habilitar esos controles de seguridad, eliminar usuarios que vienen por defecto y establecer una contraseña, por ejemplo, a un equipo físico, un firewall o un puerto que nos permite conectarnos a la consola del equipo físicamente. Todo este tipo de seguridad nos la proporcionan las guías de hardening. Es una forma de buenas prácticas que debemos seguir para que todos nuestros aplicativos, ya sean sistemas operativos o aplicaciones a nivel de hardware, nos permitan estar tranquilos y seguros de que no estamos exponiendo nada que haya venido de forma predeterminada, lo cual podría ser un vector de ataque explotable por algún atacante.

Las guías de hardening, como comenté anteriormente, más conocidas son las de C-Security, que son accesibles de forma gratuita desde Internet y que, a través de ellas, hoy en día, la mayoría de las empresas las utilizan para hardenizar todos sus equipos. Otro ejemplo que podemos observar en lo que respecta al hardening es cuando ingresamos a algunos sitios web y podemos ver que, frente a un error, aparece una gran cantidad de información que nos permite entender qué tecnología está utilizando la empresa. Por ejemplo, si hay una base de datos, a veces, cuando falla la conexión a la base de datos y entramos a un sitio web, se nos presenta la falla de la conexión. Este tipo de mensajes suelen ocurrir cuando las organizaciones no aplican guías de hardening, lo que no asegura que todos los mensajes predeterminados y las pantallas de error sean personalizadas, etcétera, lo que nos permite mejorar en todos los aspectos de seguridad que tienen todos los dispositivos, aplicaciones y sistemas operativos de forma predeterminada.

El año pasado, hubo un ataque bastante conocido en el cual se utilizaba un servicio de Microsoft que suele dejarse habilitado de forma predeterminada. Este servicio es utilizado por Microsoft para reportar errores a su propia plataforma. Cuando uno tiene un error en Windows y aparece una pantalla o algún error a nivel de sistema operativo, este servicio informa a Microsoft de que ese sistema operativo ha tenido un error, recabando esa información para luego poder sacar fixes, actualizaciones, entre otros. El año pasado, este servicio fue utilizado por atacantes para robar información. Cuando se preguntó a la mayoría de las empresas si estaban utilizando este servicio, un alto porcentaje de las personas consultadas afirmaron que sí lo tenían activo, a pesar de que no era útil para la propia empresa, ni para la organización, ni para la aplicación que estaba ejecutando ese servidor. Sin embargo, como era un servicio que ya venía iniciado, quedó activo.

Si se consulta la guía de Sys de hardening, se puede visualizar que este servicio es uno de los que se recomienda deshabilitar en todos los servidores Windows y plataformas Microsoft. Sin embargo, en un alto porcentaje de empresas, al no aplicar estas guías de hardening, se vieron afectadas por este ataque que, como mencioné anteriormente, utilizó este servicio nativo de Microsoft para enviar errores, el cual fue aprovechado para enviar información sensible y, de esta forma, hacer uso de la información de esos equipos.

### Fundamentos de Hardening
![[432.B7E2_hardening..png]]

Hardening, la acepción en inglés de "endurecimiento", aplicado en seguridad informática es el proceso de asegurar un sistema mediante la reducción de vulnerabilidades en el mismo.

Esto se consigue eliminando software, servicios, usuarios, etc. innecesarios en el sistema, así como cerrando puertos que tampoco estén en uso, además de muchos otros métodos y técnicas que veremos durante este pequeño resumen introductorio al Hardening de sistemas.

Es un conjunto de actividades que son llevadas a cabo por el administrador de un sistema operativo para reforzar al máximo posible la seguridad de su equipo. **¿Su propósito?: Entorpecer la labor del atacante y ganar tiempo para poder minimizar las consecuencias de un inminente incidente de seguridad e incluso, en algunos casos, evitar que este se concrete en su totalidad.**

Una de las primeras cosas que hay que dejar en claro del Hardening de sistemas operativos es que no necesariamente logrará forjar equipos “invulnerables”. Es importante recordar que, según el modelo de defensa en profundidad, el host es solo una capa de este. En otras palabras, un factor más a considerar dentro del gran número de puntos a ser tomados en cuenta para defender “globalmente” un sistema.

#### Elementos básicos de Hardening de sistemas
1. **Configuraciones necesarias para protegerse de posibles ataques físicos o de hardware de la máquina.** Entre otras actividades, destacan el upgrade de firmware, el establecimiento de contraseñas complejas para el arranque del equipo y la configuración de la BIOS, la deshabilitación de inicio de sistema para cualquier unidad que no sea el disco duro principal, y en casos de servidores, la deshabilitación de dispositivos ópticos, usb o similares, para evitar cualquier entrada de malware desde un medio de almacenamiento externo.
2. **Instalación segura del sistema operativo.** Esto implica, entre otras cosas, el considerar al menos dos particiones primarias (1 para el sistema operativo en sí y otra para carpetas y archivos de importancia), el uso de un sistema de archivos que tenga prestaciones de seguridad, y el concepto de instalación mínima, es decir, evitando la instalación de cualquier componente de sistema que no sea necesario para el funcionamiento del sistema.
3. **Activación y/o configuración adecuada de servicios de actualizaciones automáticas,** para asegurar que el equipo tendrá todos los parches de seguridad que entrega el proveedor al día. En caso de que se encuentre dentro de una corporación, es adecuado instalar un servidor de actualizaciones, que deberá probar en un entorno de laboratorio el impacto de la instalación de actualizaciones antes de instalarlas en producción.
4. **Instalación, configuración y mantención de programas de seguridad** tales como Antivirus, Antispyware, y un filtro Antispam según las necesidades del sistema.
5. **Configuración de la política local del sistema,** considerando varios puntos relevantes:
6. **Política de contraseñas robusta,** con claves caducables, almacenamiento histórico de contraseñas (para no usar contraseñas cíclicas), bloqueos de cuentas por intentos erróneos y requisitos de complejidad de contraseñas.
7. **Renombramiento y posterior deshabilitación de cuentas estándar del sistema,** como administrador e invitado.
8. **Asignación correcta de derechos de usuario,** de tal manera de reducir las posibilidades de elevación de privilegios, y tratando siempre de limitar al mínimo los privilegios y/o derechos de los usuarios activos.
9. **Configuración de opciones de seguridad generales,** como aquellas relacionadas con rutas de acceso compartido, apagado de sistema, inicio y cierre de sesión y opciones de seguridad de red.
10. **Restricciones de software,** basado en lo posible en el uso de listas blancas de software permitido más que en listas negras del mismo.
11. **Activación de auditorías de sistema,** claves para tener un registro de algunos intentos de ataque característicos como la adivinación de contraseñas.
12. **Configuración de servicios de sistema.** En este punto es necesario tratar siempre de deshabilitar todos aquellos servicios que no vayan a prestar una funcionalidad necesaria para el funcionamiento del sistema. Por ejemplo, si su equipo no posee tarjetas de red inalámbrica, el servicio de redes inalámbricas debería estar deshabilitado.
13. **Configuración de los protocolos de Red.** En la medida de lo posible, es recomendable usar sistemas de traducción de direcciones (NAT) para direccionar los equipos internos de una organización. Deshabilitar todos aquellos protocolos de red innecesarios en el sistema y limitar el uso de los mismos al mínimo. TCP/IP es un protocolo que no nació pensando en seguridad, por lo que limitar su uso al estrictamente necesario es imperativo.
14. **Configuración adecuada de permisos de seguridad en archivos y carpetas del sistema.** En la medida de lo posible, denegar explícitamente cualquier permiso de archivo a las cuentas de acceso anónimas o que no tengan contraseña. Un correcto set de permisos a nivel de carpetas y archivos es clave para evitar acceso no deseado al contenido de los mismos.
15. **Configuración de opciones de seguridad de los distintos programas,** como clientes de correo electrónico, navegadores de internet y en general de cualquier tipo de programa que tenga interacción con la red.
16. **Configuración de acceso remoto. En caso de no ser estrictamente necesario, es bueno deshabilitar el acceso remoto.** Sin embargo, cuando es necesario tener control remoto de la máquina, es preciso configurarlo de manera adecuada, restringiendo el acceso a un número muy limitado de usuario, restringiendo al mínimo las conexiones concurrentes, tomando cuidado en la desconexión y cierre de sesión y estableciendo un canal cifrado de comunicaciones para tales propósitos, como SSH.
17. **Configuración adecuada de cuentas de usuario, tratando de trabajar la mayor parte del tiempo con cuentas de acceso limitado y deshabilitando las cuentas de administrador.** Es absolutamente recomendable usar la _impersonificación de usuarios_ para realizar labores administrativas en vez de iniciar sesión como administradores.
18. **Cifrado de archivos o unidades según las necesidades del sistema, considerando un almacenamiento externo para las llaves de descifrado.** Considerar además la opción de trabajar con sistemas de cifrado de mensajería instantánea y correo electrónico.
19. **Realizar y programar un sistema de respaldos frecuente a los archivos y al estado de sistema.** En la medida de lo posible, administrar los respaldos vía red o llevar los respaldos a unidades físicas que estén alejadas del equipo que las origina.

Como se puede ver, el espectro de actividades que deben ser llevadas a cabo dentro de este proceso es bien amplio y tiene actividades de todo tipo. Sin embargo, la consigna para todas estas actividades es siempre la misma: dejar el sistema operativo lo más restringido posible.

#### ¿Cuánta seguridad es suficiente?
¿Hasta qué punto el Hardening es una ayuda y no una molestia?

En este punto, es importante considerar un paradigma muy interesante que tiene la seguridad. Al parecer, la seguridad, por un lado, y la versatilidad y facilidad de uso de los sistemas, por otro, son como dos grupos de personas tirando de ambos extremos de una cuerda. 

En pocas palabras, a medida que se busca una seguridad mayor en los sistemas, la versatilidad y facilidad de uso del mismo se ven limitados, puesto que la cantidad de decisiones que puede tomar el usuario se reduce y la cantidad de posibilidades ajenas al propósito inicial del sistema en sí disminuye drásticamente. Por otro lado, el aumentar la versatilidad y la facilidad de uso de los sistemas pareciera estar muy relacionado con el aumento en las decisiones y posibilidades del usuario, lo que por consiguiente aumenta la probabilidad del mismo de equivocarse y poner en peligro la seguridad de todo el sistema. Y el debate sobre el punto exacto de equilibrio en cuanto a la cantidad de decisiones que deben pasar por manos del usuario final es bastante extenso y no está del todo resuelto.

Por lo tanto, la respuesta a la pregunta planteada es la siguiente: 
> El Hardening es una ayuda hasta el momento exacto en que entorpece el objetivo inicial que tiene el sistema.

Por citar un ejemplo, si un sistema trabaja con impresoras, redes inalámbricas y además con correo electrónico, no es recomendable deshabilitar la cola de impresión, el servicio de redes inalámbricas ni bloquear los puertos de SMTP y POP. 

En cada acción de Hardening que se vaya a ejecutar en el sistema operativo, hay que tener especial cuidado en que dichas acciones no afecten el propósito del sistema en sí.

##### Conclusión
El Hardening es una ayuda indispensable para ahorrarse bastantes dolores de cabeza por parte de los administradores de sistemas. 

Entre sus ventajas, se puede contar la disminución por incidentes de seguridad, mejoras en el rendimiento al disminuir niveles de carga inútil en el sistema, una administración más simple y mayor rapidez en la identificación de problemas, ya que muchas de las posibles causas de ellos quedarán descartadas en virtud de las medidas tomadas, y finalmente la posibilidad – en muchos casos – de poder hacer un seguimiento de los incidentes y en algunos casos identificar el origen de los mismos. Es un trabajo que no es trivial, pero que bien vale la pena hacerlo.

### Principio Zero Trust
Zero Trust es un modelo de seguridad de red basado en la filosofía de que ninguna persona o dispositivo dentro o fuera de la red de una organización debe tener acceso para conectarse a sistemas o servicios de TI hasta que se autentique y se compruebe constantemente.

El modelo fue presentado en 2010, por el analista de investigación de Forrester, John Kindervag, quien propuso una solución que denominó "Zero Trust".

Fue un cambio de la estrategia de "confiar, pero verificar" a "nunca confiar, siempre comprobar". 

1. En el modelo Zero Trust, no se confía en ningún usuario o dispositivo para acceder a un recurso hasta que se compruebe su identidad y autorización. 
2. Este proceso se aplica a quienes suelen encontrarse en una red privada, como una persona empleada en un ordenador de empresa que trabaja de forma remota desde casa o en su dispositivo móvil durante una conferencia al otro lado del mundo. 
3. También se aplica a todas las personas o dispositivos fuera de esa red. No importa si ha accedido a la red antes o cuántas veces lo ha hecho: su identidad no es de confianza hasta que se vuelva a comprobar. 
4. La idea es suponer que cada máquina, usuario y servidor no son de confianza hasta que se demuestre lo contrario.

Históricamente, el enfoque de "castillo y foso" hacia la seguridad parecía viable; hubo un tiempo en que imperó la idea de un perímetro de red donde cualquiera que se encontrase fuera de la red (o foso) era "malo" y todos los que estuviesen dentro eran "buenos". 

> Al igual que los castillos y los fosos son cosa del pasado, también debe serlo este enfoque de seguridad casi medieval. Pensemos en la situación actual del trabajo remoto.

**La plantilla y el lugar de trabajo han cambiado:** Las personas han dejado atrás las cuatro paredes de una oficina y ahora trabajan en cualquier momento y de forma distinta. Con el auge de la nube, el perímetro de red ya no existe de la misma manera que antes. Es posible encontrar a los usuarios y las aplicaciones tanto a un lado como al otro del foso. Y eso añade vulnerabilidades al perímetro de las que los agentes maliciosos se pueden aprovechar. Una vez dentro del foso, pueden moverse libremente, acceder a recursos y activos de alto valor, como los datos de los clientes (¡o las joyas de la corona!); o lanzar un ataque de ransomware.

![[433.B7E2_ransomware.png]]

#### ¿Cómo funciona Zero Trust?
Imagine que el modelo Zero Trust es un guardia de seguridad extremadamente atento que revisa sus credenciales metódica y repetidamente antes de permitirle acceder al edificio de oficinas donde trabaja, incluso si ya le conoce. Después, repite ese proceso para verificar su identidad una y otra vez.

- El modelo Zero Trust se basa en una autenticación y autorización sólidas de cada dispositivo y persona antes de que tenga lugar cualquier acceso o transferencia de datos en una red privada, independientemente de si están dentro o fuera del perímetro de esa red. 
- El proceso también combina análisis, filtrado y registro para comprobar el comportamiento y para observar continuamente las señales de riesgo. 
- Si un usuario o dispositivo muestra indicios de que está actuando de manera diferente que antes, se tiene en cuenta y se supervisa como una posible amenaza. 

Pongamos un ejemplo:
- Marcus en Acme Co. suele iniciar sesión en Columbus, Ohio, en los Estados Unidos, pero hoy está intentando acceder a la intranet de Acme desde Berlín, Alemania. 
- Aunque el nombre de usuario y la contraseña de Marcus se ingresaran correctamente, un enfoque Zero Trust reconocería la anomalía en el comportamiento de Marcus y tomaría medidas, como someter a Marcus a otra prueba de autenticación para verificar su identidad.

Este cambio básico de estrategia acaba con muchas de las amenazas a la seguridad habituales. Los atacantes ya no pueden superar el foso para aprovecharse de las debilidades del perímetro y, posteriormente, de sus datos y aplicaciones confidenciales. Ya no hay foso que cruzar. Solo hay aplicaciones y usuarios, cada uno de los cuales debe autenticarse mutuamente y cuya autorización debe verificarse antes de concederse cualquier acceso. La autenticación mutua se produce cuando dos partes se autentican entre sí al mismo tiempo, como un usuario con unas credenciales y contraseña, y una aplicación con la que se conecta a través de un certificado digital.

#### Principios fundamentales detrás del acceso de red de Zero Trust
El modelo Zero Trust se basa en cinco principios básicos:
1. Siempre se presupone que todos los usuarios de una red son hostiles.
2. Existen amenazas externas e internas en la red en todo momento.
3. La localización de la red no es suficiente para decidir su nivel de confianza.
4. Cada dispositivo, usuario y flujo de red se autentica y autoriza.
5. Las políticas deben ser dinámicas y se deben calcular a partir de tantas fuentes de datos como sea posible.

#### Cuatro claves de la seguridad Zero Trust
Los siguientes son bloques de construcción que, cuando se unifican, proporcionan un camino para lograr la confianza cero en seguridad.

1. Verificar el Usuario
2. Verificar el Dispositivo
3. Limitar el acceso y los privilegios
4. Aprende y adapta

##### 1 | Verificar el usuario
Hoy en día, la forma más básica de verificar a un usuario es a través de un nombre de usuario y contraseña. 

Pero, ¿cómo podemos estar seguros de que el usuario es quien dice ser y no alguien que adivinó o falsificó la contraseña o compró credenciales comprometidas en la Dark Web? Se obtiene una seguridad de identidad adicional al mejorar las contraseñas con la autenticación multifactor (MFA), que usa algo que tiene,  algo que sabes o algo que eres.

El nivel de confianza ganado a través de pasos de verificación adicionales determina parcialmente si se otorga el acceso y a qué nivel específico.

Los principios Zero Trust se aplican independientemente del tipo de usuario (usuario final, usuario privilegiado, TI subcontratado, socio o cliente) o el recurso al que se accede (aplicación o infraestructura). Las decisiones de acceso deben ser adaptativas y dinámicas.

##### 2 | Verificar el dispositivo
Para lograr Zero Trust Security, los controles preventivos centrados en la identidad deben extenderse hasta el endpoint. 

Al igual que con los usuarios, no se puede confiar en los dispositivos sin verificar. La verificación de un dispositivo implica que el usuario verificado inscriba su dispositivo para que se reconozca.

Si el usuario solicita acceso desde un dispositivo registrado que usa todos los días, tiene un cierto nivel de confianza. Si intentan acceder a los servicios desde una estación de trabajo en un cibercafé que nunca han usado antes, la confianza está fuera.

La verificación de los dispositivos también implica asegurarse de que solo se permita el acceso a los dispositivos si cumplen con ciertos requisitos de seguridad: ¿Han sido registrados? ¿Se ajustan las configuraciones del dispositivo a las políticas de la empresa, como el cifrado de disco, la protección contra virus y los parches actualizados?

##### 3 | Limitar el acceso y los privilegios
Los privilegios de usuario deben ser administrados con mucho control. Las partes malintencionadas frecuentemente se dirigen al personal con privilegios administrativos para obtener control sobre los sistemas de negocio.

Primero, con Zero Trust Security, es importante limitar el movimiento lateral dentro de todos los recursos, como servidores y estaciones de trabajo, limitando a los usuarios solo al acceso que necesitan para realizar sus trabajos.

La segunda es la autorización en aplicaciones de negocios. Debido a que estas aplicaciones a menudo contienen grandes cantidades de datos críticos y debido a que generalmente son accedidas por más usuarios dentro de la organización, pueden ser objetivos más fáciles para los atacantes. Por lo tanto, es igualmente importante proporcionar solo acceso suficiente dentro de cada aplicación para que los usuarios hagan su trabajo.

Supongamos que un atacante inicia sesión en una base de datos utilizando credenciales robadas. Los privilegios del usuario se limitan al mínimo, el atacante también se limitará a lo que pueden acceder. Cuanto más críticos son los datos, menos privilegios, y con un mayor uso de MFA para garantizar la identidad.

##### 4 | Aprende y adapta
Al igual que Gartner ha sugerido con su enfoque CARTA, Zero Trust Security debe mejorar continuamente mediante el aprendizaje y la adaptación. 

La información sobre el usuario, el endpoint, las aplicaciones o el servidor, las políticas y todas las actividades relacionadas con ellos se pueden recopilar y enviar a un conjunto de datos que alimente el aprendizaje automático.

Luego, el sistema puede reconocer automáticamente comportamientos fuera de lo común, como un usuario que intenta acceder a los recursos desde una ubicación inusual, lo que inmediatamente provoca una señal de advertencia que puede requerir una segunda forma de autenticación, todo dependerá de las políticas.

Los análisis de comportamiento se utilizan para determinar el nivel de riesgo de las transacciones individuales y decidir en tiempo real si las permite o no, proporcionando servicios de identidad con información clave que podemos indicar a los administradores.

#### ¿De qué se compone Zero Trust?
El modelo de seguridad Zero Trust actual se ha ampliado. Sus principios se han implementado de muchas maneras, incluida la arquitectura Zero Trust (ZTA), el acceso de red Zero Trust (ZTNA) y Zero Trust Edge (ZTE). La seguridad Zero Trust también se denomina a veces "seguridad sin perímetro".

Zero Trust no se trata de una sola tecnología discreta, sino que la arquitectura Zero Trust utiliza numerosas tecnologías y principios diferentes para abordar los desafíos de seguridad comunes a través de técnicas preventivas. Estos componentes están diseñados para proporcionar protección avanzada contra amenazas a medida que las fronteras entre el trabajo y la vida personal se desdibujan, y tener una plantilla remota cada vez más distribuida se convierte en lo habitual.

##### Capacidades de acceso de red Zero Trust
1. Se controlan los flujos de red entre todos los activos.
2. Se comprueba la identidad y se proporciona acceso a la nube
3. Autenticación y autorización, como la autenticación multifactor (MFA)
4. Acceso a aplicaciones frente al acceso a toda la red
5. Acceso del usuario a todas las aplicaciones con privilegios mínimos (IaaS, SaaS y locales).
6. Eliminación de la VPN.
7. Inserción de servicios.
8. Seguridad en el borde de Internet.
9. Mejora del rendimiento de las aplicaciones.
10. Mejora de la estrategia de seguridad frente a amenazas avanzadas.

#### Ventajas clave de la arquitectura Zero Trust
Una arquitectura Zero Trust funciona a la perfección para los usuarios, ayuda a protegerse de los ciberataques y simplifica los requisitos de infraestructura. Los distintos componentes de la arquitectura Zero Trust pueden:

##### Garantizar la confianza en la red y frenar los ataques maliciosos
Los equipos de TI tienen que asegurarse de que los usuarios y los dispositivos pueden conectarse de forma segura a Internet, independientemente de su ubicación de conexión, y sin las complejidades asociadas a los enfoques heredados. También deben identificar, bloquear y mitigar proactivamente las amenazas dirigidas, como el malware, ransomware, phishing, exfiltración de datos DNS y ataques avanzados de día cero para los usuarios. Los modelos de seguridad Zero Trust pueden mejorar las estrategias de seguridad, a la vez que reducen el riesgo de sufrir ataques de malware.

##### Proporcionar acceso seguro a las aplicaciones para personas empleadas y partners
Tecnologías de acceso tradicionales, como VPN, se basan en principios de confianza anticuados, que son especialmente vulnerables debido al robo de credenciales de los usuarios y las consecuentes filtraciones de datos. Los equipos de TI deben replantearse sus tecnologías y su modelo de acceso para garantizar la seguridad de la empresa y que todos los usuarios, incluidos terceros, puedan seguir accediendo rápida y fácilmente. Los modelos de seguridad Zero Trust ayudan a reducir los riesgos y las complejidades, así como a ofrecer una experiencia de usuario uniforme.

##### Reduzca la complejidad y ahorre en recursos de TI
El acceso y la seguridad empresarial son aspectos complejos y en constante cambio. Hacer cambios con las tecnologías empresariales tradicionales suele llevar días (y requiere muchos componentes de hardware y software) y acaparar recursos valiosos. Aplicar un modelo de seguridad Zero Trust puede reducir la complejidad de la arquitectura.

##### Por qué es necesario un modelo de seguridad Zero Trust
En resumen, la plantilla moderna se está volviendo cada vez más móvil, con acceso a aplicaciones desde varios dispositivos fuera del perímetro de la empresa. En el pasado, muchas empresas adoptaron un modelo basado en comprobar primero la identidad y, a continuación, confiar. Por tanto, si alguien tenía las credenciales de usuario correctas, podía acceder a cualquier sitio web, aplicación o dispositivo que desease. Esto ha traído consigo un mayor riesgo de exposición, difuminando lo que tradicionalmente había sido la zona de control empresarial de confianza y dejando a muchas organizaciones expuestas a ataques de filtración de datos, malware y ransomware. Ahora es necesario proteger las aplicaciones, los datos, los usuarios y los dispositivos allá donde se encuentren dentro de infraestructuras digitales específicas.

##### Razones convincentes para emplear un modelo Zero Trust
1. Los usuarios, los dispositivos, los datos y las aplicaciones se están trasladando fuera del perímetro de la empresa y de la zona de control; se están alejando de los centros de datos tradicionales.
2. Los nuevos requisitos empresariales, impulsados por la transformación digital, incrementan el riesgo a la exposición.
3. El enfoque "confiar, pero verificar" ya no es una opción, dado que las amenazas avanzadas ahora acceden al perímetro de la empresa.
4. Los perímetros tradicionales son complejos, incrementan el riesgo y ya no son adecuados para los modelos de negocio actuales.
5. Para ser competitivas, las empresas necesitan una arquitectura de red Zero Trust que sea capaz de proteger los datos empresariales, independientemente de la ubicación de los usuarios y los dispositivos, al tiempo que garantiza el funcionamiento rápido y óptimo de las aplicaciones.

### Baselines y estándares de Hardening
![[434.B7E2_baselines.png]]

Una línea de base de seguridad es un grupo de ajustes de configuración recomendados que buscan incrementar la seguridad de los sistemas informáticos.

Todas las organizaciones se enfrentan a amenazas de seguridad. Sin embargo, los tipos de amenazas a la seguridad que más preocupan a una organización pueden ser completamente diferentes a los de otra.

Por ejemplo, una empresa de comercio electrónico puede centrarse en la protección de sus aplicaciones web orientadas a Internet, mientras que un hospital puede centrarse en la protección de la información confidencial de los pacientes. Lo único que todas las organizaciones tienen en común es la necesidad de mantener sus aplicaciones y dispositivos seguros. Estos dispositivos deben cumplir con las normas de seguridad (o líneas de base de seguridad) definidas por la organización.

#### ¿Por qué son necesarias las líneas de base de seguridad?
Las líneas de base de seguridad son un beneficio esencial para los clientes porque reúnen el conocimiento de expertos, los socios y los clientes.

Por ejemplo, hay más de 8.000 configuraciones de directivas de grupo para Windows 10 y los distintos productos de Microsoft. De todas estas configuraciones, solo algunas están relacionadas con la seguridad, cuyo papel para asegurar este software es fundamental. Esto lleva a las organizaciones modernas, a estudiar muy de cerca el panorama de las amenazas a la seguridad que puede amenazarles, el cual también está en constante evolución, y los profesionales de TI y los responsables de las políticas deben mantenerse al día con dichas amenazas con el fin de realizar los cambios necesarios en la configuración de seguridad para ayudar a mitigar estas amenazas. 

En este sentido, las baselines ayudan a las organizaciones crear implementaciones más rápidas y facilitar la gestión de los productos y su seguridad. Básicamente, toda la comunidad interesada en un producto ayuda a crear dichas baselines y de esta forma crear un estándar de seguridad aplicable a casos genéricos de acuerdo a las necesidades y el nivel de protección deseado. 

#### Principios de las baselines
Nuestras recomendaciones siguen un enfoque racionalizado y eficiente para las definiciones de líneas de base. La base de ese enfoque es esencialmente:
1. Las líneas de base están diseñadas para organizaciones bien gestionadas y preocupadas por la seguridad en las que los usuarios finales estándar no tienen derechos administrativos.
2. Una línea de base aplica una configuración solo si mitiga una amenaza de seguridad actual y no causa problemas operativos que sean peores que los riesgos que mitigan.
3. Una línea de base impone una configuración por defecto solo si es probable que un usuario autorizado la establezca en un estado inseguro:
4. Si una persona no administradora puede establecer un estado inseguro, aplique el valor por defecto.
5. Si la configuración de un estado inseguro requiere derechos administrativos, aplique el valor por defecto solo si es probable que un administrador mal informado elija mal.

#### Baselines dentro de la industria
1. Red Hat Baselines
2. Cis Benchmark
3. Security Technical Implementation Guide (STIG)
4. National Checklist Program (NCP)

##### 1 | Red Hat Baselines
Red Hat es considerada una de las grandes empresas del mundo de software libre que participa de forma activa dentro de este ecosistema, impulsando el desarrollo de soluciones dentro del kernel Linux y desktops como el proyecto GNOME y systemd.

Parte de ese desarrollo se ve claramente reflejado en Red Hat Linux (RHEL), una distribución centrada en ofrecer un sistema completo para empresas y que viene acompañado de una serie de recomendaciones y baselines de seguridad conocidas como Red Hat Security Baselines, que se ajustan a cada versión del sistema operativo que se encuentra en desarrollo y mantenimiento.

Actualmente, RHEL se encuentra en sus versiones 8 y 9, y puedes acceder a las baselines básicas de seguridad en la documentación online de este sistema operativo ([enlace para la versión 9](https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/9/html/security_hardening/index)). 

![[434.B7E2_redhat.png]]

##### 2 | CIS Benchmark
CIS Benchmark son una serie de baselines de seguridad publicados por el Center for Internet Security (CIS). 

Estas baselines son consideradas como las mejores prácticas documentadas del sector para configurar de forma segura los sistemas, el software y las redes de TI. En la actualidad, hay más de 140 puntos de referencia del CIS, que abarcan siete categorías tecnológicas básicas. Los puntos de referencia del CIS se desarrollan a través de un proceso único basado en el consenso en el que participan comunidades de profesionales de la ciberseguridad y expertos en la materia de todo el mundo, cada uno de los cuales identifica, perfecciona y valida continuamente las mejores prácticas de seguridad dentro de sus áreas de interés.

[CIS](https://www.cisecurity.org/cis-benchmarks/) es una organización sin ánimo de lucro creada en octubre de 2000. El CIS está impulsado por una comunidad global de TI con el objetivo común de identificar, desarrollar, validar, promover y mantener las mejores prácticas de soluciones para la ciberdefensa. A lo largo de los años, el CIS ha producido y distribuido varias herramientas y soluciones gratuitas para empresas de todos los tamaños, diseñadas para reforzar su preparación en materia de ciberseguridad.

El CIS es más conocido por su publicación CIS Controls, una guía completa de 20 salvaguardias y contramedidas para una ciberdefensa eficaz. Los Controles CIS proporcionan una lista de verificación priorizada que las organizaciones pueden implementar para reducir significativamente su superficie de ciberataque. Las referencias de CIS hacen referencia a estos controles cuando elaboran recomendaciones para una configuración de sistemas más segura.

Cada punto de referencia CIS incluye múltiples recomendaciones de configuración basadas en uno de los dos niveles de perfil. Los perfiles de referencia de nivel 1 cubren configuraciones de nivel básico que son más fáciles de implementar y tienen un impacto mínimo en la funcionalidad del negocio. Los perfiles de referencia de nivel 2 están pensados para entornos de alta seguridad y requieren más coordinación y planificación para implementarlos con una interrupción mínima del negocio.

Hay siete (7) categorías principales de puntos de referencia CIS:
1. **Los puntos de referencia de los sistemas operativos:**  
    Cubren las configuraciones de seguridad de los sistemas operativos principales, como Microsoft Windows, Linux y Apple OSX. Incluyen directrices de buenas prácticas para las restricciones de acceso local y remoto, perfiles de usuario, protocolos de instalación de controladores y configuraciones de navegadores de Internet.
2. **Los puntos de referencia del software de servidor:**  
    Cubren las configuraciones de seguridad del software de servidor más utilizado, como Microsoft Windows Server, SQL Server, VMware, Docker y Kubernetes. Estos puntos de referencia incluyen recomendaciones para configurar los certificados PKI de Kubernetes, la configuración del servidor API, los controles de administración del servidor, las políticas de vNetwork y las restricciones de almacenamiento.
3. **Los puntos de referencia del proveedor de la nube:**  
    Abordan las configuraciones de seguridad para Amazon Web Services (AWS), Microsoft Azure, Google, IBM y otras nubes públicas populares. Incluyen directrices para configurar la gestión de la identidad y el acceso (IAM), los protocolos de registro del sistema, las configuraciones de red y las salvaguardias de cumplimiento normativo.
4. **Los puntos de referencia de los dispositivos móviles:**  
    Abordan los sistemas operativos móviles, incluidos iOS y Android, y se centran en áreas como las opciones y los ajustes de los desarrolladores, las configuraciones de privacidad del sistema operativo, los ajustes del navegador y los permisos de las aplicaciones.
5. **Los puntos de referencia de dispositivos de red:**  
    Ofrecen directrices de configuración de seguridad generales y específicas del proveedor para los dispositivos de red y el hardware aplicable de Cisco, Palo Alto Networks, Juniper y otros.
6. **Los puntos de referencia del software de escritorio:**  
    Cubren las configuraciones de seguridad para algunas de las aplicaciones de software de escritorio más utilizadas, como Microsoft Office y Exchange Server, Google Chrome, Mozilla Firefox y Safari Browser. Estos puntos de referencia se centran en la privacidad del correo electrónico y la configuración del servidor, la gestión de dispositivos móviles, la configuración del navegador por defecto y el bloqueo de software de terceros.
7. **Los puntos de referencia de los dispositivos de impresión multifunción:**  
    Describen las mejores prácticas de seguridad para la configuración de impresoras multifunción en entornos de oficina y abarcan temas como la actualización del firmware, las configuraciones TCP/IP, la configuración del acceso inalámbrico, la gestión de usuarios y el uso compartido de archivos.

![[434.B7E2_cis.png]]

##### 3 | Security Technical Implementation Guide (STIG)
Security Technical Implementation Guide (STIG) o Guía de Implementación Técnica de Seguridad (STIG), es un estándar de configuración que consiste en requisitos de ciberseguridad para un producto específico. 

El uso de las STIG permite una metodología para asegurar los protocolos dentro de las redes, servidores, ordenadores y diseños lógicos para mejorar la seguridad general. Estas guías, cuando se aplican, mejoran la seguridad del software, el hardware y las arquitecturas físicas y lógicas para reducir aún más las vulnerabilidades.

Las STIGs pueden provenir de varias organizaciones o autoridades especializadas en seguridad, sin embargo, las STIGs más conocidas en este caso provienen del DoD Cyber Exchange, un programa del Departamento de Estado de los Estados Unidos que reúne baselines de seguridad bien documentadas aplicables a varios sistemas y software. Por ejemplo, hay STIGs aplicables a software como Apache Web Server, Windows Server (aplica al servidor y la seguridad de servicios como Active Directory, DNS AD, entre otros), Adobe Acrobat, Firefox, Chrome (y derivados), Android e iOS, sistemas operativos como AIX, FreeBSD y varios distros GNU/Linux.

![[434.B7E2_stig.png]]

##### 4 | National Checklist Program (NCP)
El National Checklist Program (NCP) o Programa Nacional de Listas de Comprobación (NCP), es un programa definido por el National Institute of Standards and Technology (NIST), con el fin de cumplir con el estándar [NIST SP 800-70](https://csrc.nist.gov/publications/detail/sp/800-70/rev-4/final). 

El NCP es el repositorio del gobierno de los Estados Unidos de listas de comprobación de seguridad disponibles públicamente (o puntos de referencia) que proporcionan una guía detallada de bajo nivel para establecer la configuración de seguridad de los sistemas operativos y las aplicaciones.

NCP proporciona metadatos y enlaces a listas de comprobación de varios formatos, incluidas las listas de comprobación que se ajustan al Protocolo de Automatización de Contenidos de Seguridad (SCAP). El SCAP permite que los productos de seguridad validados realicen automáticamente la comprobación de la configuración utilizando las listas de comprobación del NCP. Para más información sobre el PNC, visite la página de información o el glosario de términos. Tenga en cuenta que los campos de búsqueda actuales se han ajustado para reflejar el NIST SP 800-70 Revisión 4.

![[434.B7E2_ncp.png]]

### Hardening en Windows
El Hardening en sistemas Windows puede ser una tarea titánica debido a la complejidad de este sistema y los miles de parámetros que se pueden ajustar.

Sin embargo, es una tarea que debe realizarse a los fines de cumplir con criterios de seguridad que permitan garantizar la integridad y confiabilidad de los sistemas.

En la unidad anterior, dedicada a los baselines, pudimos conocer algunas guías de seguridad que pueden ayudarte a automatizar esta tarea, algo útil cuando trabajas en organizaciones grandes donde se deben de administrar decenas o cientos de equipos. Es por ello, que en esta sección verás cuáles son los puntos que debes tener en cuenta en el Hardening de este sistema operativo para cumplir con medidas mínimas recomendadas de seguridad.

#### ¿Qué son las Baselines de seguridad de Windows?
Windows y Windows Server están diseñados pensando en la seguridad. Microsoft asegura ciertos aspectos y también proporciona a las organizaciones controles que permiten una configuración de seguridad granular.

Para ayudar a las organizaciones a aprovechar adecuadamente los controles de seguridad, Microsoft proporciona líneas básicas de seguridad que ofrecen orientación.

Cada línea de base de seguridad de Windows es un grupo de ajustes de configuración basados en los comentarios de los ingenieros de seguridad de Microsoft, así como de grupos de productos, clientes y socios. Estas líneas básicas de seguridad están disponibles en un formato consumible, incluso como copias de seguridad de objetos de directiva de grupo.

Las Baselines de Seguridad de Windows pueden ayudar a las organizaciones a garantizar que las configuraciones de dispositivos y usuarios que ya se han configurado cumplen con las líneas básicas de Windows. También puede ayudar a establecer los parámetros de configuración para las nuevas instalaciones del sistema operativo, por ejemplo, cuando se utiliza Microsoft Endpoint Configuration Manager, Microsoft Intune o Group Policy

Las líneas básicas de seguridad están disponibles en el [Centro de descargas de Microsoft](https://www.microsoft.com/en-us/download/details.aspx?id=55319).

#### Hardening en Windows, lista de comprobación
##### Configuración de usuarios de Windows
Siga estas directrices para reducir los riesgos de las cuentas de usuario privilegiadas en Windows:
1. **Desactive el administrador local predeterminado (conocido como Admin):**  
    Normalmente no es necesario y es un objetivo popular para los atacantes.
2. **Configure una cuenta de administrador personalizada:**  
    Puede ser una cuenta de Active Directory (AD) del dominio o una cuenta local del grupo de administradores.
3. **Prefiera ejecutar como una cuenta de usuario normal:**  
    Para reducir la posibilidad de que la cuenta se vea comprometida, conéctese al servidor utilizando una cuenta de usuario normal y, cuando necesite realizar operaciones que requieran privilegios administrativos, solicite la elevación utilizando "Ejecutar como" (el equivalente a sudo en Windows).

##### #### Configuración de la red de Windows
Tome las siguientes precauciones para proteger una máquina Windows de los ataques de red:
1. **Coloque la máquina detrás del cortafuegos:**  
    Las instancias de Windows y Windows Server en producción deben ejecutarse siempre en un segmento de red debidamente protegido.
2. **Use DNS redundante:**  
    Configure dos o más servidores DNS y verifique la resolución de nombres mediante nslookup. De esta manera podrá asegurarse de que exista siempre una conexión a Internet. 
3. **Verifique los registros DNS:**  
    Asegúrese de que el servidor tiene un registro A y un registro PTR para las búsquedas DNS inversas.
4. **Asegúrese de usar servidores DNS con DNS Over HTTPS:** Para cifrar la conexión y con verificación por DNSSEC. Esto le asegurará que nadie pueda interferir con este sistema y podrá validar las direcciones otorgadas por el servicio. 
5. **Desactivar los servicios de red:**  
    Cualquier servicio que el servidor no esté utilizando realmente, como IPv6, debe desactivarse para reducir la superficie de ataque.

##### Configuración de servicios de Windows
Siga estas directrices para minimizar el riesgo de los servicios que se ejecutan en Windows y Windows Server:
1. **Desactive los servicios no utilizados:**  
    Muchos servicios que se ejecutan por defecto en Windows Server pueden no ser necesarios en su caso de uso específico, y deben ser desactivados. Desactive cualquier servicio que no sea necesario para la funcionalidad básica. Preste especial atención a Windows Server 2008 y 2003, que tienen un mayor número de servicios redundantes.
2. **Limite el contexto de seguridad:**  
    Cada servicio se ejecuta como una cuenta de usuario específica. Por defecto, estas son las cuentas de Servicio de red, Sistema local o Servicio local. Para los servicios de aplicaciones y usuarios sensibles, configure cuentas para cada servicio y limite los privilegios al mínimo necesario para cada servicio. Esto limita la capacidad de escalada de privilegios y el movimiento lateral. Esto es equivalente a crear usuario/grupos en instalaciones dentro de sistemas GNU/Linux. 

##### Configuración del Protocolo de Tiempo de Red (NTP)
El inicio de sesión de Windows y otras funciones que aprovechan la seguridad de Kerberos dependen de la precisión de las horas NTP. 

Incluso una pequeña diferencia horaria puede interrumpir la funcionalidad. Para evitar la interrupción del servicio, asegúrese de que:
1. Los servidores dentro de los dominios sincronizan automáticamente la hora con el controlador del dominio.
2. Los servidores independientes se sincronizan con una fuente de tiempo externa.
3. Los controladores de dominio se sincronizan con un servidor de hora de forma continua

##### Registros de eventos centralizados
Los sistemas Windows generan varios registros, que pueden configurarse para ser más o menos detallados. 

Los registros son una forma importante de obtener visibilidad sobre las operaciones del servidor con fines de mantenimiento y seguridad. Para proporcionar un acceso cómodo a los registros de las instancias de Windows de una organización, utilice un servidor syslog central y asegúrese de que dispone de las siguientes capacidades:
1. Capacidad para asignar categorías a registros o entradas específicas.
2. Permitir la búsqueda de texto completo y la consulta de datos de registro.
3. Integrar el registro con herramientas de corrección para permitir la respuesta automatizada a los errores.

##### Ajustes adicionales de seguridad para Windows 
Adicional a esto, puede reforzar la seguridad de Windows de la siguiente forma:

###### Aproveche las herramientas de seguridad integradas en Windows. 
Por ejemplo, en Windows 10 y 11, el sistema viene con varias herramientas de seguridad integradas, entre ellas: 
1. **Windows Defender Advanced Threat Protection:**  
    Un sistema de seguridad avanzado que incluye protección antimalware de última generación, así como protección contra exploits, reducción automatizada de la superficie de ataque, control de aplicaciones y aislamiento basado en hardware.
2. **Microsoft SmartScreen:**  
    Analiza las descargas y bloquea la ejecución de cargas útiles maliciosas.
3. **Windows Sandbox:**  
    Permite a los usuarios instalar aplicaciones no fiables en un entorno seguro y aislado.
4. **HVCI y VBS:**  
    Medidas de seguridad que garantizan la seguridad y aislamiento del kernel de Windows para evitar vulnerabilidades en el mismo. 
5. **Windows Device Guard:**  
    Una serie de protecciones a nivel de hardware y software que garantizan que el sistema se ejecute solo en medios de confianza (usa TPM, Secure Boot y BitLocker para garantizar seguridad y criptografía de alto nivel para el sistema). 
6. **Windows Mitigations Framework:**  
    Una serie de opciones configurables que permiten al sistema habilitar opciones de seguridad y mitigación de vulnerabilidades. Debe usarse con cuidado porque hay software que no está construido para soportar estas mitigaciones llevando a malos funcionamientos (ej: Discord, Slack, Zoom, entre otros)

###### Gestión de aplicaciones
Es muy recomendable configurar Windows para que solo permita la instalación de aplicaciones aprobadas desde repositorios de software controlados o mercados de aplicaciones.

Puede hacerlo configurando la opción "Permitir solo aplicaciones de la tienda" en Aplicaciones y características, o utilizando las políticas de integridad del código de Windows Defender.

Esto puede evitar que los atacantes envíen malware por correo electrónico a los usuarios, que los convenzan para que descarguen e instalen malware, o que desplieguen malware a través de descargas no autorizadas o enlaces engañosos en sitios web maliciosos. Tenga en cuenta que incluso si requiere acceso administrativo en el equipo local para instalar software, los atacantes pueden eludirlo con ingeniería social.

###### Control de aplicaciones
Muchos vectores de ataque se basan en la ejecución de código malicioso, aunque no esté instalado en el dispositivo del usuario.

Las listas blancas y negras de ejecutables en Windows 10 pueden ser eficaces para prevenir estos ataques. Muchas de las mejores prácticas de seguridad aconsejan crear una nueva lista blanca de archivos que se pueden ejecutar en las máquinas de los usuarios finales, sin depender de las listas de los proveedores de aplicaciones o de los archivos existentes en la máquina.

Sin embargo, en los entornos empresariales reales, puede ser difícil crear dicha lista blanca y mantenerla en un gran número de máquinas. Las listas blancas también tienden a ser demasiado restrictivas, perjudicando la productividad de los usuarios.

###### Desactivar el acceso remoto
Windows viene con Microsoft Remote Desktop que proporciona acceso remoto a la máquina de un usuario. 

Esta función suele ser utilizada por los atacantes para obtener el control remoto de los dispositivos de los usuarios, instalar malware y robar información. El Escritorio Remoto está desactivado por defecto, pero en caso de que los usuarios lo habiliten, es importante asegurarse de que está desactivado, excepto cuando se necesite para un uso legítimo y aprobado.

###### PowerShell
PowerShell es un lenguaje de scripting que es extremadamente poderoso en manos de un atacante. 

Siga estas directrices para proteger los sistemas contra los ataques de PowerShell:
1. Elimine la versión 2.0 o anterior de PowerShell, que tenía vulnerabilidades de seguridad
2. Establezca PowerShell en modo de lenguaje restringido
3. Habilitar el registro de PowerShell para proporcionar una pista de auditoría
4. Establecer una política de ejecución - una característica de seguridad que especifica bajo qué condiciones PowerShell cargará archivos de configuración y ejecutará scripts

###### Habilitar las actualizaciones automáticas
Implantar las actualizaciones de seguridad de Microsoft en todos los dispositivos de los usuarios de forma inmediata.

Automatice y aplique el despliegue de las actualizaciones regulares de Windows, si es posible, sin la participación del usuario.

###### Deshabilitar el soporte para SMBv1 y fortalecer el sistema de autenticación SMB
Otra medida de seguridad que es desactivar el soporte para SMBv1 (un viejo protocolo ya en desuso) y la de fortalecer la seguridad de autenticación (requiriendo cifrado y firmado digital) para las conexiones remotas de SMBv2 y SMBv3.

##### Pruebas y Auditoría de Hardening
Ahora bien, las medidas mencionadas son algunas de las medidas básicas para asegurar un sistema Windows, siendo las baselines de Windows la mejor forma de aplicar esto. 

En las baselines todos los valores de seguridad recomendados se encuentra ya configurados quedando solo aplicar los mismos según sea nuestro requerimiento. 

Para este ejemplo práctico usaremos Windows 11 y un pequeño aplicativo de nombre [HardeningKitty](https://github.com/scipag/HardeningKitty) creado por los especialistas de seguridad [Scip AG](https://www.scip.ch/), quienes actualizan el mismo con las baselines de seguridad de Windows de forma periódica y nos facilitan la aplicación de las mismas. Este Windows 11 sin modificación de seguridad viene con un score de auditoría de HardeningKitty de 1,8 puntos, bastante bajo y con la aplicación del baseline elevaremos esa seguridad. 

![[435.B7E2_elevaremos.png]]

Para usar esta herramienta todo lo que debes hacer es descargar la misma desde GitHub y descomprimir su contenido. Una vez realizado esto, te recomendamos instales la última versión de PowerShell (la versión estable), algo que puedes hacer desde este [enlace](https://docs.microsoft.com/es-es/powershell/scripting/install/installing-powershell-on-windows?view=powershell-7.2). 

Antes de empezar debes saber que HardeningKitty viene con varias baselines de Microsoft, que puedes ver en la siguiente imagen:

![[435.B7E2_HardeningKitty.png]]

- De estas listas deberás elegir la que se adapte a tu sistema operativo, en este caso, usaremos la lista
**finding_list_msft_security_baseline_windows_11_21h2_machine.csv**
- Ya que estaremos usando Windows 11 para esta prueba. Así, una vez descargada e instalada la última versión de PowerShell y ubicados en el directorio de HardeningKitty, simplemente ejecutaremos este comando desde una PowerrShell con permisos administrativos:
**Import-Module .\Invoke-HardeningKitty.ps1**
- Este nos permitirá cargar el módulo y comenzar a usarlo, y luego haremos el siguiente comando:
**Invoke-HardeningKitty -Mode Config -Backup**
- Este comando nos permitirá hacer un respaldo de la configuración de seguridad actual, un paso especialmente útil si por alguna razón queremos volver a la configuración por defecto que está desplegada en nuestro sistema. El resultado será un CSV que recomendamos guardes en un lugar seguro para volver al estado anterior de seguridad si lo deseas. 
- Seguidamente procedes a ejecutar el comando:
**Invoke-HardeningKitty -Mode HailMary -Log -Report -FileFindingList
.\lists\
finding_list_msft_security_baseline_windows_11_21h2_machine.csv**
- Este comando lo que hará es habilitar el modo de enforce de medidas de seguridad que están descritas en la lista descrita (en este caso, la lista es la que vemos en el archivo **finding_list_msft_security_baseline_windows_11_21h2_machine.csv**) y de esa manera toda la baseline de ese archivo será configurada en el sistema. Al finalizar el proceso ya habrás terminado de configurar la baseline en Windows. 
- En este punto, puedes hacer una nueva auditoria en vivo usando el comando:
**Invoke-HardeningKitty -EmojiSupport**
- Y con ello obtendremos el nuevo perfil de seguridad:

![[435.B7E2_perfil.png]]

Con ello podemos ver que las medidas de seguridad han sido aplicadas y nuestro sistema muestra un score de 5,53 (de 6 puntos totales) lo que ya nos muestra que hemos elevado de forma exitosa la seguridad del mismo. 

Si bien, esto no hace de Windows un sistema invulnerable, las medidas de seguridad hacen del mismo un espacio mucho más seguro de usar en ambientes empresariales. 

Esto no solo aplica a Windows, HardeningKitty puede usarse para aplicar STIGS y listas de seguridad para cualquier software (Firefox, Chrome, Adobe Suite, Office, y cualquiera con soporte), incluso en Windows Server, por lo que es una herramienta sencilla y muy potentes para asegurar sistemas.

### Hardening en GNU/Linux
Al igual que en Windows, el Hardening es sistemas operativos GNU/Linux es una tarea ardua que lleva a la configuración de varios archivos y configuraciones con el fin de alcanzar la configuración de seguridad deseada.

En tal caso, con el fin de alcanzar una configuración de seguridad básica para GNU/Linux estas son algunas buenas recomendaciones que puedes realizar con el fin de alcanzar el nivel deseado.

![[436.B7E2_hardening.png]]

#### Medidas básicas de Hardening en GNU/Linux
##### Control de usuarios y grupos
Una de las principales medidas de seguridad en GNU/Linux es el control de los usuarios y grupos que tienen acceso y permisos dentro del sistema. 

Utilice los comandos useradd / usermod para crear y mantener cuentas de usuario. Asegúrate de tener una política de contraseñas buena y fuerte. 

Por ejemplo, una buena contraseña incluye al menos 8 caracteres de longitud y una mezcla de alfabetos, números, caracteres especiales, letras mayúsculas y minúsculas, etc. Lo más importante es que elijas una contraseña que puedas recordar. Configure pam_cracklib.so (una librería para chequear contraseñas) para hacer cumplir la política de contraseñas que haya decidido aplicar sobre el sistema. 

##### Configurar el tiempo de validez de las contraseñas
El comando chage cambia el número de días entre los cambios de contraseña y la fecha del último cambio de contraseña. 

Esta información es utilizada por el sistema para determinar cuándo un usuario debe cambiar su contraseña. El archivo /etc/login.defs define la configuración específica del sitio para el conjunto de contraseñas en la sombra, incluyendo la configuración del envejecimiento de la contraseña. 

![[436.B7E2_envejecimiento.png]]

Desde este documento puedes cambiar configuraciones tan relevantes como la validez temporal de las contraseñas, el mask por defecto de los usuarios (para que se asignen determinados permisos a los documentos creados por el usuario), entre otras variables de seguridad.

- En todo caso, para revisar el status de un usuario puedes usar el comando:
**### chage -l nombredeusuario**
- Además, puedes usar el comando chage para cambiar estos parámetros directamente sobre el archivo /etc/shadow (que sirve de base de datos para este tipo de información) usando la siguiente línea de comando:
**### chage -M 120 -m 7 -W 7 userName**

Esto indica que:
1. La contraseña solo será válida por 120 días.
2. La existencia mínima de la contraseña será de 7 días y antes de esto no se puede cambiar. 
3. Un periodo de advertencia de 7 días, para que realices el cambio de la misma y no te tome un bloqueo del sistema porque la contraseña se ha vencido.

##### Restringir el uso de contraseñas anteriores en Linux
Puede evitar que todos los usuarios utilicen o reutilicen las mismas contraseñas anteriores en Linux. 

El parámetro “remember” del módulo pam_unix se puede utilizar para configurar el número de contraseñas anteriores que no se pueden reutilizar.

##### Bloqueo de cuentas de usuario tras fallos en el inicio de sesión
En GNU/Linux se puede utilizar el comando faillog para mostrar los registros de faillog o para configurar los límites de fallos de inicio de sesión. 

faillog formatea el contenido del registro de fallos de la base de datos /var/log/faillog / archivo de registro. También se puede utilizar para mantener los contadores y límites de fallos. Para ver los intentos de inicio de sesión fallidos, introduzca el comando:
**### faillog**
Para desbloquear una cuenta después de los fracasos de inicio de sesión, ejecute:
**### faillog -r -u nombredeusuario**
Aunque también puede usar el comando passwd para bloquear o desbloquear cuentas:
**### passwd -l nombredeusuario- Bloquea la cuenta del usuario**
**### passwd -u nombredeusuario- Desbloquea la cuenta del usuario**

##### Asegúrese de que ninguna cuenta que no sea root tenga el UID a 0
Solo la cuenta root tiene UID 0 con permisos completos para acceder al sistema. Escriba el siguiente comando para mostrar todas las cuentas con UID establecido en 0:
**### awk -F: '($3 == "0") {print}' /etc/passwd**
Solo debería ver una línea como la siguiente:

![[436.B7E2_bash.png]]

##### Desactivar el inicio de sesión de root
Nunca inicie sesión como usuario root, de hecho, desactive esa cuenta y en su lugar use una cuenta con permisos limitados y _Sudo_ (Super User Do) para administrar el sistema.

Sudo mejora enormemente la seguridad del sistema sin compartir la contraseña de root con otros usuarios y administradores. También proporciona funciones sencillas de auditoría y seguimiento.

Para bloquear root, basta con ejecutar el comando: 
**### passwd -l root- Bloquea la cuenta del usuario**

Con eso habrá deshabilitado la cuenta de root y solo podrás usar Sudo como medio para administrar el sistema. En caso de emergencia, puedes recuperar el acceso al sistema por medio de un chroot al sistema (iniciando con una distro en modo live y montando el sistema sobre un root externo creado por el chroot). 

##### Seguridad del computador físico
Debe proteger el acceso a la consola física de los servidores Linux. Configurar la BIOS y deshabilitar el arranque desde dispositivos externos como DVDs / CDs / USB pen. Configure la BIOS y la contraseña del cargador de arranque GRUB para proteger estas configuraciones.

Todas las cajas de producción deben estar bloqueadas en los IDC (Centros de Datos de Internet) y todas las personas deben pasar algún tipo de control de seguridad antes de acceder a su servidor. 

##### Desactive los servicios Linux no deseados
Desactive todos los servicios y demonios innecesarios (servicios que se ejecutan en segundo plano). Es necesario eliminar todos los servicios no deseados del inicio del sistema.

Ya que la mayoría de distribuciones GNU/Linux usan systemd, basta con ejecutar el comando:
**### systemctl list-unit-files --type=service**

Para obtener una lista completa de los servicios que se ejecutan en el computador, tal como se muestra en la siguiente imagen:

![[436.B7E2_servicios.png]]

Revisa dicha lista, cualquier cosa que no esté usando, desactívela usando el comando:
- Para detener el servicio de impresora (no tenemos)
**### systemctl stop cups.service-**
- Enmascara el servicio para que no inicie 
**### systemctl mask cups.service-**
- Al final puedes revisar el status del servicio usando el comando 
**### systemctl status cups.service**
- Y esto te mostrará el estado actual del servicio:

![[436.B7E2_estado_actual.png]]

##### Instala solo el software que realmente necesitas
Instalar software en GNU/Linux es muy sencillo, basta con usar los manejadores de paquetes para hacerlo. 

- Por ejemplo, instalar en Debian/Ubuntu, un programa como Audacity (para edición de audio) es tan sencillo como ejecutar el comando:
**### sudo apt install audacity**

Con eso inicia la descarga del software desde los repositorios (un servidor donde se encuentra disponible todo el software compatible con la distribución) y la instalación se realiza de forma automática. Asimismo, desinstalar software es igual de sencillo y la recomendación es desinstalar todo aquello que no necesitas. De esta manera, estarás reduciendo la superficie de ataque que puede haber sobre el sistema, ya que hay menos código y software ejecutándose sobre el computador, lo que reduce las posibilidades vulneración del sistema. 

- Para desinstalar solo debes usar el comando:
**### sudo apt purge audacity **

##### Uso de herramientas de Hardening en GNU/Linux
Una de las herramientas básicas para el Hardening de sistemas GNU/Linux es Lynis. 

Tanto su versión comunitaria como su versión empresarial, permiten ajustar la seguridad de estos sistemas a buenos niveles. De hecho, Lynis Enterprise es capaz de asegurar sistemas para cumplir con los estándares de seguridad PCI DSS, HIPPA, ISO 127001 e ISO 127002, lo que nos permite mantener los sistemas empresariales debidamente protegidos. 

Por supuesto, hay muchas más opciones de seguridad, sobre todo si se usan servicios como Docker o LXC (sistemas de contenedores), en los que la seguridad de los sistemas se amplifica y que necesitan de un estudio más personal de cada servicio que se instale usando este tipo de sistemas. 

En todo caso, cada uno de esos servicios pueden asegurarse usando las baselines y STIGS que se han visto en los módulos anteriores. Por ejemplo, puedes usar un STIG de Apache y Docker, para asegurar Docker y el servicio Apache que se instale dentro el mismo, de esta manera serás capaz de agregar un mayor nivel de seguridad a tu infraestructura Docker.

### Casos de uso de Hardening en el mundo cripto
El Hardening es especialmente útil en el mundo cripto, especialmente, cuando se tiene en cuenta el diseño de sistemas de hardware y software seguro desde sus inicios.

En ese sentido, podemos decir que el Hardening tiene espacios dentro de:
1. **Realización de software y hardware seguro,** usando los mayores estándares de seguridad (ej: Common Criteria) a nivel de criptografía, diseño de software y hardware, generación y manejo de proyectos, entre otros. 
2. **Permitir la instalación y despliegue de servicios públicos y privados de criptomonedas** (exchanges, exploradores, entre otros) que sean seguros de usar y resilientes a los ataques que puedan perpetrarse en su contra.
3. **Ofrecer a los usuarios mejores garantías de que sus tokens y criptomonedas se encuentran seguros dentro de los servicios, hardware y software ofrecido por las empresas del sector.** La transmisión de confianza y seguridad de los servicios ofrecidos permite a las empresas generar una mejor imagen profesional en el sector.

## E3. Legislación y Ciberseguridad
### Legislación (Video)
![[438.B7E3_Legislación.mp4]]
[Legislacion](https://app.web3mba.io?wvideo=8yuituz812)

Existen varios tipos de legislaciones que atañen a distintos tipos de empresas. Generalmente, las legislaciones más extensas suelen estar relacionadas con empresas del mundo financiero, las cuales tienen que cumplir con una gran cantidad de normativa regulatoria y de seguridad para poder brindar sus servicios. Si bien hay muchas normativas y legislación vigente, voy a tratar de destacar dos de las cuales prácticamente todas las empresas están bajo el paraguas. La primera, y sumamente importante para todos, es la legislación que regula la gestión de datos personales.

Como sabemos, a nivel de Europa existe lo que se llama GDPR, que es la normativa de protección de datos personales. Su adecuación en España se llama LOPD, que es la Ley Orgánica de Protección de Datos. Esta ley regula qué son los datos personales, cuáles sí, cuáles no, y de qué forma se tienen que proteger, así como la manera en que se debe comunicar cualquier brecha de seguridad o fuga de información que involucre datos personales.

¿Qué son los datos personales? Los datos personales son aquellos que permiten identificar a una persona. Por ejemplo, a veces solo con un dato personal, como el nombre, no se puede identificar a la persona, ya que puede haber muchas personas con ese nombre. Sin embargo, tal vez con una combinación de datos personales, como un nombre, apellido y dirección, se puede identificar a la persona. Entonces, ¿qué son los datos personales? Hay una lista bastante amplia de datos personales, como nombre, apellido, dirección, correo electrónico y número de seguridad social. Todas las empresas tenemos que cumplir con lo que es GDPR y con lo que es LOPD en el caso de España para hacer un correcto uso y una adecuada protección de los datos personales.

¿Cómo ha logrado la legislación que las empresas pongan foco en la protección de datos personales y que puedan seguir los requisitos que esta legislación exige? Bueno, uno de los aspectos más importantes es definir el rol que se llama DPO, que es Data Privacy Officer, o sea, el oficial de protección de datos, que todas las empresas que gestionen datos personales deberían contar con este rol, que es una persona dedicada a proteger los datos personales.

¿Qué funciones tiene esta persona? Esta persona tiene que velar por los datos personales, saber en detalle en qué sistemas y bases de datos se encuentran estos datos personales, cuáles son los aplicativos que tiene la empresa por los cuales gestiona y recaba esta información, y de qué forma se están protegiendo. Esta legislación garantiza que nuestros datos personales se gestionen de forma correcta. Hace unos años, hubo de público conocimiento una mala gestión de datos personales, lo que llevó a Europa a romper el convenio que tenía, por ejemplo, con Estados Unidos respecto a la legislación sobre cómo gestionar los datos personales. Esta legislación es un error muy importante y grave, ya que también conlleva muchas consecuencias a nivel económico para aquellas empresas que no la cumplan.

La legislación es muy estricta en cuanto a cómo comunicar las brechas de datos personales, en qué tiempo hacerlo y cuáles son las consecuencias de no hacerlo en tiempo y forma. Otra legislación muy importante que existe hoy en día, aparte de la gestión de datos personales, es la legislación que regula la gestión de la información dentro de las empresas. Empresas reguladas, por ejemplo, por el Banco de España, tienen que cumplir con un determinado tiempo de resguardo de la información, en el cual las personas pueden hacer uso de esa información, de sus transacciones. A nivel de recursos humanos, los departamentos que estén bajo esta legislación también tienen que cumplir con cierto grado de retención de esa información, por ejemplo, a nivel de nóminas de empleados, recibos de salario, etc. Tienen que poder mantener esa información durante un tiempo determinado, y eso lo marcan las leyes.

Hoy en día, diría que hay muchas leyes de acuerdo a las empresas y organizaciones que deben seguirse y cumplirse, y que están diseñadas para garantizar que la información que se gestiona en las empresas relacionada con datos personales, datos de nóminas, datos sensibles, como puede ser una empresa que gestione datos de tarjetas de crédito o débito de sus clientes, se maneje adecuadamente. Todas estas leyes y legislaciones nos proporcionan garantías sobre cómo se gestiona la información, y el nivel de exigencia requerido para gestionar esa información varía según el tipo de datos que se manejen.

### Normativas legales en materia de Ciberseguridad
![[439.B7E3_normativas.png]]

La ciberseguridad estaría acompañada por un compendio de normas, puesto que no existe una sola norma que lo regule todo.

Por ejemplo, existe un reglamento específico para establecer un marco jurídico común para los servicios de confianza y los medios de identificación electrónica en la UE: el Reglamento eIDAS.

Pero adicional a este, existe otro conjunto de normas adicionales que deben tenerse en cuenta para considerarse en cumplimiento de los estándares legales de ciberseguridad. 

Y, dado el aumento de los ciberataques y la sofisticación de la ciberdelincuencia, Europa busca dar respuestas más firmes con el fin de: 
1. Protegerse contra las ciberamenzas.
2. Proporcionar un entorno de comunicación seguro, especialmente mediante la encriptación.
3. Garantizar el acceso a los datos a efectos judiciales y policiales.

#### En la Unión Europea
Una de las Directivas Europeas en Ciberseguridad es la Directiva 2016/1148, relacionada con las medidas destinadas a garantizar un elevado nivel común de seguridad en las redes y sistemas de información de la Unión.

Esta Directiva dispone de un par de artículos relacionados con la seguridad de las redes y sistemas de información para los operadores de servicios esenciales y para los proveedores de servicios digitales. En la misma norma, en su artículo 14 se establece que: 

Los Estados miembros velarán porque los operadores de servicios esenciales tomen las medidas técnicas y de organización adecuadas y proporcionadas para gestionar los riesgos que se planteen para la seguridad de las redes y sistemas de información que utilizan en sus operaciones. Habida cuenta de la situación, dichas medidas garantizarán un nivel de seguridad de las redes y sistemas de información adecuado en relación con el riesgo planteado.

Esto quiere decir que los Estados miembros, velarán para que se cumpla con las medidas proporcionadas o adecuadas al riesgo planteado. Además, también deben adoptar medidas con el fin de minimizar, reducir o prevenir incidentes que afecten a la seguridad.

Así mismo, también se deberá notificar sin dilación indebida a la autoridad competente o al CSIRT (siglas de término en inglés Computer Security Incident Response Teams) los incidentes que tengan efectos significativos en la continuidad de los servicios esenciales que se presten para que se puedan tomar medidas con carácter institucional o nacional al respecto, en su caso.

También en el artículo 16 se establece el deber del Estado para que los proveedores de servicios digitales determinen y adopten medidas de seguridad técnicas, organizativas y proporcionadas para gestionar los riesgos existentes a la seguridad de las redes y sistemas de información que se utilizan. Por ello, deben adoptar medidas con relación a la seguridad de sistemas e instalaciones, gestión de incidentes, gestión de la continuidad de las actividades, supervisión, auditorías y pruebas y cumplimiento de normas internacionales.

Sin embargo, en diciembre de 2020, la Comisión Europea propuso una revisión de la Directiva SRI (SRI 2) para sustituir a la Directiva de 2016 y dar respuesta a la evolución de las amenazas, teniendo en cuenta la transformación digital, muy acelerada por la crisis del COVID-19. 

El Consejo llegó a una orientación general sobre la nueva Directiva en diciembre de 2021. Una vez adoptada, la nueva Directiva (SRI2), sustituirá a la de 2016 a fin de "seguir mejorando la resiliencia y las capacidades de respuesta ante incidentes tanto del sector público como del privado y de la UE en su conjunto". 

Además, en junio de 2019 entró en vigor el Reglamento de Ciberseguridad de la UE, e introdujo: 
1. Un sistema de certificación para toda la UE,
2. Un mandato nuevo y reforzado para la Agencia de la UE para la Ciberseguridad.

Gracias a este, la UE ha implantado un marco único de certificación a escala de la UE que generará confianza, aumentará el crecimiento del mercado de la ciberseguridad y facilitará el comercio en toda la UE. 

#### En España
En España tenemos un Código de Derecho de la Ciberseguridad, publicado en el Boletín Oficial del Estado, que cita las principales normas a tener en cuenta con relación a la protección del ciberespacio y el velar por la mencionada ciberseguridad.

En este código se hace referencia a las siguientes leyes, entre otras:

###### Normativas de seguridad nacional
1. **Ley 36/2015,** de 28 de septiembre, de Seguridad Nacional, que regula los principios y organismos clave, así como las funciones que deberán desempeñar para la defensa de la Seguridad Nacional.
2. **Orden TIN/3016/2011,** de 28 de octubre, por la que se crea el Comité de Seguridad de las Tecnologías de la Información y las Comunicaciones del Ministerio de Trabajo e Inmigración.

###### Normativas de seguridad
1. **Ley Orgánica 4/2015,** de 30 de marzo, de protección de la seguridad ciudadana.
2. **Ley 5/2014,** de 4 de abril, de Seguridad Privada.
3. **Con relación a incidentes de seguridad,** existe todo un entramado relacionado con las Fuerzas Armadas, pero también se dispone de una inclusión parcial en la Ley 34/2002, de 11 de julio, de servicios a la sociedad de la información y comercio electrónico.

##### Relacionadas con las telecomunicaciones, existen las siguientes normas
1. **Ley 34/2002,** de 11 de julio, de servicios a la sociedad de la información y comercio electrónico (antes citada).
2. **Real Decreto 381/2015,** de 14 de mayo, por el que se establecen medidas contra el tráfico no permitido o irregular con fines fraudulentos en comunicaciones electrónicas.
3. **La Ley 9/2014,** de 9 de mayo, General de Telecomunicaciones.
4. **Ley 25/2007,** de 18 de octubre, de conservación de datos relativos a las comunicaciones electrónicas y a las redes públicas de comunicaciones.
5. **Relacionado con la ciberdelincuencia,** encontramos inclusiones parciales en el Código Penal, la Ley Orgánica 5/2000, de 12 de enero, reguladora de la responsabilidad penal de los menores; o en el Real Decreto de aprobación de la Ley de Enjuiciamiento Criminal.
6. **También es de aplicación lo dispuesto en la Ley Orgánica 3/2018,** de 5 de diciembre, de Protección de Datos Personales y garantía de los derechos digitales.

Como puede verse, existe un entramado sumamente complejo que tendrá por objeto regular unas u otras situaciones en la red.

#### Otras leyes que regulan la ciberseguridad a nivel técnico y organizativo
Con relación a la ciberseguridad a nivel técnico y organizativo, hay que tener en cuenta también lo establecido por el nuevo Reglamento Europeo de Protección de Datos 2016/679, así como la existencia de otro tipo de protocolos o reglas internacionales, en especial las relacionadas con las transferencias internacionales de datos, como el Privacy Shield.

Estas tan solo son algunas de las normas que tienen por objeto proteger el ciberespacio, pero existen muchas más en detalle que regularían aspectos todavía más concretos.

Por ejemplo, las normas que se deberán tener en cuenta cuando se comete un acto delictivo relacionado con la suplantación de identidad de una marca o empresa, de aprovechamiento ilícito de la misma o de infracción a creaciones de autores protegidas por la propiedad intelectual. En estos casos, además de las normas que aparecen en el código español antes mencionado, se deberá también tener en cuenta el derecho marcario o la normativa de propiedad intelectual e industrial, según corresponda.

La ciberseguridad puede ser quebrantada, por lo tanto, no solo por la comisión u omisión de ciertos actos que tengan que ver con la seguridad en sí misma considerada, sino que en ocasiones se puede afectar a un derecho de un tercero, aprovechándose de actos que vayan en contra, precisamente, de la seguridad en la red.

#### Legislación a nivel internacional
La Asamblea General de Naciones Unidas (AGNU), en el marco de la Primera Comisión, ha logrado llegar a un consenso mínimo en este mismo sentido a través del “Grupo de Expertos Gubernamentales sobre los Avances en la Información y las Telecomunicaciones en el Contexto de la Seguridad Internacional” (GEG).

En el Informe de 2013 del GEG se llegó a un acuerdo en torno a la aplicabilidad al ciberespacio del Derecho internacional existente, en concreto, la Carta de la ONU, los derechos humanos, así como las reglas básicas sobre responsabilidad internacional.

Del mismo modo, el Informe de 2015 del GEG vino a insistir sobre la aplicabilidad en el ciberespacio de algunos principios del Derecho internacional humanitario (como la proporcionalidad o la distinción), así como la obligación de diligencia debida. 

- Algunas iniciativas privadas importantes han secundado esta opción, como ha hecho el Manual de Tallin (2013 y 2017), promovido por la OTAN, y que hace un análisis exhaustivo de esta aplicación analógica. 
- La segunda opción, consistente en la elaboración de nuevos tratados internacionales, ha sido abanderada por Rusia, China y otros países, que han hecho propuestas como el Código de Conducta para la Seguridad de la Información de 2011.

La contraposición entre estas dos opciones se ha puesto de manifiesto en el Informe del GEG de 2017, que ha sido considerado como un fracaso. En efecto, cuestiones tales como el recurso a la legítima defensa, las contramedidas, o el reconocimiento explícito de ciertas normas del derecho internacional humanitario han sido rechazadas por países como Rusia, China o Cuba, sobre la base de que los países occidentales persiguen una militarización del ciberespacio.

Este fracaso puede llevar a pensar que la vía multilateral se encuentra cerrada y que los Estados van a recurrir a la vía unilateral o regional. Sin embargo, a finales de 2018 se han creado dos grupos de trabajo en el marco de la AGNU. Por una parte, se ha puesto en marcha un nuevo GEG patrocinado por EEUU (con 25 representantes gubernamentales) y, por otra parte, se ha creado un Grupo Abierto de Trabajo promovido por Rusia, no incompatible con el anterior y pretendidamente más inclusivo (puede incorporar a todos los miembros de la ONU). 

> Este resultado demuestra una nueva actitud más pro-normativa entre los Estados miembros de la ONU, aunque puede ser a costa de una mayor lentitud y complejidad en el proceso.

Esta actividad pro-normativa puede ser también una especie de reacción gubernamental ante las diversas iniciativas privadas que se está produciendo recientemente. En efecto, además del denominado proceso de La Haya, en el que se inserta el Manual de Tallin II, de 2017, ocupa un lugar destacado la Convención Digital de Ginebra, promovida por Microsoft desde el año 2017.

En el ámbito más limitado de la ciberdelincuencia se ha producido una evolución singular, también animada por la prevalencia de los ciberataques de origen privado, que provocan un coste creciente, valorado en 600 mil millones de dólares anuales, según un informe de 2018. 

En efecto, en el terreno del cibercrimen se adoptó ya en 2001 la Convención de Budapest en el marco del Consejo de Europa. Se trata de una convención que ejemplifica de forma temprana una exitosa cooperación internacional. Esta convención lleva a cabo una armonización mínima en materia jurisdiccional y, de forma específica, en materia de acceso a la prueba digital. No obstante, como en otros supuestos de cooperación jurídica internacional, esta convención se ve lastrada por una importante lentitud en la asistencia entre los Estados parte (las solicitudes tardan meses en ser atendidas) lo que lleva a muchos Estados parte a recurrir alternativamente a instrumentos bilaterales (los conocidos como MLAs). También se ha criticado que esta Convención permite a los Estados eludir las salvaguardas nacionales en favor de los derechos humanos.

Como consecuencia de la escasa efectividad de la cooperación jurídica internacional puesta en marcha con la Convención de Budapest, los Estados han empezado a recurrir a mecanismos de corte unilateral para hacer frente al fenómeno del cibercrimen de carácter transnacional. Una de esas vías unilaterales consiste en el hackeo transfronterizo. No existen hasta ahora ejemplos de denuncia de este tipo de prácticas por parte de Estado alguno. 

No obstante, la certeza sobre la existencia de este tipo de capacidades permite adivinar que su uso se ha llevado ya a cabo en situaciones particulares. Por otra parte, existe otra vía unilateral para el acceso a la prueba digital, como es la que consiste en la obtención de la colaboración directa por parte de los proveedores de servicio del Estado de destino. La ventaja que ofrece esta posibilidad es que convierte en innecesaria la intervención o la autorización de las autoridades del Estado de destino para que el Estado solicitante tenga acceso a la evidencia electrónica. Esta posibilidad es la que ha contemplado la US Cloud Act de 2018 y también es la que prevé la propuesta de Directiva E-evidence, que incluye una Orden de Producción Europea.

Precisamente, desde el Consejo de Europa se ha querido hacer frente a la actual infrautilización de la Convención de Budapest, por lo que se ha iniciado el proceso de adopción de un nuevo Protocolo a la Convención de 2001. Este nuevo protocolo pretende introducir simplificación en el proceso de asistencia jurídica entre los Estados parte, mejorando así las cifras que se han obtenido hasta la fecha en este sentido. El resultado final al que se pretende llegar con el protocolo permitiría al Estado de origen hacer prevalecer sus normas aplicables sobre la materia como consecuencia del ejercicio de su jurisdicción para perseguir el ciberdelito de que se trate. 

> ONGs como Edri o EFF han criticado este intento por elaborar un nuevo Protocolo, ya que consideran que supondrá con toda seguridad una erosión de los estándares aplicables en el Estado de destino.

Teniendo en cuenta que entre los Estados del Consejo de Europa no sólo no hay armonización de normas penales, sino que los sistemas jurídicos nacionales son muy diversos, los ámbitos que se podrían ver más afectados serían los relativos a los derechos humanos protegidos en el Estado de destino, entre los que hay que destacar el derecho a la privacidad y la protección de datos personales, así como las salvaguardas de carácter procesal aplicables en dicho Estado de destino.

En el plano de la ONU, una propuesta de Rusia sobre una Convención contra el Cibercrimen fue rechazada ya en el 2010. En el 2011, la Comisión para la Prevención del Delito y la Justicia Penal (CPDJP) creó un Grupo de Expertos, a petición de la Asamblea General, para realizar un estudio exhaustivo sobre el cibercrimen, con el objeto de preparar respuestas jurídicas o no, nacionales o internacionales, para afrontar este fenómeno. Este estudio exhaustivo sobre el cibercrimen fue encargado a la Oficina de la ONU contra las Drogas y el Crimen y completado en 2013. La labor del Grupo de Expertos continuará hasta 2021 en que está previsto que finalice su tarea. 

Sin embargo, existe un desacuerdo en el marco de la ONU sobre cómo afrontar la lacra del cibercrimen. Por una parte, EEUU y sus aliados entienden que la Convención de Budapest es un texto suficiente para luchar contra el cibercrimen. Además, la labor del Grupo de Expertos está por finalizar, de modo que en la actualidad lo más conveniente es esperar a evaluar los resultados de ese trabajo. Por otro lado, Rusia y otros Estados han manifestado que prefieren la elaboración de un nuevo texto universal que materialice un consenso global, por tanto, un consenso que no se limite a los Estados parte del Consejo de Europa. Además, en su opinión, ciertos mecanismos del Convenio de Budapest, como el artículo 32.b, suponen un atentado a la soberanía del Estado territorial, ya que implica la posibilidad de eludir la previa autorización de dicho Estado con ocasión de la obtención de la evidencia electrónica.

En este contexto, ha sorprendido a ciertos países occidentales que se haya aprobado recientemente por la AGNU una Propuesta de Convención sobre el Cibercrimen a finales de 2019. En efecto, la mayoría alcanzada para adoptar esta Resolución ha puesto de manifiesto un voto divisivo (79-60-30), pero esta vez a favor de la iniciativa normativa. La propuesta de convención está basada en un borrador presentado por Rusia en 2017. 

Este borrador incluía una lista de los ciber delitos perseguibles (entre los que se encuentra el hackeo), las distintas opciones de cooperación jurídica entre Estados, así como el establecimiento de un Centro de contacto para investigaciones. Con el objeto de hacer avanzar la propuesta aprobada por la ONU en 2019, se ha incorporado la creación de un Comité Abierto de Expertos ad hoc. No obstante, esta propuesta de la ONU ha sido criticada por las ONGs. Se aduce por parte de éstas que, teniendo en cuenta que su promotor es Rusia, la propuesta no puede conducir sino a una mayor criminalización de las conductas en Internet, en línea con el mayor control estatal que Estados como Rusia o China promueven en la Red. En su opinión, con esta propuesta se quiere ir más allá de las previsiones recogidas en el Convenio de Budapest, de modo que la posibilidad de rechazo de solicitudes de asistencia por parte del Estado de destino se reduce. Además, habría que dejar que el Grupo de Expertos del CPDJP terminase su trabajo en 2021.

> La propuesta de un nuevo Convenio de la ONU sobre Cibercrimen es un ejemplo de la nueva actitud más pro-normativa que parece ir consolidándose en la actualidad.

Por un lado, la Convención de Budapest acumula una experiencia de dos décadas, con gran aceptación entre los Estados (hay 65 Estados parte y muchos la han incorporado a su legislación nacional). En particular, ha sido objeto de una Declaración de Apoyo por parte de la UE que, junto a EEUU, rechaza la propuesta de la ONU. Por otro lado, Rusia, China y muchos [PVD](https://cybersophia.net/articles/what-is/what-is-passive-vulnerability-detection/) aducen que la Convención de Budapest representa a un club limitado de Estados, lejos del consenso global que se puede alcanzar en la ONU. De hecho, esta opción por una nueva convención ha ido ganando peso entre los Estados miembros de esta organización, bien porque los equilibrios de política exterior han ido mudando (hay Estados parte de la Convención de Budapest, incluso del Consejo de Europa, que han votado a favor de la propuesta), bien porque existe un creciente atractivo en torno a un nuevo Tratado Global sobre esta materia y el consiguiente refuerzo de la soberanía estatal que puede conllevar.

Desde el punto de vista jurídico, no deben obviarse las consecuencias derivadas de la adopción de una nueva Convención sobre el Cibercrimen que, como la Convención de Budapest, aspira a la generalidad. Si existen dos convenciones sobre la misma materia habrá que recurrir al artículo 30 de la Convención de Viena sobre Derecho de Tratados. Con independencia de la solución que haya de adoptarse en cada caso, recurriendo a una suerte de bilateralización, lo cierto es que la existencia de dos marcos jurídicos de carácter general sobre la misma materia no va a ayudar a la simplificación de la asistencia jurídica entre Estados.

#### En conclusión
Existe una ausencia de consenso normativo que enfrenta a EEUU y los países occidentales, por una parte, y Rusia, China y muchos PVDs, por otra. 

- Los primeros abogan por una aplicación analógica de las normas existentes al ciberespacio. 
- El segundo grupo prefiere la elaboración de nuevas normativas.

Las causas de esta ausencia de consenso son tanto políticas (Internet abierto y protección de los derechos humanos frente a Internet cerrado y mayor control estatal) como estratégicas (defensa de la actual ventaja tecnológica frente a ruptura del status quo). 

Esta ausencia de consenso resulta peligrosa para la estabilidad de las relaciones internacionales, así como para la capacidad de frenar los ciberataques, amén de la dejación de funciones que implica y que explica la proliferación de iniciativas normativas privadas. Además, en el ámbito más concreto del cibercrimen, se produce una cierta paradoja. 

Las percepciones sobre la defensa a ultranza de la soberanía estatal, por unas razones o por otras, impiden avanzar en cuanto a la normación se refiere. Sin embargo, una mayor cooperación en este terreno conduciría a una protección más efectiva de los intereses estatales, ya que en la situación actual las veleidades unilaterales siguen siendo frecuentes.