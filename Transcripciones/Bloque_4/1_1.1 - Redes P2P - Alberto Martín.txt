Speaker speaker_not_detected | 00:14.902
4, unida 1, toma 2.

Speaker 0 | 00:25.918
Las redes P2P vienen de la necesidad de poder conectar ordenadores de manera punto a punto, de manera final a final, sin tener un servidor intermediario que tenga que mediar la comunicación. Esto surgió más o menos en los años 80, cuando dentro de protocolos UNIX, dentro de protocolos GNU, se querían poder subir ficheros de una manera que no tuviésemos que pasar por un servidor central que pudiese tener luego una copia de ese fichero. La gente que ahora utiliza... más distribuciones GNU, MacOS y cualquiera por el estilo, les se donará mucho SSH o SCP, la manera que tenemos ahora mismo de conectarnos con una sesión a un servidor remoto. El origen de todo ello viene de cómo se implementaron las primeras redes P2P. Y luego esas redes empezaron a crecer con distintas características, con distintas necesidades a cubrir, y fueron evolucionando de manera diferenciada a lo que conocemos a día de hoy. Ejemplos de las más conocidas a día de hoy. de hoy puede ser BitTorrent, pero a nivel técnico para operativo puede ser este protocolo SCP que comentábamos, que lo que queremos en el fondo es hacer un supercopy de punto A a punto B. Sobre cómo funcionan, tenemos que empezar a pensar cómo funciona una red desde un punto de vista técnico. Dentro de ese punto de vista técnico, si vemos cómo funciona un mensaje sobre HTTP, sobre internet, vemos que tenemos distintos niveles de jerarquía de paquete. Dentro del protocolo TCPIP tenemos siete. Dentro de la red P2P lo que estamos trabajando es sobre el protocolo 7, sobre el protocolo de aplicación, en el cual lo que hacemos es intentar crear una red de nodos, las cuales van a tener direcciones de sus vecinos y gracias a ello vamos a poder ir haciendo una mini internet en la cual todo el mundo tiene acceso a los datos que tiene todo el mundo. Las ventajas principales que yo diría que de una red P2P son varias. La primera pasaría por el hecho de no necesitar ese punto único de fallo que va a tener siempre una red centralizada. Si solucionamos el problema de no tener un single point of failure, empezamos a tener luego distintas habilidades que nos pueden implementar, por ejemplo, las descargas de ficheros de manera distribuida. No tenemos por qué tener una representación única del fichero, sino que la podemos tener distribuida y la podemos coger de muchos sitios a la vez en participaciones. Y a su vez podemos estar compartiendo con no únicamente un servidor, si queremos expandir una noticia o queremos expandir un dato, sino que podemos hacerlo de manera particionada y simultánea en muchos sitios a la vez. Pues yo creo que sobre todo a nivel España, las primeras implementaciones fueron el típico Kaza, Emule, Napster, que aquí llegó un poquito menos, que lo que intentaban era redistribuir en aquella época sobre todo. contenido que tradicionalmente estaba protegido por copyright, darle una segunda vida útil a partir de esa comunicación peer-to-peer. Dentro de aquella época, se vieron también no solo las ventajas, sino algunas de las desventajas de la red, y es que cuando tenemos una red distribuida, hay que cuidar con mucho cariño la calidad del contenido que circula por esa red, porque cuando hay un fichero corrupto, podemos empezar a distribuirlo y spot-staff de los propios miembros el poder identificarlo y quitarlo de la red. Lo que necesitas principalmente es un software que cada cliente pueda descargarse y un conjunto de clientes o nodos que vayan a estar corriendo ese software. Una vez que tienes cada participación del cliente, lo que empieza a funcionar es el hecho de poder conocer a tus vecinos. En el fondo, tú lo que necesitas es una red de vecinos, a los cuales, en el fondo, a uno le puedas pedir sal, a otro le puedas pedir pimienta, y tú a la vez puedas decir a tus vecinos que tienes leche y pan. Para poder hacer todo eso, hay que tener unas tablas de paginación en las cuales tengamos unos índices para poder descubrir qué es lo que tiene cada uno realmente. Y esto a escala pequeña funciona bien, pero lo complejo es poder hacerlo a mayor escala. Una de las primeras que se basaba en texto era el IRC. IRC es un caso muy curioso de redistribuir a peer-to-peer porque no empezó como tal. Al principio teníamos un directorio central el cual guardaba ese índice de vecinos con sus direcciones y a partir de ahí podíamos empezar a crear una conversación con ellos. Luego se aplicó también para ficheros, pero la idea era poder tener comunicación. ¿Qué pasó? Que llegó un momento dado que la gente no quería que su comunicación pasase por ese índice central y querían tener un entorno en el cual los propios miembros de la comunidad fuesen los que estaban al poder. y los cuales miembros de subcomunidades pudiesen hacer su propio IRC privado porque a pesar de que la red es pública y accesible puede ser desconocida. Ahí es donde se pasó de tener esa tabla de índices central a tener varias tablas de índices distribuidas. Ya hemos comentado por encima un par de ventajas que tienen estos sistemas desde el punto de vista ya sea filosófico o de caso de uso pero cabe comentar también ventajas y desventajas que tienen estos sistemas a nivel técnico. Si nos centramos sobre todo en las ventajas, tenemos una red que no se puede censurar. En países donde es posible que los ISPs, que son los proveedores de servicio de Internet, estén controlados por el gobierno, tenemos situaciones como en China, por ejemplo, en las cuales no se pueden acceder a ciertas páginas web. Cuando estás distribuyendo de manera... pierde o pierde el contenido, no hay posibilidad de que un servidor DNS vaya a denegar una ruta concreta porque es una red de nodos los que van a servir ese contenido. Si hablamos después sobre distintos tipos de escalabilidad que vamos a tener para compartir un fichero de vídeo, un fichero de audio, como por ejemplo esos casos iniciales en los cuales teníamos BitTorrent. Esto ha evolucionado mucho, mientras que al principio teníamos un sistema en el cual se bloqueaban las descargas y era entre peer-to-peer, yo descargo tu fichero, ahora ya podemos tener particiones distribuidas en las cuales podemos ir almacenando trocitos de distintos proveedores, los cuales no son bloqueantes y gracias a ello podemos tener acceso a nuestros archivos con mayor celeridad de si al contrario intentásemos descargar de un servidor centralizado. Otra de las ventajas es que también es agnóstica del tipo de fichero que queremos plantear. Podemos plantear sobre la misma red, sobre el mismo ecosistema y sin cambiar absolutamente nada, desde mandar un tweet a descargarte una canción, a descargarte una base de datos de wallets comprometidos sobre los que no quieres aceptar transacciones. Entonces lo bueno que tenemos es que solo hace falta montar una infraestructura y a partir de ahí cualquier tipo de información es libre de fluir. Vale, si vamos a plantear las desventajas del sistema, podemos empezar por qué pasa con esta red de esa escala. Y qué pasa con esta red de esa escala va a depender mucho del tipo de algoritmo que se utilice para esta distribución de nodos. Según el tipo de fichero que queramos distribuir, unos van a tener más calvidad que otros y según el número de nodos que intentemos mantener, la replicación de esa información va a ir siendo más lenta. Por eso es posible. que ciertas redes distribuidas o ciertas redes peer-to-peer, para según qué casos de uso, directamente no sean operables. Otro caso sería el hecho de comentar que una red distribuida es prácticamente incensurable, pero no es un protocolo que por defecto, a no ser que esté diseñado específicamente para ello, te va a dar privacidad. Esto pasa, por ejemplo, en Alemania. Yo vivía allí y BitTorrent está capturado, todo el tráfico de BitTorrent, por los ISPs y te puede caer una multa porque el tráfico peer-to-peer de contenido protegido por copyright pues no se puede hacer. Entonces, este tipo de tráficos pueden venir de la mano de otras medidas secundarias que... auguran esa privacidad, por ejemplo, hacer un peer-to-peer en torno a la red de Tor, o hacerlo a través de una VPN que tenga ciertas características, pero tenemos siempre que tener en cuenta que la red distribuida nos da libertad de distribución, pero no privacidad sobre lo que distribuimos. Ya por último comentar también... problemas que hay a nivel estructural, todo tipo de red, todo tipo de ecosistema tiene sus pros y sus contras y dentro de las redes distribuidas, las redes peer-to-peer, tenemos casos de uso en los cuales podemos permitir, si el diseño no es lo suficientemente robusto, ataques, por ejemplo, tipo eclipse. En un ataque tipo eclipse lo que está pasando es que intentas aislar un nodo, por así decirlo, crearle un eclipse y puede ser con distintas finalidades, desde reducir su capacidad de minería, o poder meter transacciones fraudulentas. Esto se consigue a medida de poner nodos replicantes que vayan apuntando vecinos muy cercanos a ello y son tecnologías que tienen que estar específicamente diseñadas, cuando hablamos de entornos cripto, para ser también resilientes a este tipo de ataques. ¿Cómo entró todo esto en criptomonedas? Fue obviamente con la primera blockchain que hemos tenido, con Bitcoin, y para ello, cuando Satoshi estaba diseñando el sistema, se fijó bastante en cómo lo estaba haciendo BitTorrent. BitTorrent lo que hacía en aquella época es ya tener unos algoritmos que empezaban a distribuir por distintos nodos la carga lectiva, y dentro de ello hicimos un... un approach similar. ¿Cómo funcionaba esto luego traducido a la minería? y la minería es la acción de encontrar la solución a un bloque y añadirlo a la cadena. El bloque que se añade a la cadena es retransmitido a todos los nodos. Si tenemos una cantidad fija de nodos y una cantidad fija de mineros tenemos que tener una robustez en el sistema la cual nos permita hacer que ninguno de los agentes activos que están validando esas transacciones pueda meter una transacción maliciosa. Esto posiblemente os suene con la regla del 51%. la cual dice que si la mitad más uno de los nodos están de acuerdo en algo, ese algo es cierto. Y para poder meter una transacción maliciosa, tendrías que, en un tiempo muy corto, en un periodo muy corto de tiempo, poder engañar a esa mitad más uno de los nodos. ¿Qué es lo que pasa en un momento dado? Que si tenemos, por ejemplo, 20 mineros y 100 nodos, y esos 20 mineros, 10 de ellos capturan... el poder de 80% de los nodos, cosa que a escala de hoy es impracticable a nivel potencia de cómputo, tendríamos la situación en la que esos mineros podrían intentar inyectar esa transacción maliciosa. Si por tener la mayoría de los nodos esa transacción va adentro, se provocaría una situación en la que unos nodos la aceptan, otros no la aceptan y eso crearía un hard fork. El hard fork será la bifurcación de la blockchain, en la cual se crean dos redes peer-to-peer diferenciadas, en las cuales cada una de ellas va a tener unas reglas de consenso completamente separadas. Este tipo de algoritmo y este tipo de prácticas no se reducen solo a Bitcoin. Si nos ponemos a ver todas las redes que hay en blockchain, todas son distribuidas y cada una de ellas tiene una participación u otra de ciertos algoritmos que se han ido evolucionando a lo largo del tiempo. Cabe comentar como separación respecto a Bitcoin el que tiene Ethereum. Si nos fijamos en cómo se hace minería día de hoy, tanto de Bitcoin como de Ethereum, hay patrones diferenciados. Bitcoin permite que con cierta potencia de cómputo puedas tener un performance mayor dentro de la minería que estás haciendo. Mientras que Ethereum lo que está premiando es el hecho de tener una minería descentralizada. ¿Qué pasa al tener una minería que premia la descentralización respecto a la eficiencia? Que obviamente es menos eficiente. al tener que hacer esa descentralización, tienes que tener mucha más duplicidad de datos, tienes que tener muchos más mensajes intercambiados para poder sincronizar todo a la vez, y esa escala, obviamente, va a hacer que las cosas vayan un poco más lentas, lo cual se acaba traduciendo en un gas-fee más caro. El tipo de algoritmo que tiene Ethereum se llama Cadembria, del cual hablaremos en breves en más profundidad. Y lo que hay que comentar es que no están solos en este tipo de implementación, Hay otros protocolos como IPFS o Filecom que siguen la misma característica. Tanto IPFS como Filecom lo que tratan es conseguir una red peer-to-peer en la cual vamos a distribuir ficheros de manera libre y en la cual cada uno de nosotros podamos actuar como un nodo activo teniendo participaciones de esos ficheros. Al tener participaciones de esos ficheros lo que se asegura es que la confidencialidad de la totalidad del fichero y gracias al algoritmo que focaliza sobre todo en la distribución, vamos a tener esa garantía de que es robusto, no solo para la privacidad, sino también para la imposibilidad de distribuirlo. Comentar que Ethereum no está solo en este tipo de implementación, Cadembly también ha sido adoptado por proyectos como IPFS o Filecon, que lo que tratan es crear redes distribuidas en las cuales se puedan intercambiar ficheros peer-to-peer, permitiendo que cualquiera de nosotros podamos ser nodos activo. Aquí de nuevo vemos la importancia de tener un algoritmo que premie esa descentralización masiva aunque repercuta un poco en en el performance. Esto es debido a que lo que queremos si estamos subiendo un dato a esta nube distribuida es que por un lado esté muy particionado para que nadie pueda tener acceso a la totalidad del fichero y por el otro nadie pueda tener el poder suficiente como para poder reconstruirlo. Entonces, desde esas perspectivas vamos a ir viendo poco a poco cuál es el uso característico de Academia. Vale, cada emilia es el algoritmo que se ha decidido utilizar, como comentábamos, tanto en Ethereum como en Filecoin y en otros proyectos, por lo siguiente. Es un algoritmo que es robusto a la hora de poder encontrar caminos entre nodos cuando un nodo desaparece. y es a la vez capaz de soportar ataques de denegación de servicios. Cómo funciona o la característica principal de este algoritmo es que no organiza los nodos de una manera distribuida como si fuese una sopa, sino lo que hace es como una especie de árbol. Tienes un árbol binario en el cual vas teniendo distintas caídas de nodos que van a tener particiones de estos tipos de ficheros, particiones de este tipo de transacciones o particiones de lo que queramos guardar en el fondo, todo es información. ¿Qué pasa cuando tenemos ese árbol de nodos, que en el fondo es imaginarse un sauce? Que lo que tenemos que tener es una posibilidad algorítmica de poder acceder a cada uno de los nodos en caso de que haya una fatalidad. Y esto es lo bueno del algoritmo. Este algoritmo es muy bueno para evitar ataques de denegación de servicios, porque los ataques de denegación de servicios lo que intentan es ir a por una familia de nodos, bombardearla y que a nivel de performance no pueden aceptar más transferencias entrantes. Con academia lo que tenemos es la seguridad de que como máximo en 20 pasos podemos acceder a cualquiera de los nodos y si un nodo ha fallado ese nodo se salta y volvemos a hacer un arbolito que nos vaya a llevar al siguiente. Si ese nodo sigue estando denegado vamos al siguiente. y tenemos la certeza de que a no ser que hayan tumbado absolutamente toda la red, como mucho en 20 pasos, hemos encontrado un nodo sano al cual le podemos transmitir la información. Si queremos hacer un poquito más de deep down a nivel de lo que es la implementación técnica por debajo de este algoritmo, lo que tenemos que tener es, como comentábamos en un principio, una cantidad de nodos distribuida y esa cantidad de nodos tiene que haber descubierto sus vecinos. Una vez que descubres a tus vecinos, los tienes que guardar en una especie de índice. Esa especie de índice la conforma lo que se llama una tabla de hash. Tabla de hash son básicamente la primera hoja de cada libro en las cuales sin tener la dirección completa tienes la dirección parcial que te permite poder llegar a ese vecino. Cuando llegas a ese vecino, si ese vecino no puede proveerte servicio, saltas al siguiente. Si no, saltas al siguiente. Y esto lo que te va a hacer a nivel técnico es requerir que tú vayas, a medida que vayan fallando vecinos, preguntar a la red por vecinos nuevos. Por ello hay como tres o cuatro operaciones específicas dentro de cualquier red distribuida que utilice este tipo de algoritmo, que en el fondo van a ser, da mi información, toma información y hola, buenos días. El hola, buenos días es un ping. Si tú le haces ping a una dirección, te tiene que contestar con un pong y eso sería lo que añadimos a nuestra hoja de índices. Esto está pasando en tiempo real y de manera distribuida. Por eso decimos siempre que, a pesar de tener una red como Ethereum que tiene un nivel transaccional importante, gran parte de los mensajes siguen siendo para mantener la integridad de la red. ¿Por qué? Porque a día de hoy tenemos gente intentando meter software malicioso cada dos por tres y es la propia robustez del algoritmo la que nos protege de ello. En el fondo, cuando hablamos que... cierta blockchain tiene un consumo eléctrico brutal o que otra blockchain tiene un consumo eléctrico mucho menor, muchas veces está basado en las necesidades que tiene esa blockchain, no solo para validar transacciones, sino para mantener la robustez que hemos comentado. Por ello, algoritmos como el que estamos comentando, van a tener un tráfico mayor que algoritmos que permitan la centralización y por ello podemos concluir, por ejemplo, que Ethereum tenga un consumo eléctrico muy alto, un gasto eléctrico mayor que el de Solana, un performance menor que el de Solana. Hay que tener en cuenta para este tipo de soluciones, que según el algoritmo que utilicemos, hemos dicho que vamos a tener una cantidad de mensajes bastante diferenciada. si premiamos performance o premiamos robustez, y vamos a tener situaciones en las cuales, por ejemplo, podremos entender por qué Bitcoin o Ethereum son más caros que Solana, por ejemplo. Teniendo aparte que Bitcoin es proof of work, Ethereum es proof of stake, o Ethereum.2 va a ser proof of stake, tenemos aquí la situación en la cual esas diferencias de cómo manejamos la robustez del algoritmo van a darnos. una necesidad mucho mayor de consumo eléctrico y consumo transaccional.