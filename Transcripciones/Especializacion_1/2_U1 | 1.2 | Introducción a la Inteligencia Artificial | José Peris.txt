Speaker 0 | 00:19.254
Para entender otro concepto importante en Machine Learning, para poder seguir hacia adelante, debemos saber que este campo se centra mucho en el estado del arte. ¿Qué es el estado del arte? El estado del arte lo definiríamos como en qué punto nos encontramos, cuál es la última tendencia, cuál es el último avance, cuál es el último hito que se ha alcanzado tecnológico. Para que os hagáis una idea, todo esto empezó con la programación tradicional. basada en los bucles, por ejemplo, if else, son condiciones muy simples y bucles. Pero posteriormente apareció el machine learning, que fue el primer gran salto. Machine learning lo que hizo fue poder desarrollar algoritmos y tiene una característica aquí que, bueno, puede trabajar con big data, pero puede trabajar también con menos datos. Por otro lado, machine learning es muy. útil porque permite muchísima explicabilidad de las características del algoritmo. Más adelante veremos un poco qué es todo esto. Posteriormente llegó el deep learning, que al final, como hemos comentado, lo que hace es copiar el funcionamiento del cerebro humano. Sí que es cierto que deep learning es mucho más atractivo y es más avanzado a nivel de estado del arte, pero tenemos un handicap donde tenemos que trabajar con cantidades de datos mucho más elevadas para obtener resultados optimales. Después del Deep Learning vino el Automation Learning. Esto ya prácticamente rizar el rizo, porque estamos hablando de inteligencia artificial que hace inteligencia artificial. Esta ventaja sobre todo se han visto beneficiados o perjudicados, depende de cómo lo miremos, los desarrolladores. ¿Por qué? Porque lo que hace es aplicar inteligencia artificial a procesos de la elaboración del algoritmo que son muy tediosos. Al final, en pocas palabras, lo que hace es simplemente nos permite optimizar el tiempo y ser mucho más ágiles, aunque es cierto que no porque se optimice todo podamos utilizarla sin tener conocimientos de este campo, que sería el data science. Y ya por último, lo que sería el estado del arte de hoy, tendríamos los transformers. Los transformers ha sido la disrupción más fuerte que hemos tenido en 2021. y que veremos a continuación. Cuando hablamos de Transformers, hablamos de GPT-3. GPT-3, en una frase, es el chat más inteligente del mundo. Estamos hablando de hitos que eran impensables alcanzar hace unos años. ¿Por qué? Porque GPT-3 ha entrenado con millones de librerías de Wikipedia, de todos los libros que existen casi disponibles online. Y claro, todos tenemos la imagen del chatbot, que le haces cuatro preguntas y se quita el chatbot. equivoca la tercera o no tiene coherencia en sus respuestas. GPT-3 es un producto de OpenAI, y detrás de OpenAI está Elon Musk, que sabemos ya que es el chat más inteligente del mundo, ¿por qué? Porque es capaz de coger la personalidad, por ejemplo, de un personaje histórico. Es decir, en GPT-3 puedes hablar con Albert Einstein y tener una conversación coherente, tener un diálogo totalmente coherente con él, pero él va a hablar siempre con su lenguaje y con sus palabras. En el mismo chat puedes añadir a Elon Musk, o puedes añadir a Gandhi, o puedes añadir todos esos personajes públicos que hay mucha literatura, en la red, al haber mucha literatura sobre ellos, hay datos, datos para el entrenamiento. Pero la ventaja de los Transformers, y es algo que se utiliza mucho en este campo, es que es un campo muy líquido, es decir, el conocimiento que se descubre en el campo, por ejemplo, del habla, o de la escritura, se puede tener un buen conocimiento. trasladar a la imagen. GPT-3 nació en 2021, la versión beta se liberó. Y, bueno, estamos hablando también que al estar entrenado de esta forma tan eficiente, llega el punto al que tú puedes pedirle, por ejemplo, a GPT-3 que te diseñe una página web, que tenga dos botones en el centro, uno de color rojo y otro de color negro. Y no es solo que te la va a generar, sino que te va a generar el código. Es capaz de programar en casi cualquier lenguaje. de programación. Simplemente tienes que pedirle que te haga una función matemática que cumpla una serie de condiciones y lo que va a hacer es generarte el código. y después con este código puedes ejecutar este programa y te va a funcionar. Estamos hablando de un salto realmente muy, muy potente. Esta es la potencia de GPT-3, que la podéis comprobar en el Playground, que os dejamos aquí adjunto el enlace para que podáis jugar. Simplemente tenéis que registraros con vuestra cuenta de Google. Podéis comprobar que incluso le podéis pedir que os escriba un ensayo entre Platón y Aristóteles hablando sobre el concepto del amor. una longitud de carácteres que vosotros deséis. Y os va a establecer, os va a crear un ensayo coherente. Incluso le podéis pedir que cogeis los ingredientes que tenéis en la nevera y pedir que os haga una receta. Con esos ingredientes yo os la va a hacer. Por supuesto, no es perfecto al 100%. Estamos hablando de una versión beta, pero realmente ha llegado a unas cotas que eran impensables hace unos años. Como os decía, este campo es muy líquido. Y cuando llegan sorpresas suelen llegar juntas, porque lo que hay es mucha capilaridad entre proyectos. También apareció Dalí. obra de OpenAI, donde rompió el paradigma también de lo que es la visión artificial, porque ya estamos hablando que aquí se ha juntado el conocimiento que se ha avanzado en el tema del habla y la escritura, con el conocimiento de la imagen. ¿Qué significa todo esto? Que simplemente mediante palabras podemos crear, por ejemplo, objetos o conceptos gráficos que nunca han existido. que no están en ninguna base de datos. Simplemente, esta combinación de estos dos algoritmos, esto podéis ver, es un ejemplo de la narrow intelligence, como cuando se combinan, pueden llegar a algo mucho más amplio o mucho más elevado. La realidad es que los resultados también son fascinantes, pero sí que es cierto que con Dalí hubo un impasse donde se frenó el desarrollo, Y bueno, vino un desarrollo por otro lado con Glyde. Glyde lo que ha hecho es mejorar todo esto y estamos hablando de que si tú quieres a Glyde, le puedes pedir también que te dibuje una ilustración de Albert Einstein con un vestido de Superman y te la va a hacer. O que le pidas que te dibuje a un gato jugando al ajedrez con el estilo de Dalí. y te lo va a ejecutar. Es decir, imágenes imposibles, imágenes que nunca han existido, porque al final se combina la semántica con la imagen. Pero bueno, esto estamos hablando de, como os decía, del estado del arte. Esto es el punto máximo. Y también comentaros que algunos de estos algoritmos sí que están disponibles para testar la versión beta o tenemos el código ya. Pero, ¿cómo se hace? otros, pues aún no, simplemente se han utilizado para mostrar el potencial de dónde podemos llegar. Por ejemplo, ¿qué puede hacer por nosotros Glide? Para mí, Glide puede hacer algo totalmente fascinante, como es el uncrapping. El uncrapping no es más que tú, imagínate que le tomas una foto a tu amigo o tu amiga, y el uncrapping lo que te hace es, mediante algoritmos de visión artificial, lo que te hace es que te reconstruye, te amplía la escena. Él mismo se va inventando la escena que continuaría, con lo cual nos amplía el campo. El punto en el que nos encontramos ahora es muy excitante, simplemente por el hecho de que comienzan a confluir las tecnologías. Por un lado tenemos las tecnologías descentralizadas y por otro lado tenemos inteligencia artificial. Esto a que nos lleva a que podemos generar NFTs simplemente por la tecnología. utilizando código de inteligencia artificial. Es por ello que algoritmos como vkugan más clip nos están permitiendo generar aquí lo que nosotros queramos simplemente incluyendo tres, cuatro palabras. Es decir, podemos pedirle que nos genere un animal en un estilo modernista, en una... escena del universo. Estamos hablando de imaginación, de creatividad y si os fijáis casi siempre os hablo de que es VQGAN más clip, estamos hablando de la suma de dos algoritmos, del ensamblaje. ¿Por qué? Porque lo que hacemos es unir, unir características de diferentes algoritmos. En este caso, lo que estamos uniendo es Clip, por ejemplo, que lo que hace es un clasificador que describe de forma muy exacta la imagen que está viendo a un nivel de detalle muy elevado. Es decir, no es lo mismo detectar que la imagen que está viendo un algoritmo de visual artificial es un coche o una bicicleta que detecte que, por ejemplo, está viendo una imagen de un husky siberiano sobre una vidriera. Estamos hablando de niveles de detalle muy diferentes. Este avance en la semántica ha permitido, al fusionarlo con la imagen, llegar a cotas muy elevadas. Lo mismo que VQGAN, que viene de las GANs, Generative Adversarial Networks, que lo que hace a nivel de imagen es comprender la profundidad de la imagen que está viendo. Imaginaros que estamos viendo una imagen de un pájaro o de un perro, lo que hace es calcular este vector de profundidad y entiende que esto es un animal que se llama pájaro que puede estar representado con plumas de diferentes colores o con picos de diferentes formas. Lo mismo para un perro, puede tener diferentes texturas, diferentes tipos de arrugas. Claro, todo esto nos lleva a que realmente lo que vamos a ver, y de hecho lo vais a practicar, os vamos a dejar aquí... una pieza del código donde podéis crear vuestro NFT a partir de las palabras que vosotros creáis y os lo convierte a vídeo, también os lo anima. Claro, todo esto realmente... ha pasado a partir del 2021, venía con mucho recorrido detrás. Por tanto, este es el estado del arte de hoy. Como os comentaba también, Automachine Learning básicamente se basa en automatizar las tareas del Data Scientist. ¿Y qué significa eso? Básicamente, de una forma muy genérica, lo que hace un científico de datos es, primero, recopilar datos, gran cantidad de big data para resolver un problema y lo que hace pues bueno estos datos se tienen que limpiar, se tienen que preparar, porque al final estos datos muchas veces están rellenados por personas que han rellenado una base de datos y pueden haber insertado un valor nulo, por ejemplo esto hay que limpiarlo, es un proceso que se llama ETL que significa Extract, Transform, Unload y AutoML ya permite agilizar este proceso. Estamos hablando que un algoritmo se puede desarrollar o diseñar en en horas o en semanas o en meses o en años dependiendo de la complejidad a la que nos enfrentemos. Por tanto, si cogemos una una métrica estándar, como puedan ser dos o tres meses, el proceso de TL representa el 80%. y el proceso de selección del algoritmo puede representar el 20, 30, depende del problema que estemos afrontando. ¿Qué hace el AutoML? En estas dos partes más tediosas nos automatiza los procesos y al final lo que nos va a hacer es limpiar de forma más o menos automatizada y nos va a hacer una clasificación de qué algoritmos son los mejores que encajan para tu problema. Con lo cual, al final, esto se trata de inputs y outputs. Entonces, el input son los datos y el output que te va a dar el AutoML es limpieza de los datos y un ranking con los mejores algoritmos para resolver tu problema. El tercer punto es el deep learning. Deep learning, como os he comentado, se trata en trabajar... con capas y con números de neuronas. Al final, pues imaginaros un clasificador. Hemos dicho que la inteligencia artificial predice, clasifica y agrupa. Imaginaros que, mediante visión artificial, queremos hacer un clasificador que sea capaz de clasificar entre lo que es un perro y un gato. ¿Cómo funciona el deep learning? Pues bueno, el deep learning lo que hace es imaginaros, establecemos... una serie de capas con un número de neuronas donde cada capa de neuronas es encargada de realizar una función específica. Imaginaros que las primeras capas lo que van a hacer es analizar de lo general a lo concreto. Es decir, las primeras van a analizar, van a buscar una forma de una cabeza de un perro o una forma de una cabeza de un gato. Al final, aquí lo que se hace es una técnica que se llaman embeddings, que es... traducir los píxeles a vectores, a unos y ceros, porque los algoritmos se lo entienden de unos y ceros. Entonces, lo que hace es, en una primera instancia, reconoce la forma del animal de forma genérica, después pasaría a analizar la cabeza, una estructura de ojos, nariz y boca, después pasaría a analizar ya diferentes narices y después pasaría a analizar las curvas, que son los vectores que están marcando el contorno. y al final decidiría si es un gato o es un perro. Todo esto, ¿qué ventaja tiene? Que funciona con backpropagation. Para que os hagáis una idea, backpropagation lo que significa es que la red neuronal va aprendiendo... va hacia adelante y en las neuronas hay lo que llamamos los pesos, que es una función matemática que es Matching Learning, y lo que va haciendo es hacer una iteración hacia adelante, comprueba el resultado, aquí cuando hablamos de resultado hablamos de precisión, siempre medimos la precisión del algoritmo, una precisión máxima casi sería un 95-97, el 100% no existe, y lo que va haciendo es, imaginaros, obtiene una precisión del 80, cuando vuelve a hacer otra pasada hacia detrás, actualiza los pesos y los optimiza hasta ir subiendo la precisión de forma iterativa mediante lo que llamamos Epochs. Este es un poco el concepto general de Deep Learning, sí que quiero que os quede claro que en Deep Learning necesitamos trabajar con miles de datos, estaríamos hablando a lo mejor 50.000 filas si estuviésemos hablando de datos tabulares. Pero sí que es cierto que el deep learning a nivel de imagen, cuando estáis viendo, por ejemplo, el caso de los deepfakes, es un caso de visión artificial muy común. Y lo mismo, cuando tú estás viendo un deepfake, hay un algoritmo que está reconociendo todo lo que es el contorno de los ojos, la nariz y la boca, y lo que está haciendo es mapeando otra imagen, está analizando los dos patrones y fusionándolos. Esto es un poco la tecnología que hay detrás, debo explicarlo de una forma sencilla, pero claro, Deep Learning también estaréis viendo en el tema, por ejemplo, trasladándolo otra vez a la descentralización, por ejemplo, estaréis viendo NFTs creados con estilos, con estilos similares a Van Gogh, a Dalí, incluso a Picasso. Otra característica que tiene el Deep Learning es el Transfer Style, es decir, que puede transferir un estilo. Todo esto... en fases primarias es lo que habéis visto también en filtros de diferentes aplicaciones o software de fotografía. Como hemos dicho, Machine Learning, yo casi que diría que es mi favorita, y la realidad es que es mi favorita por un factor, por la explicabilidad. Aquí tendremos que entender una cosa, los algoritmos se miden con la precisión, ¿Qué significa esto? Que, por ejemplo, si yo quiero saber el negocio de mi cliente cuánto va a facturar de aquí a dos semanas, y hacemos un algoritmo predictivo que nos emita esta predicción de si va a facturar este día 2.500 euros, y la realidad nos dice que facturó 2.400 euros, pues estaríamos hablando de una... de una cura así o una precisión elevada, ¿no? 90, 92 por 100. Bien, esto es interesante, ¿no?, porque nos permite anticiparnos. Si yo sé que mi negocio de aquí a dos semanas va a facturar 2.400 euros, pues me está indicando que necesitaré más materias primas, más trabajadores, etcétera. Esto, aunque se traduce en acción y en ventaja competitiva. Pero, ¿qué pasa si yo tengo una previsión, Machine learning tiene otra característica, que es la explicabilidad. Y esto es muy importante. Porque, por ejemplo, para hacer este algoritmo de predicción de cuánto voy a vender de aquí dos semanas, le hemos insertado a nivel de datos de Big Data, que es nuestra gasolina, todas las variables que afectan a nuestro negocio. Una variable podría ser si hizo una promoción o no. Otra variable podría ser número de trabajadores que tenía ese día, otra variable podría ser, pues, número de clientes, etcétera. Entonces, ¿qué ocurre? Que aparte de haceros una predicción, os va a decir el feature importance. Y el feature importance, lo que significa es que voy a saber cada variable cuánto afecta a ese resultado. Es decir, puedo llegar a saber que no es que sepa que vaya a 2.400 euros ese día. Es que sé que las variables que más afectan son el que haya una promoción o no al 82%, el que hayan 10 trabajadores al 72% y así sucesivamente. Es decir, nos habla a nivel de negocio de las palancas que tenemos que activar para mejorar nuestras métricas. Con todo esto ya hemos hecho un recorrido del estado del arte, de la historia de cómo pasamos de la programación básica a los transformers. Muchos alumnos me suelen preguntar qué es mejor, si machine learning, si deep learning o si en un momento dado se puede utilizar programación tradicional o si hay que utilizar un transformer. Y la respuesta es que es más fácil. siempre es la misma. Depende de la naturaleza de tu problema, depende del caso de uso y depende sobre todo de tus datos. Como he dicho al principio, los datos hablan sobre historias, por tanto una vez entendida la historia seremos capaces de decidir qué herramienta es la que mejor encaja para nuestro caso de uso.