---
title: Tokenización en Ethereum | David Ortega
URL: https://app.web3mba.io/courses/take/bloque-5-tokenizacion/lessons/39553826-3-tokenizacion-en-ethereum-david-ortega
Tags/Keywords: #B5 #Tokenizacion #B5U3 #Tokenización en Ethereum #David Ortega
lang: es-AR
---
# Tokenización en Ethereum
![[278.B5_Tokenización_en_Ethereum.mp4]]
[Tokenizacion en Ethereum](https://app.web3mba.io?wvideo=dll0v69igl)

La tokenización puede entenderse como la transformación de activos del mundo real en activos digitales. Esta tokenización, aplicada al ámbito de blockchain, se puede dividir en dos tipos diferentes: activos fungibles y activos no fungibles.

Para ilustrar, un activo fungible se define por el hecho de que si tenemos dos activos, como por ejemplo dos monedas, y nos las intercambiamos, ninguno de los dos pierde ni gana valor, ya que ambas monedas tienen el mismo valor. En contraste, los activos no fungibles son completamente diferentes; cada uno de ellos posee su propia idiosincrasia y características únicas. Por ejemplo, si tú tienes un cuadro de Picasso y yo tengo un dibujo que acabo de hacer, al intercambiarlos, uno de los dos perderá valor.

En el mundo de blockchain, podemos generar estos activos fungibles y no fungibles a través de contratos inteligentes. En el caso específico de Ethereum, estos contratos se desarrollan en base a ciertos estándares. Los activos fungibles se rigen por el estándar conocido como ERC20. El nombre ERC proviene de una página web creada y mantenida por la Ethereum Foundation, donde cualquier usuario de la comunidad puede añadir nuevos Ethereum Request for Comments, es decir, nuevas propuestas para mejorar la usabilidad de la plataforma. No se trata de proponer cambios internos en la plataforma, sino de definir cómo vamos a utilizarla externamente, estableciendo qué estándares podemos implementar en el desarrollo en Solidity, por ejemplo, para crear nuevas utilidades y casos de uso.

El ERC20 es el primer estándar que se estableció para el intercambio de tokens fungibles, permitiendo que si tenemos dos monedas y nos las intercambiamos, sean exactamente la misma moneda. En el caso de los tokens no fungibles, existen otros dos estándares que son actualmente los más utilizados en el mercado: el ERC721 y el ERC1155. El ERC721 se creó como un estándar genérico para los tokens no fungibles, permitiendo la creación de prácticamente cualquier cosa, donde cada elemento tokenizado tendrá su propia idiosincrasia y características, convirtiéndose en un ente completamente independiente de cualquier otro.

Estos estándares se utilizan en una variedad de aplicaciones. Por ejemplo, los tokens fungibles se emplean para generar participaciones sociales en una empresa o para crear partes de votación, permitiendo así la representación de un porcentaje de voto a través de un token fungible. En cuanto a los tokens no fungibles, hay diversos casos de uso, como los NFTs conocidos como PFPs (Profile Pictures), que incluyen ejemplos como el Bored Ape Yacht Club, donde lo que se vende es una personalidad. En este caso, puedes ser representado como un mono, por poner un ejemplo. Otros usos incluyen la creación de obras de arte digitales respaldadas por un token no fungible, así como la representación de propiedades, como viviendas o vehículos.

Todos estos estándares se han desarrollado en función de diferentes casos que existían en el momento de su creación. El mercado sigue evolucionando, añadiendo nuevos casos de uso y funcionalidades a estos estándares iniciales. En resumen, la tokenización nos permite dar forma en el mundo digital a la realidad que ya existe en el mundo físico. Esto es especialmente relevante en contextos como el metaverso, del cual seguramente habrás oído hablar, o simplemente para facilitar la realización de contratos. Los contratos inteligentes pueden utilizarse para transferir, por ejemplo, el valor de una propiedad que tenemos representada a través de un contrato ERC721.

Todo esto es importante porque nos permite dar forma a este mundo virtual, que no deja de ser una representación del mundo físico. El futuro de la tokenización radica en la generación de nuevos estándares y casos de uso que nos desbloqueen opciones que, en el mundo físico actual, no podemos realizar debido a las limitaciones existentes.