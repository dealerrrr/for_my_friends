---
title: Introducción a la Inteligencia Artificial
URL: https://app.web3mba.io/courses/take/especializacion-1-analisis-IA/lessons/41865984-u1-1-2-introduccion-a-la-inteligencia-artificial-jose-peris
Tags/Keywords: #Especialidad 1 #E1 #Analisis e IA #IA #AI #Inteligencia Artificial #E1U1 #José Peris
lang: es-AR
---
# Introducción a la Inteligencia Artificial
![[472.E1_Introducción_a_la_Inteligencia_Artificial.mp4]]
[Introducción a la Inteligencia Artificial](https://app.web3mba.io/courses/take/especializacion-1-analisis-IA/lessons/41865984-u1-1-2-introduccion-a-la-inteligencia-artificial-jose-peris)

Para entender otro concepto importante en Machine Learning y poder avanzar, debemos saber que este campo se centra mucho en el estado del arte. ¿Qué es el estado del arte? El estado del arte lo definiríamos como el punto en el que nos encontramos, cuál es la última tendencia, cuál es el último avance y cuál es el último hito tecnológico que se ha alcanzado. Para que os hagáis una idea, todo esto empezó con la programación tradicional, basada en bucles, como por ejemplo, las condiciones if-else, que son muy simples. Pero posteriormente apareció el machine learning, que fue el primer gran salto. Machine learning lo que hizo fue desarrollar algoritmos que tienen una característica importante: pueden trabajar con big data, pero también pueden funcionar con menos datos. Por otro lado, machine learning es muy útil porque permite una gran explicabilidad de las características del algoritmo. Más adelante veremos un poco qué es todo esto.

Posteriormente llegó el deep learning, que, como hemos comentado, imita el funcionamiento del cerebro humano. Es cierto que deep learning es mucho más atractivo y avanzado a nivel de estado del arte, pero tenemos un handicap: necesitamos trabajar con cantidades de datos mucho más elevadas para obtener resultados óptimos. Después del deep learning, vino el automation learning. Esto ya es prácticamente llevar las cosas al extremo, porque estamos hablando de inteligencia artificial que genera inteligencia artificial. Esta ventaja ha beneficiado o perjudicado, dependiendo de cómo lo miremos, a los desarrolladores. ¿Por qué? Porque lo que hace es aplicar inteligencia artificial a procesos de elaboración de algoritmos que son muy tediosos. En pocas palabras, lo que hace es optimizar el tiempo y ser mucho más ágiles, aunque es cierto que no porque se optimice todo podamos utilizarla sin tener conocimientos en este campo, que sería el data science.

Y ya por último, lo que sería el estado del arte de hoy, tendríamos los transformers. Los transformers han sido la disrupción más fuerte que hemos tenido en 2021, y que veremos a continuación. Cuando hablamos de transformers, hablamos de GPT-3. GPT-3, en una frase, es el chatbot más inteligente del mundo. Estamos hablando de hitos que eran impensables alcanzar hace unos años. ¿Por qué? Porque GPT-3 ha sido entrenado con millones de librerías de Wikipedia y de casi todos los libros disponibles en línea. Y claro, todos tenemos la imagen del chatbot que, al hacerle cuatro preguntas, se equivoca en la tercera o no tiene coherencia en sus respuestas. GPT-3 es un producto de OpenAI, y detrás de OpenAI está Elon Musk. Sabemos que es el chatbot más inteligente del mundo, ¿por qué? Porque es capaz de adoptar la personalidad, por ejemplo, de un personaje histórico. Es decir, en GPT-3 puedes hablar con Albert Einstein y tener una conversación coherente, un diálogo totalmente lógico con él, pero él siempre hablará con su lenguaje y con sus palabras. En el mismo chat puedes añadir a Elon Musk, a Gandhi o a otros personajes públicos sobre los que hay mucha literatura en la red, lo que proporciona datos para el entrenamiento.

Pero la ventaja de los transformers, y es algo que se utiliza mucho en este campo, es que es un campo muy líquido. Es decir, el conocimiento que se descubre en el ámbito del habla o de la escritura se puede trasladar a la imagen. GPT-3 nació en 2021, cuando se liberó la versión beta. Y, bueno, estamos hablando también de que, al estar entrenado de esta forma tan eficiente, llega el punto en el que puedes pedirle, por ejemplo, a GPT-3 que te diseñe una página web que tenga dos botones en el centro, uno de color rojo y otro de color negro. Y no solo te la va a generar, sino que también te va a generar el código. Es capaz de programar en casi cualquier lenguaje de programación. Simplemente tienes que pedirle que te haga una función matemática que cumpla una serie de condiciones y lo que hará es generarte el código. Después, con este código, puedes ejecutar el programa y te va a funcionar. Estamos hablando de un salto realmente muy potente. Esta es la potencia de GPT-3, que la podéis comprobar en el Playground; os dejamos aquí adjunto el enlace para que podáis jugar. Simplemente tenéis que registraros con vuestra cuenta de Google. Podéis comprobar que incluso le podéis pedir que os escriba un ensayo entre Platón y Aristóteles hablando sobre el concepto del amor, con una longitud de caracteres que vosotros deseéis. Y os va a crear un ensayo coherente. Incluso le podéis pedir que coja los ingredientes que tenéis en la nevera y que os haga una receta. Con esos ingredientes, os la va a hacer. Por supuesto, no es perfecto al 100%. Estamos hablando de una versión beta, pero realmente ha llegado a unas cotas que eran impensables hace unos años.

Como os decía, este campo es muy líquido. Y cuando llegan sorpresas, suelen llegar juntas, porque hay mucha capilaridad entre proyectos. También apareció DALL-E, obra de OpenAI, que rompió el paradigma de lo que es la visión artificial, porque aquí se ha juntado el conocimiento avanzado en el tema del habla y la escritura con el conocimiento de la imagen. ¿Qué significa todo esto? Que simplemente mediante palabras podemos crear, por ejemplo, objetos o conceptos gráficos que nunca han existido y que no están en ninguna base de datos. Esta combinación de estos dos algoritmos es un ejemplo de la narrow intelligence; cuando se combinan, pueden llegar a algo mucho más amplio o elevado. La realidad es que los resultados también son fascinantes, pero sí que es cierto que con DALL-E hubo un impasse donde se frenó el desarrollo. Y bueno, vino un desarrollo por otro lado con Glide. Glide lo que ha hecho es mejorar todo esto y estamos hablando de que si tú quieres a Glide, le puedes pedir que te dibuje una ilustración de Albert Einstein con un vestido de Superman y te la va a hacer. O que le pidas que te dibuje a un gato jugando al ajedrez con el estilo de Dalí, y te lo va a ejecutar. Es decir, imágenes imposibles, imágenes que nunca han existido, porque al final se combina la semántica con la imagen. Pero bueno, esto estamos hablando del estado del arte. Esto es el punto máximo.

También quiero comentaros que algunos de estos algoritmos sí que están disponibles para probar la versión beta o ya tenemos el código. Pero, ¿cómo se hace? Otros, pues aún no, simplemente se han utilizado para mostrar el potencial de dónde podemos llegar. Por ejemplo, ¿qué puede hacer por nosotros Glide? Para mí, Glide puede hacer algo totalmente fascinante, como es el uncrapping. El uncrapping no es más que, imagínate que le tomas una foto a tu amigo o amiga, y el uncrapping lo que hace es, mediante algoritmos de visión artificial, reconstruir y ampliar la escena. Él mismo se va inventando la escena que continuaría, con lo cual nos amplía el campo. El punto en el que nos encontramos ahora es muy excitante, simplemente por el hecho de que comienzan a confluir las tecnologías. Por un lado, tenemos las tecnologías descentralizadas y, por otro lado, la inteligencia artificial. Esto nos lleva a que podemos generar NFTs simplemente mediante la tecnología, utilizando código de inteligencia artificial. Es por ello que algoritmos como VQGAN más CLIP nos están permitiendo generar lo que nosotros queramos simplemente incluyendo tres o cuatro palabras. Es decir, podemos pedirle que nos genere un animal en un estilo modernista, en una escena del universo. Estamos hablando de imaginación, de creatividad y, si os fijáis, casi siempre os hablo de que es VQGAN más CLIP; estamos hablando de la suma de dos algoritmos, del ensamblaje. ¿Por qué? Porque lo que hacemos es unir características de diferentes algoritmos. En este caso, lo que estamos uniendo es CLIP, que es un clasificador que describe de forma muy exacta la imagen que está viendo a un nivel de detalle muy elevado. Es decir, no es lo mismo detectar que la imagen que está viendo un algoritmo de visión artificial es un coche o una bicicleta que detectar que, por ejemplo, está viendo una imagen de un husky siberiano sobre una vidriera. Estamos hablando de niveles de detalle muy diferentes. Este avance en la semántica ha permitido, al fusionarlo con la imagen, llegar a cotas muy elevadas. Lo mismo ocurre con VQGAN, que viene de las GANs, Generative Adversarial Networks, que a nivel de imagen comprende la profundidad de la imagen que está viendo. Imaginaros que estamos viendo una imagen de un pájaro o de un perro; lo que hace es calcular este vector de profundidad y entiende que esto es un animal que se llama pájaro, que puede estar representado con plumas de diferentes colores o con picos de diferentes formas. Lo mismo para un perro, que puede tener diferentes texturas y tipos de arrugas. Claro, todo esto nos lleva a que realmente lo que vamos a ver, y de hecho lo vais a practicar, os vamos a dejar aquí una pieza del código donde podéis crear vuestro NFT a partir de las palabras que vosotros queráis y os lo convierte a vídeo, también os lo anima. Claro, todo esto realmente ha pasado a partir de 2021, aunque venía con mucho recorrido detrás. Por tanto, este es el estado del arte de hoy.

Como os comentaba también, el automachine learning se basa en automatizar las tareas del data scientist. ¿Y qué significa eso? Básicamente, de una forma muy genérica, lo que hace un científico de datos es, primero, recopilar datos, una gran cantidad de big data para resolver un problema. Estos datos se tienen que limpiar y preparar, porque muchas veces están rellenados por personas que han completado una base de datos y pueden haber insertado un valor nulo, por ejemplo. Esto hay que limpiarlo; es un proceso que se llama ETL, que significa Extract, Transform, Load, y AutoML ya permite agilizar este proceso. Estamos hablando de que un algoritmo se puede desarrollar o diseñar en horas, semanas, meses o años, dependiendo de la complejidad a la que nos enfrentemos. Por tanto, si cogemos una métrica estándar, como pueden ser dos o tres meses, el proceso de ETL representa el 80%, y el proceso de selección del algoritmo puede representar el 20 o 30%, dependiendo del problema que estemos afrontando. ¿Qué hace el AutoML? En estas dos partes más tediosas, nos automatiza los procesos y, al final, lo que nos va a hacer es limpiar de forma más o menos automatizada y nos va a hacer una clasificación de qué algoritmos son los mejores que encajan para tu problema. Con lo cual, al final, esto se trata de inputs y outputs. Entonces, el input son los datos y el output que te va a dar el AutoML es la limpieza de los datos y un ranking con los mejores algoritmos para resolver tu problema.

El tercer punto es el deep learning. Deep learning, como os he comentado, se trata de trabajar con capas y con números de neuronas. Al final, imaginaros un clasificador. Hemos dicho que la inteligencia artificial predice, clasifica y agrupa. Imaginaros que, mediante visión artificial, queremos hacer un clasificador que sea capaz de distinguir entre un perro y un gato. ¿Cómo funciona el deep learning? Pues bien, lo que hace es establecer una serie de capas con un número de neuronas, donde cada capa de neuronas se encarga de realizar una función específica. Imaginaros que las primeras capas lo que van a hacer es analizar de lo general a lo concreto. Es decir, las primeras van a buscar la forma de la cabeza de un perro o de un gato. Aquí se utiliza una técnica llamada embeddings, que traduce los píxeles a vectores, a unos y ceros, porque los algoritmos entienden unos y ceros. Entonces, en una primera instancia, reconoce la forma del animal de forma genérica, después pasa a analizar la cabeza, la estructura de ojos, nariz y boca, luego analiza diferentes narices y finalmente analiza las curvas, que son los vectores que marcan el contorno, y al final decidiría si es un gato o un perro.

Todo esto, ¿qué ventaja tiene? Que funciona con backpropagation. Para que os hagáis una idea, backpropagation significa que la red neuronal va aprendiendo. Va hacia adelante y en las neuronas hay lo que llamamos pesos, que es una función matemática que se relaciona con el machine learning. Lo que hace es hacer una iteración hacia adelante, comprueba el resultado; aquí, cuando hablamos de resultado, hablamos de precisión. Siempre medimos la precisión del algoritmo; una precisión máxima sería de un 95-97%, ya que el 100% no existe. Lo que hace es, imaginaros, obtener una precisión del 80%; cuando vuelve a hacer otra pasada hacia atrás, actualiza los pesos y los optimiza hasta ir subiendo la precisión de forma iterativa mediante lo que llamamos epochs. Este es un poco el concepto general de deep learning. Quiero que os quede claro que en deep learning necesitamos trabajar con miles de datos; estaríamos hablando, a lo mejor, de 50.000 filas si estuviésemos hablando de datos tabulares. Pero sí que es cierto que el deep learning a nivel de imagen, cuando estáis viendo, por ejemplo, el caso de los deepfakes, es un caso de visión artificial muy común. Y lo mismo, cuando tú estás viendo un deepfake, hay un algoritmo que está reconociendo todo lo que es el contorno de los ojos, la nariz y la boca, y lo que está haciendo es mapear otra imagen, analizando los dos patrones y fusionándolos. Esto es un poco la tecnología que hay detrás; debo explicarlo de una forma sencilla, pero claro, el deep learning también lo estaréis viendo en el tema, por ejemplo, trasladándolo otra vez a la descentralización. Estaréis viendo NFTs creados con estilos similares a Van Gogh, a Dalí, incluso a Picasso. Otra característica que tiene el deep learning es el transfer style, es decir, que puede transferir un estilo. Todo esto, en fases primarias, es lo que habéis visto también en filtros de diferentes aplicaciones o software de fotografía.

Como hemos dicho, machine learning, yo casi diría que es mi favorita, y la realidad es que es mi favorita por un factor: la explicabilidad. Aquí tendremos que entender una cosa: los algoritmos se miden con la precisión. ¿Qué significa esto? Que, por ejemplo, si yo quiero saber cuánto va a facturar mi cliente de aquí a dos semanas, y hacemos un algoritmo predictivo que nos emita esta predicción de si va a facturar ese día 2.500 euros, y la realidad nos dice que facturó 2.400 euros, estaríamos hablando de una precisión elevada, ¿no? 90, 92%. Bien, esto es interesante, ¿no? Porque nos permite anticiparnos. Si yo sé que mi negocio de aquí a dos semanas va a facturar 2.400 euros, me está indicando que necesitaré más materias primas, más trabajadores, etcétera. Esto se traduce en acción y en ventaja competitiva. Pero, ¿qué pasa si yo tengo una previsión? Machine learning tiene otra característica, que es la explicabilidad. Y esto es muy importante. Porque, por ejemplo, para hacer este algoritmo de predicción de cuánto voy a vender de aquí a dos semanas, le hemos insertado a nivel de datos de big data, que es nuestra gasolina, todas las variables que afectan a nuestro negocio. Una variable podría ser si se hizo una promoción o no. Otra variable podría ser el número de trabajadores que tenía ese día, otra variable podría ser el número de clientes, etcétera. Entonces, ¿qué ocurre? Que, aparte de haceros una predicción, os va a decir el feature importance. Y el feature importance significa que voy a saber cuánto afecta cada variable a ese resultado. Es decir, puedo llegar a saber que no solo sé que voy a facturar 2.400 euros ese día, sino que sé que las variables que más afectan son el que haya una promoción o no, al 82%, el que haya 10 trabajadores, al 72%, y así sucesivamente. Es decir, nos habla a nivel de negocio de las palancas que tenemos que activar para mejorar nuestras métricas.

Con todo esto, ya hemos hecho un recorrido del estado del arte, de la historia de cómo pasamos de la programación básica a los transformers. Muchos alumnos me suelen preguntar qué es mejor: si machine learning, si deep learning o si, en un momento dado, se puede utilizar programación tradicional o si hay que utilizar un transformer. Y la respuesta es que siempre es la misma: depende de la naturaleza de tu problema, del caso de uso y, sobre todo, de tus datos. Como he dicho al principio, los datos cuentan historias; por tanto, una vez entendida la historia, seremos capaces de decidir qué herramienta es la que mejor encaja para nuestro caso de uso.