---
title: Desarrollo del Algoritmo
URL: https://app.web3mba.io/courses/take/especializacion-1-analisis-IA/texts/41658579-u3-1-desarrollo-del-algoritmo
Tags/Keywords: #Especialidad 1 #E1 #Analisis e IA #IA #AI #Inteligencia Artificial #E1U3 #analisis avanzado #desarrollo del algoritmo #Algoritmo
lang: es-AR
---
# Desarrollo del Algoritmo
Vamos a hablar de varios conceptos claves para el correcto funcionamiento del proceso de desarrollo de nuestro algoritmo.

Son aquellos conceptos que siempre tenemos que revisar antes de comenzar a entrenar nuestro algoritmo. Cuando observamos que la precisión no es la correcta, tendremos que volver a revisar si cumplimos esta serie de características. 

Para ello, vamos a intentar analizar punto por punto dónde tenemos que prestar más atención. 

![[479.E1_Desarrollo_del_Algoritmo_1.png]]

## 1 | Missing Values
El primer paso sería visualizar nuestro Dataset, consultar las estadísticas que nos da para que nos diga de una forma científica cuantos Missing Values tenemos. 

No se trata de ir comprobándolo de forma manual. Existen diversas formas, según el método que utilicemos, de ver qué porcentaje de Missing Values que tenemos en nuestras columnas o en nuestras variables. 

Aquí lo importante es que, una vez las detectamos, saber qué estrategia seguimos y como manejamos esta situación.

Una de las estrategias a seguir, dividirlas en dos grupos. 
- Grupo 1: Eliminar
- Grupo 2: Reemplazar 

 ### 1 | Eliminar
Aquí hay que hablar de dos escenarios muy diferentes. 
- **Cuando tenemos muchísimos datos, p. ej. 300k / 400k filas.** Si tenemos un porcentaje de Missing Values de un 20%, El hecho de que las eliminemos no va a importar demasiado. 
- **Cuando vamos justos de datos: 3k o 4k filas.** Si estamos hablando de eliminar filas donde Missing Values estaríamos teniendo un problema, porque si íbamos muy justos, estamos siendo aún más justos. Con lo cual esto puede tener una afectación en la performance de nuestro algoritmo. Por tanto, esta sería la primera medida, no eliminar filas que decidiríamos con base en nuestra cantidad de datos. 
- **Si vemos que una variable tiene una gran cantidad de Missing Values.** Realmente lo que está afectando a un 40% de los datos, un 40% de las filas, Lo mejor es eliminarlas, porque no va a haber forma de reemplazar estos valores.

### 2 | Reemplazar
Esa estrategia la vamos a aplicar en el supuesto escenario de que tengamos pocos datos. 

Tenemos que hacer es exprimir al máximo estos datos. 
- Se puede reemplazar por la media. 
- Se puede reemplazar por la mediana. 
- Se puede reemplazar con una constante.
- Etc…

Hay otro tipo de estrategias, por ejemplo: 
1. En un dataset, un factor muy importante es la edad. 
2. Tenemos Missing Values en la variable edad, que tenemos muchos y no sabemos la edad de una cantidad muy grande de usuarios. 
3. Pero sí que tenemos su nivel de estudios y su ocupación actual. 
4. Podríamos interpolar o averiguar un poco el rango de edad, no tenemos la edad exacta, pero podemos determinar si esta persona está en primaria, secundaria, en estudios universitarios, trabajando o jubilada. 

Aquí tendríamos ya cinco grupos y aquí lo que estaríamos haciendo es crear una columna nueva donde podemos también el parámetro de edad, transformarlo y de esta forma podríamos salvar el problema de los Missing Values. 

> Hay que comprender el contexto y ser creativo.

![[479.E1_Desarrollo_del_Algoritmo_2.png]]

## 2 | Cross Validation
Podemos representarlo como el concepto de mezclar las cartas. 

Cuando jugamos a un juego de cartas y cogemos una baraja, lo que hacemos es mezclarla, estamos buscando heterogeneidad. Imaginaros que hemos terminado la partida y los cuatro están sobre la mesa porque seguimos una escala homogénea.

Si nosotros simplemente las cartas las juntamos, lo que nos pasará es que estarán los ases y los caballos juntos, es decir, habrá una homogeneidad. 

Cuando jugamos a cartas, necesitamos mezclar y buscar heterogeneidad. Recordad que hemos hablado que nosotros partimos el entrenamiento en test 80/20 o 70/30. 

Vamos a poner el foco en lo que es el concepto de la captura del dato. 

## Ejemplo: Algoritmo predictivo 
Queremos saber, basándonos en ciertos datos sociológicos y de historial médico, intentar predecir si un paciente va a sufrir o vamos coronavirus o no. 

Vamos a visualizar cómo capturar los datos, ya que hemos pasado por procesos de vacunaciones masivas. Imaginamos que cogemos un centro sanitario de una capital y ahí lo que hacemos es a medir diversos parámetros médicos de estos usuarios. 

Hacemos una convocatoria masiva porque necesitamos personas de todas las edades, todo el rango de edades.
1. Llega primero un autobús de un parvulario, llegan todos los niños y se les cogen todos los parámetros médicos y se almacena en una base de datos del cero al 50. 
2. Llega a un instituto y aplicamos el mismo protocolo a todos los alumnos. 
3. Llega un autobús de una empresa. 
4. Llega otro autobús con gente de una residencia de ancianos. 

Hacemos un entrenamiento, test 80/20 con todos estos datos.
- El primer autobús que ha venido es el de los niños de preescolar y el último es el de los ancianos. 
- Si partimos el 80/20, probablemente nos vamos a dejar fuera el autobús de los ancianos. 
- Este algoritmo, que lo estamos entrenando con unos datos, tiene un sesgo porque no ha visto casos de gente anciana, un rango de edad. Por lo tanto, aquí hay un sesgo. 

¿Cuál sería la solución? Mezclar las cartas, mezclar los 4 autobuses. De forma que en este 80% de entrenamiento tendríamos todos los rangos de edad mezclados.

En el rango del 20% de test tendríamos ejemplos de todos de test de todos los rangos de edad. 

Este es el concepto de Cross Validation y se basa en el concepto de K, que son el número default o el número de particiones que hacemos. 

Es una forma de evitar sesgos, porque al final no hay que olvidar que un algoritmo no es más que una opinión codificada y puede tener sesgos humanos.