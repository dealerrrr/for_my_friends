---
title: Machine Learning | José Peris
URL: https://app.web3mba.io/courses/take/especializacion-1-analisis-IA/lessons/41866154-u5-1-2-machine-learning-jose-peris
Tags/Keywords: #Especialidad 1 #E1 #Analisis e IA #IA #AI #Inteligencia Artificial #E1U5 #Machine Learning #José Peris
lang: es-AR
---
# Machine Learning
![[489.E1_Machine_Learning.mp4]]
[Machine Learning](https://app.web3mba.io/courses/take/especializacion-1-analisis-IA/lessons/41866154-u5-1-2-machine-learning-jose-peris)

**Cómo evaluamos nuestro algoritmo**

Aquí vamos a diferenciar dos grandes grupos y recordad que siempre hablamos desde el punto de vista de aprendizaje supervisado, cuando tiene etiqueta, cuando hay una mano detrás, cuando sabemos el resultado de antemano. Los grandes grupos son, uno, la regresión, y otro, la clasificación.

La regresión, ¿cómo vamos a evaluarla? Como podéis ver en la gráfica, básicamente lo que tenemos son los puntos de datos y nuestro algoritmo se vería representado como la línea verde que tenemos. Esta línea verde representa una regresión lineal. Si os fijáis, lo que ocurre es que pasa más o menos por el medio de la nube de puntos. ¿Qué significa esto? Significa que esa recta tiene una fórmula matemática y esa fórmula matemática es la que nos permite predecir dónde va a caer el próximo punto.

¿Cómo medimos la precisión? Lo que hacemos es comparar nuestras predicciones frente a los resultados reales y medimos la distancia de cada punto real respecto a nuestra recta. A partir de aquí, midiendo esta distancia para cada punto, vamos a sacar una media y esa será la media de nuestro error. Esto es cuando estamos hablando de regresión, donde el valor podría ser, por ejemplo, 1824 euros.

¿Cómo evaluamos la clasificación? La clasificación se evalúa mediante un instrumento llamado matriz de confusión, y el nombre está muy bien puesto porque realmente estamos hablando de elaborar una matriz donde vamos a clasificar los diferentes resultados. En este caso, por ejemplo, vamos a tener dos columnas: una será para los resultados reales y dos filas donde estarán los resultados del algoritmo. Aquí, básicamente, lo que hacemos es contar cuántas veces hemos acertado y cuántas veces hemos fallado en la clasificación.

Este concepto es un poco lioso, pero el hecho de que hemos pasado por una pandemia ha ayudado a entenderlo un poco mejor, porque esto se basa en falsos positivos y falsos negativos. ¿Qué ocurre con el coronavirus, por ejemplo? Tenemos el caso de falso positivo y falso negativo. A día de hoy, todos sabemos ya lo que significa. Te pueden diagnosticar el coronavirus y no lo tenías; eso sería un falso positivo. Pero también hay un falso negativo: te pueden diagnosticar que no tienes coronavirus y sí que lo tienes, y ya has contagiado a todo tu entorno. Este es el concepto clave para la clasificación, porque cuando clasificamos si es sí o no, tenemos que ver si es un falso positivo o un falso negativo.

A continuación, os voy a dejar aquí un ejemplo interactivo donde podéis experimentar un poco con el concepto de la matriz de confusión. Lo que vais a ver son dos grupos de imágenes: un clasificador que representa imágenes de comida y imágenes que no representan comida. Lo que tenéis que hacer es clasificar las que van a un lado. Tenéis que pensar que para evaluar una clasificación es muy importante tener en cuenta cuántos hemos acertado. En este caso, miraríamos los true positives y los true negatives, y cuánto hemos fallado, los false positives o false negatives. Lo que hacemos es comparar los que hemos acertado contra los que hemos fallado.

Lo que pasa es que no es lo mismo fallar prediciendo una enfermedad que fallar prediciendo si una campaña de marketing va a funcionar o no; es aquí donde debemos establecer nuestro umbral. Existen otros métodos más avanzados, pero a nivel general vamos a crear un método más avanzado con estos conceptos básicos de medición y evaluación de algoritmos.

Vamos a seguir hablando de los datasets y, sobre todo, de un concepto muy importante que es el entrenamiento y el test. Fijaros que estamos hablando de que tenemos que medir y evaluar la predicción de nuestros algoritmos, ya sea en regresión como en clasificación. Para ello, lo que vamos a hacer es que nunca vamos a trabajar con el 100% de los datos. ¿A qué me refiero con esto? Imaginaros que me envían un dataset de 100.000 filas y 15 columnas, 15 variables.

El primer paso que tenemos que hacer es, aparte de realizar un análisis del negocio, llevar a cabo un proceso de ETL. Lo siguiente que haríamos sería partir el dataset en entrenamiento y test. Hay diversas formas de partirlo; normalmente es un 80-20, aunque puede ser un 70-30. También hay formas de incluso partirlo más, en entrenamiento, test y validación, pero en este punto en el que nos encontramos vamos a hablar de entrenamiento y test.

Lo que vamos a hacer siempre es partir nuestro dataset: el 80% será de entrenamiento y el 20% será de test. ¿Esto qué significa? Que desde la fila 0 hasta la fila 80.000 serán nuestros datos de entrenamiento y desde la fila 80.000 hasta la 100.000 serán los datos de test. ¿Por qué? Porque lo que vamos a hacer es entrenar nuestro algoritmo con este 80% de los datos y, una vez esté entrenado, lo que vamos a hacer es, imaginemos que seguimos con el ejemplo del algoritmo de predicción de si un cliente va a pagar un crédito o no, para saber si se lo podemos ofrecer o no.

En este caso, lo que sucedería es que, una vez nuestro algoritmo está entrenado con el 80% de los datos, nosotros simplemente cogeríamos los datos del test, ese 20% donde lo que veríamos realmente sería un ID de un usuario y todas sus características, todo su histórico, todo su histórico de cobros, de pagos, de ingresos y de gastos con el banco, y el algoritmo aquí haría una predicción.

¿Qué ocurre? Que como tenemos el dato real porque hemos partido en 80-20, podemos contrastar la predicción del algoritmo con el dato real: predicción contra realidad. Siempre es este el patrón que seguimos, por tanto, analizaríamos punto a punto, ¿cuánto hemos acertado o cuánto hemos fallado? Si estamos hablando de regresión, será un número; estaremos hablando de un error que, haciendo la inversa, es la precisión. Si estamos hablando de clasificación, en una primera instancia lo haríamos con una matriz de confusión y, de forma más avanzada, ya utilizaríamos análisis como el ROC o AUC. Pero nos vamos a quedar en esta base, en que para medir y poder trabajar, tenemos que partir siempre en entrenamiento y en test.

Vamos a hablar sobre la parte más importante en Machine Learning y en Inteligencia Artificial, que son las variables. Recordad la estructura que es aumentada de un dataset: tendríamos muchas filas y tendríamos columnas. Estas columnas son las variables. Las variables, realmente, de una forma entendible, serían aquellos parámetros que explican todo el contexto.

Vamos a llevarlo a cabo con un caso muy fácil y entendible, como puede ser el caso de la hostelería: un bar, un restaurante, un hotel. Pongamos que un cliente nos pide que desarrollemos un algoritmo predictivo que nos permita predecir cuánto vamos a facturar a dos semanas vista o cuántos trabajadores vamos a necesitar a dos semanas vista. Si pensáis bien, si sabemos cuánto vamos a facturar y cuántos trabajadores vamos a necesitar, tenemos mucha ventaja competitiva porque realmente sabemos que no va a haber rotura de stock, sabremos que va a haber un buen servicio, podemos preparar la sala y el personal para un determinado escenario, con lo cual estamos hablando de un retorno considerable. Esto es el rol de trabajar con Machine Learning y con IA.

Sigamos en este caso. Imaginad que el caso común es que un cliente, por ejemplo, te dé su base de datos y te diga: "Bueno, aquí tienes mi base de datos". Lo que vas a tener es un timestamp, como hemos dicho anteriormente, porque tendremos fechas. Tendremos un histórico de fechas; pongamos que tenemos 10 años, y al lado tendremos una columna con la facturación de cada día. A día de hoy, lo que se suele hacer cuando no hay una transformación digital por medio es hacerlo realmente a ojo.

Entonces, ¿qué significa hacerlo a ojo? Pues bueno, que si calculamos un incremento o un descenso de x, porque este año es mejor o es peor. Esto nos lleva a que son predicciones muy inexactas, que rozan el 50%. Un 50% en Machine Learning es lanzar la moneda, con lo cual no aportas absolutamente nada. Vamos a ver cómo configuraríamos este algoritmo, estas variables, para poder realizar un buen algoritmo.

Lo primero es pensar con lógica. Nosotros tenemos una fecha, un timestamp, y una facturación, unos datos de facturación en euros. De una forma muy sencilla, ¿creéis que se factura lo mismo en hostelería un sábado o un viernes que un lunes o un martes? Evidentemente no. Aquí hay un componente psicológico en el cual un lunes o un martes va a ser difícil que la gente acuda más a los bares; sin embargo, un viernes, un sábado o un domingo sí. Sabemos que, obviamente, esto va a afectar a la facturación. ¿En qué día de la semana estoy? Va a afectar directamente a mi facturación. Por tanto, el día de la semana es una variable muy importante que, haciendo ETL, la podemos añadir a nuestro dataset. Esto se traduciría en que si el día de la semana es el 1 o es el 7, o es el 2 o es el 3.

¿Qué otra variable podría afectar? Por ejemplo, la variable de festivos. Si es Halloween, es obvio que ese día es probable que afecte la facturación, o incluso la víspera. Por tanto, el factor festivo en el calendario nacional es una variable también muy importante. Pero pensad que este bar, este restaurante o este hotel está en España. Cuando está lloviendo, la gente va a los bares o a los restaurantes; les cuesta muchísimo más salir de casa. Sin embargo, cuando hace sol, nos lanzamos a la calle. Por tanto, la temperatura va a influir claramente también en nuestro objetivo, que se denomina Machine Learning, que es la facturación.

O, por ejemplo, las precipitaciones, la lluvia, que también podríamos englobar dentro de esta misma variable. Pero tenemos que tener en cuenta que hay otro tipo de variables que pueden afectar, porque imaginaros que alrededor de este restaurante se realiza un evento, hay un fin de semana de conciertos donde vienen artistas de todo el mundo. ¿Qué va a pasar? Que va a haber mucha más gente alrededor. Por lo tanto, esto en Machine Learning lo veríamos como un evento: si hay evento, sería un 1, y si no hay evento, sería un 0, por ejemplo. Así es como traduciríamos esta información de forma binaria.

Pero podrían afectar también otra serie de variables, como, por ejemplo, qué día del mes es. No es lo mismo; no gastamos lo mismo el día 5 que el día 30. Los ánimos no son los mismos. Pero, por otro lado, también hay otras variables que podrían influir, que son Open Data, que son variables externas. Imaginaros que la tasa de paro juvenil se sitúa en un 40%. Esto va a afectar también; esta variable externa, este Open Data, va a afectar. O digamos que el PIB ha bajado muchísimo. Todo este tipo de variables son lo que nosotros denominamos variables, y es aquí donde está la génesis de la creación de un buen algoritmo.

Es realmente la clave comprobar qué variables son las que mejor explican este suceso o evento. A partir de aquí, ya podríamos, una vez hemos conformado nuestro dataset, hemos añadido esta serie de variables y hemos comprobado su importancia, pasar a partir en entrenamiento y test y desarrollar nuestro algoritmo de nuestra caja de herramientas, ajustarlo y conseguir la precisión adecuada.

Para que os hagáis una idea, estaríamos hablando en términos cuantitativos. Por ejemplo, en términos de precisión, estaríamos hablando de que si simplemente lo que vamos a tener es un timestamp de una columna con un valor en euros, podríamos situarnos en precisiones alrededor del 60%. En el momento en que añadimos variables, variables que apuntan a qué pasó en esos días y utilizamos Open Data, podríamos subir a precisiones del 90%, incluso del 95%. Lo cual, como podéis comprender, puede ser una ventaja competitiva muy potente.

El campo del Machine Learning y la Inteligencia Artificial es un campo técnico, es cierto, pero no todo es desarrollo y tecnicismos. Realmente puede acceder gente desde el ámbito del negocio que va a tener que aprender una serie de técnicas que son perfectamente alcanzables. Al final, realmente lo que importa es una buena combinación de la parte táctica y estratégica con la parte técnica.