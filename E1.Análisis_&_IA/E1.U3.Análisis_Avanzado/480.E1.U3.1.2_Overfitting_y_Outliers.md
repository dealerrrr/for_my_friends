---
title: Overfitting y Outliers
URL: https://app.web3mba.io/courses/take/especializacion-1-analisis-IA/texts/41662910-u3-1-2-overfitting-y-outliers
Tags/Keywords: #Overfitting #Outliers
lang: es-AR
---
# Overfitting y Outliers
A priori, puede parecer conceptos bastante abstractos, pero tienen mucho sentido… ¿Qué son y para qué sirven?

## Overfitting
Los algoritmos de Machine Learning e Inteligencia Artificial aprenden de datos históricos del pasado. Simplemente, significa que pueden haber aprendido demasiado de esos datos del pasado.

El objetivo principal de un algoritmo es poder generalizar en sus predicciones, no es importante una precisión súper elevada, sino que sepa generalizar bien para que no haga predicciones de aberraciones o de cosas incoherentes.

Veamos un ejemplo Overfitting muy sencillo:
- Vamos a un sastre para hacernos un traje a medida. 
- Este sastre mide las dimensiones corporales exactas y no deja ninguna holgura, simplemente, construye un traje totalmente ceñido a tu cuerpo, tus dimensiones. 
- Esto nos haría caminar rígidos.

Cuando hablamos de Overfitting, empezamos a pensar en ese cuerpo rígido con el traje sin tolerancia alguna.

Imaginemos ahora que los datos son una nube de puntos. ¿Qué ocurre cuando un algoritmo aprende con Overfitting? 
- Lo que está ocurriendo es que va prediciendo cada punto aprendido, ha entrenado de forma demasiado exacta.
- De hecho, no nos interesa que se ajuste cada punto. Nos interesa que pase por la media de los puntos, está un poco ligado al concepto de media y varianza.
- Queremos que nuestro algoritmo no haga una predicción exacta de cada punto, sino que esté en la media correcta de todos los puntos porque nos va a permitir generalizar correctamente.

> Si un algoritmo se entrena con Overfitting, en el momento que hace una predicción y ciertos valores se salen un poco de este patrón, va a realizar predicciones nefastas, puede pasar del 90% al 55% y esto no nos interesa, se ha ceñido demasiado a los datos históricos.

- Por tanto, cuando ve un dato nuevo, extraño, no sabe cómo comportarse. 
- Nos interesa más que el algoritmo tenga una precisión más estable, por ejemplo, entre el 85% y el 89%, pero cuando vea casos atípicos, generalice bien.
- En Machine Learning e Inteligencia Artificial, el 100% no existe, con lo que estamos hablando de que siempre vamos a asumir un error. 
- Este error, tanto en regresión como en clasificación, queremos tenerlo controlado y que, al final, permita generalizar de forma coherente porque dicho error ya está asumido.

![[480.E1_Overfitting_y_Outliers_2.png]]

### ¿Cómo detectar el Overfitting?
Lo podemos detectar en los datos, cuando se entrena el algoritmo. Si en los entrenamientos arroja precisiones muy elevadas (99%), tenemos que prestar atención, pues nuestro algoritmo se está ajustando demasiado a los datos, por lo tanto, no va a ser flexible ante los nuevos datos.

En este punto, debemos iterar, revisar y aplicar técnicas para poder evitar el Overfitting.
- Cross Validation, mezclar las cartas. 
- Data Aumentation, que sería aumentar, de forma artificial, nuestra cantidad de datos.
- Drop Out. Dejar fuera ciertos datos de forma aleatoria.
- Early Stopping.

Al final lo que buscamos es tener Heterogeneidad y que los algoritmos aprendan de forma correcta.

## Outliers
En primer lugar, hay que tener una buena praxis para detectar un Outlier y, para ello, lo que tenemos que hacer es visualizar y pintar nuestros datos. 

Es un metapoint que tiene un valor muy atípico, es decir, que se desvía muchísimo de la media de temas.
- Imaginemos que vamos a elaborar un algoritmo predictivo de ventas para un e-commerce que venda todo tipo de productos similares a los que puede tener Amazon.
- Capturamos los datos, cogemos la base de datos y empezamos a analizar los valores.
- De lunes a viernes venden, de media global, 1000 productos.
- De repente, un viernes de un mes concreto, se vendieron 10000, hay un x10.

**Lo primero que haremos es visualizar ese dato, detectarlo y comprobar si ese valor es real o no,** porque puede pasar que en lugar de 1000, la base de datos haya insertado manualmente 10000, entonces estaríamos ante una anomalía que habría que corregir.
- Pero hacemos las comprobaciones, hablamos con el cliente y resulta que sí, que, efectivamente, ese día se vendieron 10000 unidades.
- A nivel de variables diríamos que lo que sucedió ese día es que había una promoción, pero el hecho que provocó esto fue que en Amazon, ese mismo día, se acabaron las existencias de un producto determinado. Los clientes llegaron hacia nosotros.
- Este hecho es, obviamente, importante, pero si pensamos en términos de gráficas, de que estamos hablando de valores de 1000 o cercanos y, de repente, 10000.
- Un algoritmo puede ser visto en forma abstracta o conceptual, como una línea recta o curva que tiene una fórmula matemática. 
- Esta línea nos la distorsionaría de forma abrupta con este valor tan elevado.

Entonces es aquí cuando hay que volver al concepto de generalizar. 

Como queremos que generalice bien, en este caso, es más útil eliminar el Outlier porque va a crear una distorsión en todo el conjunto. Es muy importante remarcar que debemos entender la naturaleza del problema que estamos abordando.

![[480.E1_Overfitting_y_Outliers_1.png]]

Pero, ==eliminar el Outlier no siempre es la mejor estrategia==.

Por ejemplo, la naturaleza del problema en los casos de predicción de los Stock Market, de acciones en la Bolsa de Valores o en los casos Cripto, los Outliers son realmente muy importantes y hay que prestarles muchísima atención.

De hecho, las métricas que hay que utilizar en estos casos, son métricas que están preparadas para prestar especial atención a esto porque en la gráfica, esos Outliers, esos picos y valles, son datos muy potentes porque al final están hablando de que ese día ocurrió algo especial, importante, por tanto, hay que analizar la naturaleza del problema para ver la estrategia a seguir.